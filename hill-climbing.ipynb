{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"},{"sourceId":7453542,"sourceType":"datasetVersion","datasetId":921302},{"sourceId":10097128,"sourceType":"datasetVersion","datasetId":6226248},{"sourceId":10370860,"sourceType":"datasetVersion","datasetId":6415434},{"sourceId":10409094,"sourceType":"datasetVersion","datasetId":6450507},{"sourceId":211322530,"sourceType":"kernelVersion"},{"sourceId":216172723,"sourceType":"kernelVersion"},{"sourceId":217481514,"sourceType":"kernelVersion"},{"sourceId":217813503,"sourceType":"kernelVersion"},{"sourceId":217931837,"sourceType":"kernelVersion"},{"sourceId":218131499,"sourceType":"kernelVersion"},{"sourceId":218144682,"sourceType":"kernelVersion"},{"sourceId":218801338,"sourceType":"kernelVersion"},{"sourceId":218802756,"sourceType":"kernelVersion"},{"sourceId":219153168,"sourceType":"kernelVersion"},{"sourceId":219154661,"sourceType":"kernelVersion"},{"sourceId":219195490,"sourceType":"kernelVersion"},{"sourceId":219311236,"sourceType":"kernelVersion"},{"sourceId":219519933,"sourceType":"kernelVersion"},{"sourceId":219788453,"sourceType":"kernelVersion"},{"sourceId":219953795,"sourceType":"kernelVersion"},{"sourceId":220208646,"sourceType":"kernelVersion"},{"sourceId":220212754,"sourceType":"kernelVersion"},{"sourceId":220243528,"sourceType":"kernelVersion"},{"sourceId":220393279,"sourceType":"kernelVersion"},{"sourceId":221224474,"sourceType":"kernelVersion"},{"sourceId":221474387,"sourceType":"kernelVersion"},{"sourceId":221524326,"sourceType":"kernelVersion"},{"sourceId":221636013,"sourceType":"kernelVersion"},{"sourceId":221640769,"sourceType":"kernelVersion"},{"sourceId":221830134,"sourceType":"kernelVersion"},{"sourceId":222021427,"sourceType":"kernelVersion"},{"sourceId":222265918,"sourceType":"kernelVersion"},{"sourceId":222267362,"sourceType":"kernelVersion"},{"sourceId":222268629,"sourceType":"kernelVersion"},{"sourceId":222637056,"sourceType":"kernelVersion"},{"sourceId":222638468,"sourceType":"kernelVersion"},{"sourceId":222639128,"sourceType":"kernelVersion"},{"sourceId":222646580,"sourceType":"kernelVersion"},{"sourceId":222647954,"sourceType":"kernelVersion"},{"sourceId":222688114,"sourceType":"kernelVersion"},{"sourceId":222831405,"sourceType":"kernelVersion"},{"sourceId":223111714,"sourceType":"kernelVersion"},{"sourceId":223730449,"sourceType":"kernelVersion"},{"sourceId":223733528,"sourceType":"kernelVersion"},{"sourceId":223734261,"sourceType":"kernelVersion"},{"sourceId":223847496,"sourceType":"kernelVersion"},{"sourceId":224446847,"sourceType":"kernelVersion"},{"sourceId":224920880,"sourceType":"kernelVersion"},{"sourceId":225297866,"sourceType":"kernelVersion"},{"sourceId":225326328,"sourceType":"kernelVersion"},{"sourceId":225343712,"sourceType":"kernelVersion"},{"sourceId":225424423,"sourceType":"kernelVersion"},{"sourceId":225426770,"sourceType":"kernelVersion"},{"sourceId":225454357,"sourceType":"kernelVersion"},{"sourceId":225456146,"sourceType":"kernelVersion"},{"sourceId":225456748,"sourceType":"kernelVersion"},{"sourceId":225464407,"sourceType":"kernelVersion"},{"sourceId":225634491,"sourceType":"kernelVersion"},{"sourceId":225640399,"sourceType":"kernelVersion"},{"sourceId":225706668,"sourceType":"kernelVersion"},{"sourceId":225719412,"sourceType":"kernelVersion"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installations","metadata":{"_uuid":"9daabf89-8847-4537-a0b7-2a722b5c452d","_cell_guid":"46a264b2-b97f-487b-9a3d-2597a0ecdc21","collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:15:51.123667Z","iopub.execute_input":"2025-03-04T18:15:51.123888Z","iopub.status.idle":"2025-03-04T18:16:11.613179Z","shell.execute_reply.started":"2025-03-04T18:15:51.123863Z","shell.execute_reply":"2025-03-04T18:16:11.611863Z"}},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from autograd==1.7.0) (1.26.4)\nInstalling collected packages: autograd\nSuccessfully installed autograd-1.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nProcessing /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/site-packages (from autograd-gamma==0.5.0) (1.7.0)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/site-packages (from autograd-gamma==0.5.0) (1.15.0rc1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\nBuilding wheels for collected packages: autograd-gamma\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=3bdb66ee655ff8453e44c69f111fb7bf8cafb266ce1754dc55e363c39c4f8ffa\n  Stored in directory: /root/.cache/pip/wheels/6b/b5/e0/4c79e15c0b5f2c15ecf613c720bb20daab20a666eb67135155\nSuccessfully built autograd-gamma\nInstalling collected packages: autograd-gamma\nSuccessfully installed autograd-gamma-0.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nProcessing /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\nInstalling collected packages: interface-meta\nSuccessfully installed interface-meta-1.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nProcessing /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\nRequirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/site-packages (from formulaic==1.0.2) (1.15.0rc1)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/site-packages (from formulaic==1.0.2) (1.17.0)\nRequirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/site-packages (from formulaic==1.0.2) (1.3.0)\nRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/site-packages (from formulaic==1.0.2) (2.2.3)\nRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/site-packages (from formulaic==1.0.2) (1.26.4)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/site-packages (from formulaic==1.0.2) (4.12.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0->formulaic==1.0.2) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.0.2) (1.17.0)\nInstalling collected packages: formulaic\nSuccessfully installed formulaic-1.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nProcessing /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\nRequirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/site-packages (from lifelines==0.30.0) (1.7.0)\nRequirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/site-packages (from lifelines==0.30.0) (1.0.2)\nRequirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/site-packages (from lifelines==0.30.0) (2.2.3)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/site-packages (from lifelines==0.30.0) (1.26.4)\nRequirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/site-packages (from lifelines==0.30.0) (3.10.0)\nRequirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/site-packages (from lifelines==0.30.0) (0.5.0)\nRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/site-packages (from lifelines==0.30.0) (1.15.0rc1)\nRequirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.17.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.55.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.2)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (11.0.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.9.0.post0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.2.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.17.0)\nInstalling collected packages: lifelines\nSuccessfully installed lifelines-0.30.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --no-index -U --find-links=/kaggle/input/tabm-tabular-dl-library tabm==0.0.1.dev0\n!pip -q install /kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:16:11.614178Z","iopub.execute_input":"2025-03-04T18:16:11.614431Z","iopub.status.idle":"2025-03-04T18:16:18.778595Z","shell.execute_reply.started":"2025-03-04T18:16:11.614384Z","shell.execute_reply":"2025-03-04T18:16:18.777311Z"}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/tabm-tabular-dl-library\nProcessing /kaggle/input/tabm-tabular-dl-library/tabm-0.0.1.dev0-py3-none-any.whl\nRequirement already satisfied: torch<3,>=1.12 in /usr/local/lib/python3.10/site-packages (from tabm==0.0.1.dev0) (2.4.0)\nProcessing /kaggle/input/tabm-tabular-dl-library/rtdl_num_embeddings-0.0.11-py3-none-any.whl\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.4.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (12.1.105)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (12.1.3.1)\nRequirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.0.0)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (11.4.5.107)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (12.1.105)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.16.1)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (9.1.0.70)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (1.13.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (12.1.0.106)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (12.1.105)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (2.20.5)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (11.0.2.54)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (2024.10.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.1.4)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=1.12->tabm==0.0.1.dev0) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch<3,>=1.12->tabm==0.0.1.dev0) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch<3,>=1.12->tabm==0.0.1.dev0) (1.3.0)\nInstalling collected packages: rtdl_num_embeddings, tabm\nSuccessfully installed rtdl_num_embeddings-0.0.11 tabm-0.0.1.dev0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip -q install /kaggle/input/tabpfn-v2/tabpfn-2.0.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:16:18.779590Z","iopub.execute_input":"2025-03-04T18:16:18.779882Z","iopub.status.idle":"2025-03-04T18:16:22.434027Z","shell.execute_reply.started":"2025-03-04T18:16:18.779853Z","shell.execute_reply":"2025-03-04T18:16:22.433032Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Step 1 : Installations","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.stats import rankdata \n\nimport sys\nsys.path.append('/kaggle/input/tabm-tabular-dl-library')\n\nimport os\nimport tabm\nimport math\nimport torch\nimport random\nimport warnings\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport rtdl_num_embeddings\nimport matplotlib.pyplot as plt\nfrom typing import Optional, Tuple\nfrom sklearn.model_selection import KFold\nfrom scipy.stats import rankdata \n#from colorama import Fore, Style\nfrom typing import Optional, Tuple\nfrom numpy.typing import ArrayLike\nfrom sklearn.base import BaseEstimator\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import KFold\nfrom tabm_reference import Model, make_parameter_groups\nfrom sklearn.preprocessing import OrdinalEncoder, QuantileTransformer\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Embedding\nfrom tensorflow.keras.layers import Concatenate, BatchNormalization\nimport tensorflow.keras.backend as K\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom tabpfn import TabPFNRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:16:28.777069Z","iopub.execute_input":"2025-03-04T18:16:28.777396Z","iopub.status.idle":"2025-03-04T18:17:11.584233Z","shell.execute_reply.started":"2025-03-04T18:16:28.777363Z","shell.execute_reply":"2025-03-04T18:17:11.582406Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1741112218.503610      10 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0304 18:16:58.512343026      10 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0304 18:16:58.512360373      10 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0304 18:16:58.512363610      10 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0304 18:16:58.512365972      10 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0304 18:16:58.512368355      10 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0304 18:16:58.512370672      10 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0304 18:16:58.512372998      10 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0304 18:16:58.512375244      10 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0304 18:16:58.512377470      10 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0304 18:16:58.512379674      10 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0304 18:16:58.512381954      10 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0304 18:16:58.512384209      10 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0304 18:16:58.512386437      10 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0304 18:16:58.512388644      10 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0304 18:16:58.512390849      10 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0304 18:16:58.512393081      10 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0304 18:16:58.512395424      10 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0304 18:16:58.512397652      10 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0304 18:16:58.512399912      10 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0304 18:16:58.512402188      10 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0304 18:16:58.512404405      10 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0304 18:16:58.512406632      10 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0304 18:16:58.512408962      10 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0304 18:16:58.512411209      10 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0304 18:16:58.512413369      10 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0304 18:16:58.512415545      10 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0304 18:16:58.512417804      10 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0304 18:16:58.512420059      10 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0304 18:16:58.512422394      10 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0304 18:16:58.512425685      10 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0304 18:16:58.512428114      10 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0304 18:16:58.512430447      10 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0304 18:16:58.512432782      10 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0304 18:16:58.512435009      10 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0304 18:16:58.512437275      10 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0304 18:16:58.512439485      10 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0304 18:16:58.512441638      10 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0304 18:16:58.512443835      10 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0304 18:16:58.512446107      10 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0304 18:16:58.512448345      10 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0304 18:16:58.512450534      10 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0304 18:16:58.512452694      10 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0304 18:16:58.512454912      10 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0304 18:16:58.512457172      10 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0304 18:16:58.512459446      10 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0304 18:16:58.512637360      10 ev_epoll1_linux.cc:123]               grpc epoll fd: 66\nD0304 18:16:58.512649732      10 ev_posix.cc:113]                      Using polling engine: epoll1\nD0304 18:16:58.522949518      10 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0304 18:16:58.522959591      10 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0304 18:16:58.522967345      10 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0304 18:16:58.522970445      10 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0304 18:16:58.522973438      10 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0304 18:16:58.522976395      10 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0304 18:16:58.523004310      10 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0304 18:16:58.523016407      10 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0304 18:16:58.523031940      10 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0304 18:16:58.523061848      10 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0304 18:16:58.523069237      10 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0304 18:16:58.523072760      10 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0304 18:16:58.523076723      10 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0304 18:16:58.523079822      10 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0304 18:16:58.523082750      10 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0304 18:16:58.523085812      10 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0304 18:16:58.523114574      10 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0304 18:16:58.524885658      10 ev_epoll1_linux.cc:359]               grpc epoll fd: 68\nI0304 18:16:58.526105661      10 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0304 18:16:58.534949188     339 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0304 18:16:58.535018937     339 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0304 18:16:58.544416370      10 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2025-03-04T18:16:58.544400649+00:00\"}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Step 2: Experiments Paths  to add in ensemble","metadata":{}},{"cell_type":"code","source":"experiments = [\n\"/kaggle/input/xgboost-exp-01\",\n\"/kaggle/input/catboost-exp-01\", \n\"/kaggle/input/lgbm-exp-01\",\n\"/kaggle/input/xgboost-exp-02\",\n\"/kaggle/input/catboost-exp-02\",\n\"/kaggle/input/lgbm-exp-03\",\n\"/kaggle/input/catboost-exp-03\",\n\"/kaggle/input/tabm-exp-01\",\n\"/kaggle/input/nn-exp-01\",\n\"/kaggle/input/tn-exp-01\",\n\"/kaggle/input/tf-exp-01\",\n\"/kaggle/input/svr-exp-01\",\n\"/kaggle/input/abd-exp-01\",\n\"/kaggle/input/catboost-exp-04\",\n\"/kaggle/input/lgbm-exp-04\",\n\"/kaggle/input/tabm-exp-02\",\n\"/kaggle/input/ds-exp-01\",\n\"/kaggle/input/nn-exp-02\",\n\"/kaggle/input/nn-exp-04\",\n\"/kaggle/input/catboost-exp-05\",\n\"/kaggle/input/xgboost-exp-05\",\n\"/kaggle/input/lgbm-exp-05\",\n\"/kaggle/input/tn-exp-02\",\n\"/kaggle/input/vr-exp-01\",\n\"/kaggle/input/tt-exp-01\",\n\"/kaggle/input/en-exp-01\",\n\"/kaggle/input/en-exp-02\",\n\"/kaggle/input/nn-exp-05\",\n\"/kaggle/input/rf-exp-05\",\n\"/kaggle/input/mcts-exp-02\",\n\"/kaggle/input/catboost-exp-06\",\n\"/kaggle/input/xgboost-exp-06\",\n\"/kaggle/input/lgbm-exp-06\",\n\"/kaggle/input/nn-exp-06\",\n\"/kaggle/input/xgboost-exp-07\",\n\"/kaggle/input/ri-exp-01\",\n\"/kaggle/input/xgboost-exp-08\",\n\"/kaggle/input/catboost-exp-08\",\n\"/kaggle/input/lgbm-exp-08\",\n\"/kaggle/input/xgboost-exp-09\",\n\"/kaggle/input/prlnn-exp-01\",\n\"/kaggle/input/ri-exp-06\",\n\"/kaggle/input/xgboost-exp-10\",\n\"/kaggle/input/lasso-exp-01\",\n\"/kaggle/input/lir-exp-01\",\n\"/kaggle/input/svr-exp-06\",\n\"/kaggle/input/et-exp-01\",\n\"/kaggle/input/lasso-exp-02\",\n\"/kaggle/input/pr-exp-06\",\n\"/kaggle/input/tr-exp-06\",\n\"/kaggle/input/lasso-exp-06\",\n\"/kaggle/input/ransac-exp-01\",\n\"/kaggle/input/cnn-exp-01\",\n\"/kaggle/input/ts-exp-01\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:20.304230Z","iopub.execute_input":"2025-03-04T18:17:20.305125Z","iopub.status.idle":"2025-03-04T18:17:20.311811Z","shell.execute_reply.started":"2025-03-04T18:17:20.305070Z","shell.execute_reply":"2025-03-04T18:17:20.310155Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Step 3 : Competition metric","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport pandas.api.types\nimport numpy as np\nfrom lifelines.utils import concordance_index\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n    \n    event_label = 'efs'\n    interval_label = 'efs_time'\n    prediction_label = 'predictions'\n    for col in submission.columns:\n        if not pandas.api.types.is_numeric_dtype(submission[col]):\n            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n    # Merging solution and submission dfs on ID\n    merged_df = pd.concat([solution, submission], axis=1)\n    merged_df.reset_index(inplace=True)\n    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n    metric_list = []\n\n    for race in merged_df_race_dict.keys():\n        # Retrieving values from y_test based on index\n        indices = sorted(merged_df_race_dict[race])\n        merged_df_race = merged_df.iloc[indices]\n        # Calculate the concordance index\n        c_index_race = concordance_index(\n                        merged_df_race[interval_label],\n                        -merged_df_race[prediction_label],\n                        merged_df_race[event_label])\n        metric_list.append(c_index_race)\n    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:24.989435Z","iopub.execute_input":"2025-03-04T18:17:24.989853Z","iopub.status.idle":"2025-03-04T18:17:25.067703Z","shell.execute_reply.started":"2025-03-04T18:17:24.989819Z","shell.execute_reply":"2025-03-04T18:17:25.066446Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Step 4: Find best model ","metadata":{}},{"cell_type":"code","source":"parquet_experiments = [\n    \"/kaggle/input/abd-exp-01\",\n    \"/kaggle/input/lgbm-exp-04\", \n    \"/kaggle/input/catboost-exp-01\", \n    \"/kaggle/input/lgbm-exp-01\", \n    \"/kaggle/input/lgbm-exp-03\", \n    \"/kaggle/input/ds-exp-01\",\n    \"/kaggle/input/nn-exp-02\",\n    \"/kaggle/input/nn-exp-04\",\n    \"/kaggle/input/tabm-exp-03\",\n    \"/kaggle/input/catboost-exp-05\",\n    \"/kaggle/input/xgboost-exp-05\",\n    \"/kaggle/input/lgbm-exp-05\",\n    \"/kaggle/input/tn-exp-02\",\n    \"/kaggle/input/vr-exp-01\",\n    \"/kaggle/input/tt-exp-01\",\n    \"/kaggle/input/en-exp-01\",\n    \"/kaggle/input/svr-exp-01\",\n    \"/kaggle/input/en-exp-02\",\n    \"/kaggle/input/nn-exp-05\",\n    \"/kaggle/input/rf-exp-05\",\n    \"/kaggle/input/mcts-exp-02\",\n    \"/kaggle/input/catboost-exp-06\",\n    \"/kaggle/input/xgboost-exp-06\",\n    \"/kaggle/input/lgbm-exp-06\",\n    \"/kaggle/input/nn-exp-06\",\n    \"/kaggle/input/xgboost-exp-07\",\n    \"/kaggle/input/ri-exp-01\",\n    \"/kaggle/input/xgboost-exp-08\",\n    \"/kaggle/input/catboost-exp-08\",\n    \"/kaggle/input/lgbm-exp-08\",\n    \"/kaggle/input/xgboost-exp-09\",\n    \"/kaggle/input/prlnn-exp-01\",\n    \"/kaggle/input/ri-exp-06\",\n    \"/kaggle/input/xgboost-exp-10\",\n    \"/kaggle/input/lasso-exp-01\",\n    \"/kaggle/input/lir-exp-01\",\n    \"/kaggle/input/svr-exp-06\",\n    \"/kaggle/input/et-exp-01\",\n    \"/kaggle/input/lasso-exp-02\",\n    \"/kaggle/input/pr-exp-06\",\n    \"/kaggle/input/tr-exp-06\",\n    \"/kaggle/input/lasso-exp-06\",\n    \"/kaggle/input/ransac-exp-01\",\n    \"/kaggle/input/cnn-exp-01\",\n    \"/kaggle/input/ts-exp-01\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:30.517324Z","iopub.execute_input":"2025-03-04T18:17:30.517790Z","iopub.status.idle":"2025-03-04T18:17:30.523661Z","shell.execute_reply.started":"2025-03-04T18:17:30.517752Z","shell.execute_reply":"2025-03-04T18:17:30.522329Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def compute_metric_cindex(oof, exp_name, fast=False):    \n    if fast:\n        y_true = oof[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n        y_pred = oof[[\"ID\",\"predictions\"]].copy()\n        return optimized_score(y_true.copy(), y_pred.copy(), \"ID\"), oof\n    else:\n        y_true = oof[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n        y_pred = oof[[\"ID\",\"predictions\"]].copy()\n        return score(y_true.copy(), y_pred.copy(), \"ID\"), oof","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:36.064944Z","iopub.execute_input":"2025-03-04T18:17:36.065364Z","iopub.status.idle":"2025-03-04T18:17:36.070954Z","shell.execute_reply.started":"2025-03-04T18:17:36.065331Z","shell.execute_reply":"2025-03-04T18:17:36.069668Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"pip install openpyxl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:37.460239Z","iopub.execute_input":"2025-03-04T18:17:37.460627Z","iopub.status.idle":"2025-03-04T18:17:41.478672Z","shell.execute_reply.started":"2025-03-04T18:17:37.460583Z","shell.execute_reply":"2025-03-04T18:17:41.477288Z"}},"outputs":[{"name":"stdout","text":"Collecting openpyxl\n  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting et-xmlfile\n  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\nInstalling collected packages: et-xmlfile, openpyxl\nSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%time\n\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nfrom typing import List, Dict, Tuple\nimport logging\nimport gc\nfrom scipy.stats import rankdata\nfrom lifelines.utils import concordance_index\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\n\ndef fast_concordance_index(event_times, predicted_scores, event_observed):\n    \"\"\"Faster implementation of concordance index using NumPy operations\"\"\"\n    # Convert to numpy arrays for faster operations\n    event_times = np.asarray(event_times)\n    predicted_scores = np.asarray(predicted_scores)\n    event_observed = np.asarray(event_observed)\n    \n    # Only consider pairs where at least one has an event\n    mask = event_observed == 1\n    \n    if not np.any(mask):\n        return 0.0\n    \n    # Get indices of samples with events\n    event_indices = np.where(mask)[0]\n    \n    # Initialize counters\n    concordant = 0\n    discordant = 0\n    tied_risk = 0\n    pairs = 0\n\n    # For each sample with an event\n    for i in event_indices:\n        # Find all samples with longer survival time\n        longer_survival = event_times > event_times[i]\n        \n        # For samples with same survival time, only consider if they didn't have an event\n        same_survival = (event_times == event_times[i]) & (event_observed == 0)\n        \n        # Combine masks\n        comparable = longer_survival | same_survival\n        \n        if not np.any(comparable):\n            continue\n        \n        # Get predictions for comparable samples\n        comp_scores = predicted_scores[comparable]\n        current_score = predicted_scores[i]\n        \n        # Count concordant, discordant, and tied pairs\n        concordant += np.sum(comp_scores < current_score)\n        discordant += np.sum(comp_scores > current_score)\n        tied_risk += np.sum(comp_scores == current_score)\n        \n        # Update total pairs count\n        pairs += np.sum(comparable)\n    \n    if pairs == 0:\n        return 0.0\n    \n    return (concordant + 0.5 * tied_risk) / pairs\n\n\ndef optimized_score(solution_data, submission_data, row_id_column_name=None):\n    \"\"\"Optimized scoring function using NumPy operations\"\"\"\n    if row_id_column_name:\n        # Extract necessary columns and convert to NumPy arrays\n        event = solution_data['efs'].values\n        time = solution_data['efs_time'].values\n        race_groups = solution_data['race_group'].values\n        predictions = submission_data['predictions'].values\n    else:\n        # Assume data is already in the right format\n        event = solution_data[:, 0]  # efs\n        time = solution_data[:, 1]   # efs_time\n        race_groups = solution_data[:, 2]  # race_group\n        predictions = submission_data  # predictions\n    \n    # Get unique race groups\n    unique_races = np.unique(race_groups)\n    c_indices = []\n    \n    # Calculate c-index for each race group\n    for race in unique_races:\n        mask = race_groups == race\n        \n        # Use lifelines concordance_index for correctness\n        c_index_race = concordance_index(\n            time[mask],\n            -predictions[mask],\n            event[mask]\n        )\n        c_indices.append(c_index_race)\n    \n    c_indices = np.array(c_indices)\n    return float(np.mean(c_indices) - np.sqrt(np.var(c_indices)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:45.724939Z","iopub.execute_input":"2025-03-04T18:17:45.725492Z","iopub.status.idle":"2025-03-04T18:17:45.739218Z","shell.execute_reply.started":"2025-03-04T18:17:45.725424Z","shell.execute_reply":"2025-03-04T18:17:45.737826Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 167 μs, sys: 0 ns, total: 167 μs\nWall time: 173 μs\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"multiprocessing.cpu_count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:49.626524Z","iopub.execute_input":"2025-03-04T18:17:49.626929Z","iopub.status.idle":"2025-03-04T18:17:49.635454Z","shell.execute_reply.started":"2025-03-04T18:17:49.626898Z","shell.execute_reply":"2025-03-04T18:17:49.634024Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"96"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from tqdm import tqdm\nimport pandas as pd\n\n# Initialize empty list to store individual prediction dataframes\ndfs_to_merge = []\n\n# Load first experiment to get the base structure\nbase_exp = experiments[0]\nif base_exp in parquet_experiments:\n    base_df = pd.read_parquet(base_exp + '/' + (base_exp.split('/')[-1]).replace('-','_') + '_oof.parquet')\nelse:\n    base_df = pd.read_excel(base_exp + '/' + (base_exp.split('/')[-1]).replace('-','_') + '_oof.xlsx')\n\n# Create base dataframe with ID and target variables\npreds_df = base_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n\n# Load and merge predictions from each experiment\nfor exp_name in tqdm(experiments):\n    # Read the prediction file\n    if exp_name in parquet_experiments:\n        if \"mcts-exp-02\" in exp_name:\n            curr_df = pd.read_parquet(exp_name + '/mcts_exp_01' + '_oof.parquet')\n        elif \"ts-exp-01\" in exp_name:\n            prev_df = pd.read_parquet(\"/kaggle/input/cnn-exp-01/cnn_exp_01_oof.parquet\")\n            curr_df = pd.read_parquet(\"/kaggle/input/ts-exp-01/ts_exp_01_oof.parquet\")\n            curr_df[\"ID\"] = prev_df[\"ID\"]\n        else:\n            curr_df = pd.read_parquet(exp_name + '/' + (exp_name.split('/')[-1]).replace('-','_') + '_oof.parquet')\n    else:\n        curr_df = pd.read_excel(exp_name + '/' + (exp_name.split('/')[-1]).replace('-','_') + '_oof.xlsx')\n    \n    # Create a temporary dataframe with ID and predictions\n    temp_df = curr_df[[\"ID\", \"predictions\"]].copy()\n    temp_df = temp_df.rename(columns={\"predictions\": exp_name})\n    \n    # Merge with the main dataframe\n    preds_df = preds_df.merge(temp_df, on=\"ID\", how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:55.988647Z","iopub.execute_input":"2025-03-04T18:17:55.989020Z","iopub.status.idle":"2025-03-04T18:21:58.831797Z","shell.execute_reply.started":"2025-03-04T18:17:55.988992Z","shell.execute_reply":"2025-03-04T18:21:58.830603Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 54/54 [03:41<00:00,  4.11s/it]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"preds_df.shape, preds_df.columns ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:07.023540Z","iopub.execute_input":"2025-03-04T18:22:07.023989Z","iopub.status.idle":"2025-03-04T18:22:07.030545Z","shell.execute_reply.started":"2025-03-04T18:22:07.023949Z","shell.execute_reply":"2025-03-04T18:22:07.029235Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((28800, 58),\n Index(['ID', 'efs', 'efs_time', 'race_group', '/kaggle/input/xgboost-exp-01',\n        '/kaggle/input/catboost-exp-01', '/kaggle/input/lgbm-exp-01',\n        '/kaggle/input/xgboost-exp-02', '/kaggle/input/catboost-exp-02',\n        '/kaggle/input/lgbm-exp-03', '/kaggle/input/catboost-exp-03',\n        '/kaggle/input/tabm-exp-01', '/kaggle/input/nn-exp-01',\n        '/kaggle/input/tn-exp-01', '/kaggle/input/tf-exp-01',\n        '/kaggle/input/svr-exp-01', '/kaggle/input/abd-exp-01',\n        '/kaggle/input/catboost-exp-04', '/kaggle/input/lgbm-exp-04',\n        '/kaggle/input/tabm-exp-02', '/kaggle/input/ds-exp-01',\n        '/kaggle/input/nn-exp-02', '/kaggle/input/nn-exp-04',\n        '/kaggle/input/catboost-exp-05', '/kaggle/input/xgboost-exp-05',\n        '/kaggle/input/lgbm-exp-05', '/kaggle/input/tn-exp-02',\n        '/kaggle/input/vr-exp-01', '/kaggle/input/tt-exp-01',\n        '/kaggle/input/en-exp-01', '/kaggle/input/en-exp-02',\n        '/kaggle/input/nn-exp-05', '/kaggle/input/rf-exp-05',\n        '/kaggle/input/mcts-exp-02', '/kaggle/input/catboost-exp-06',\n        '/kaggle/input/xgboost-exp-06', '/kaggle/input/lgbm-exp-06',\n        '/kaggle/input/nn-exp-06', '/kaggle/input/xgboost-exp-07',\n        '/kaggle/input/ri-exp-01', '/kaggle/input/xgboost-exp-08',\n        '/kaggle/input/catboost-exp-08', '/kaggle/input/lgbm-exp-08',\n        '/kaggle/input/xgboost-exp-09', '/kaggle/input/prlnn-exp-01',\n        '/kaggle/input/ri-exp-06', '/kaggle/input/xgboost-exp-10',\n        '/kaggle/input/lasso-exp-01', '/kaggle/input/lir-exp-01',\n        '/kaggle/input/svr-exp-06', '/kaggle/input/et-exp-01',\n        '/kaggle/input/lasso-exp-02', '/kaggle/input/pr-exp-06',\n        '/kaggle/input/tr-exp-06', '/kaggle/input/lasso-exp-06',\n        '/kaggle/input/ransac-exp-01', '/kaggle/input/cnn-exp-01',\n        '/kaggle/input/ts-exp-01'],\n       dtype='object'))"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"len(experiments)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:09.524968Z","iopub.execute_input":"2025-03-04T18:22:09.525346Z","iopub.status.idle":"2025-03-04T18:22:09.530733Z","shell.execute_reply.started":"2025-03-04T18:22:09.525318Z","shell.execute_reply":"2025-03-04T18:22:09.529570Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"54"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"best_score    = 0\nbest_index    = -1\nbest_ensemble = 0\n\nfor k,name in enumerate(experiments):\n    oof_pre = preds_df[[\"ID\",\"efs\",\"efs_time\",\"race_group\",name]]\n    oof_pre = oof_pre.rename(columns={name: \"predictions\"})\n    s, oof = compute_metric_cindex(oof_pre, name, fast=True)\n    if s > best_score:\n        best_score    = s\n        best_index    = name\n        best_ensemble = oof\n        \n    print(f'C-index {s} {name}') \nprint()\nprint(f'Best single model is {best_index} with C-Index = {best_score}')\nexperiments.remove(best_index)\nfirst_best_index = best_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:09.786273Z","iopub.execute_input":"2025-03-04T18:22:09.786636Z","iopub.status.idle":"2025-03-04T18:22:27.417214Z","shell.execute_reply.started":"2025-03-04T18:22:09.786593Z","shell.execute_reply":"2025-03-04T18:22:27.416118Z"}},"outputs":[{"name":"stdout","text":"C-index 0.6743662038463064 /kaggle/input/xgboost-exp-01\nC-index 0.673797469068503 /kaggle/input/catboost-exp-01\nC-index 0.6735659109490936 /kaggle/input/lgbm-exp-01\nC-index 0.6719739976829171 /kaggle/input/xgboost-exp-02\nC-index 0.6715438291634074 /kaggle/input/catboost-exp-02\nC-index 0.6744113273004797 /kaggle/input/lgbm-exp-03\nC-index 0.6750446351219317 /kaggle/input/catboost-exp-03\nC-index 0.6698445972872783 /kaggle/input/tabm-exp-01\nC-index 0.6672504731273489 /kaggle/input/nn-exp-01\nC-index 0.6082304286386713 /kaggle/input/tn-exp-01\nC-index 0.6609386133349129 /kaggle/input/tf-exp-01\nC-index 0.6204664346764159 /kaggle/input/svr-exp-01\nC-index 0.6775546112659996 /kaggle/input/abd-exp-01\nC-index 0.6228381497451487 /kaggle/input/catboost-exp-04\nC-index 0.6216961934710434 /kaggle/input/lgbm-exp-04\nC-index 0.6777472728532595 /kaggle/input/tabm-exp-02\nC-index 0.6427991982766068 /kaggle/input/ds-exp-01\nC-index 0.6541867987232884 /kaggle/input/nn-exp-02\nC-index 0.6794831551153862 /kaggle/input/nn-exp-04\nC-index 0.680734863930053 /kaggle/input/catboost-exp-05\nC-index 0.6801801958617659 /kaggle/input/xgboost-exp-05\nC-index 0.6791851357350963 /kaggle/input/lgbm-exp-05\nC-index 0.659742829229569 /kaggle/input/tn-exp-02\nC-index 0.6754542289908226 /kaggle/input/vr-exp-01\nC-index 0.6051212359506114 /kaggle/input/tt-exp-01\nC-index 0.6244728416862964 /kaggle/input/en-exp-01\nC-index 0.6417663206377346 /kaggle/input/en-exp-02\nC-index 0.6794831551153862 /kaggle/input/nn-exp-05\nC-index 0.6511582598647447 /kaggle/input/rf-exp-05\nC-index 0.6113856489762708 /kaggle/input/mcts-exp-02\nC-index 0.6805225213899068 /kaggle/input/catboost-exp-06\nC-index 0.6795077628167032 /kaggle/input/xgboost-exp-06\nC-index 0.6791063706461627 /kaggle/input/lgbm-exp-06\nC-index 0.6804090466531342 /kaggle/input/nn-exp-06\nC-index 0.6797980742985197 /kaggle/input/xgboost-exp-07\nC-index 0.6241849482559193 /kaggle/input/ri-exp-01\nC-index 0.6798723688263519 /kaggle/input/xgboost-exp-08\nC-index 0.6785727820807782 /kaggle/input/catboost-exp-08\nC-index 0.6786178926206528 /kaggle/input/lgbm-exp-08\nC-index 0.681724483438663 /kaggle/input/xgboost-exp-09\nC-index 0.6817974276309455 /kaggle/input/prlnn-exp-01\nC-index 0.6356258684894599 /kaggle/input/ri-exp-06\nC-index 0.6816452214688579 /kaggle/input/xgboost-exp-10\nC-index 0.48930453274500724 /kaggle/input/lasso-exp-01\nC-index 0.6239428862824246 /kaggle/input/lir-exp-01\nC-index 0.6488602845403236 /kaggle/input/svr-exp-06\nC-index 0.6392423245703106 /kaggle/input/et-exp-01\nC-index 0.6229596041054568 /kaggle/input/lasso-exp-02\nC-index 0.6202197572441672 /kaggle/input/pr-exp-06\nC-index 0.6356244704999544 /kaggle/input/tr-exp-06\nC-index 0.6349722139900572 /kaggle/input/lasso-exp-06\nC-index 0.6240434159920552 /kaggle/input/ransac-exp-01\nC-index 0.6250480614268742 /kaggle/input/cnn-exp-01\nC-index 0.6481408047652605 /kaggle/input/ts-exp-01\n\nBest single model is /kaggle/input/prlnn-exp-01 with C-Index = 0.6817974276309455\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"experiments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:32.335941Z","iopub.execute_input":"2025-03-04T18:22:32.336332Z","iopub.status.idle":"2025-03-04T18:22:32.342467Z","shell.execute_reply.started":"2025-03-04T18:22:32.336299Z","shell.execute_reply":"2025-03-04T18:22:32.341353Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/xgboost-exp-01',\n '/kaggle/input/catboost-exp-01',\n '/kaggle/input/lgbm-exp-01',\n '/kaggle/input/xgboost-exp-02',\n '/kaggle/input/catboost-exp-02',\n '/kaggle/input/lgbm-exp-03',\n '/kaggle/input/catboost-exp-03',\n '/kaggle/input/tabm-exp-01',\n '/kaggle/input/nn-exp-01',\n '/kaggle/input/tn-exp-01',\n '/kaggle/input/tf-exp-01',\n '/kaggle/input/svr-exp-01',\n '/kaggle/input/abd-exp-01',\n '/kaggle/input/catboost-exp-04',\n '/kaggle/input/lgbm-exp-04',\n '/kaggle/input/tabm-exp-02',\n '/kaggle/input/ds-exp-01',\n '/kaggle/input/nn-exp-02',\n '/kaggle/input/nn-exp-04',\n '/kaggle/input/catboost-exp-05',\n '/kaggle/input/xgboost-exp-05',\n '/kaggle/input/lgbm-exp-05',\n '/kaggle/input/tn-exp-02',\n '/kaggle/input/vr-exp-01',\n '/kaggle/input/tt-exp-01',\n '/kaggle/input/en-exp-01',\n '/kaggle/input/en-exp-02',\n '/kaggle/input/nn-exp-05',\n '/kaggle/input/rf-exp-05',\n '/kaggle/input/mcts-exp-02',\n '/kaggle/input/catboost-exp-06',\n '/kaggle/input/xgboost-exp-06',\n '/kaggle/input/lgbm-exp-06',\n '/kaggle/input/nn-exp-06',\n '/kaggle/input/xgboost-exp-07',\n '/kaggle/input/ri-exp-01',\n '/kaggle/input/xgboost-exp-08',\n '/kaggle/input/catboost-exp-08',\n '/kaggle/input/lgbm-exp-08',\n '/kaggle/input/xgboost-exp-09',\n '/kaggle/input/ri-exp-06',\n '/kaggle/input/xgboost-exp-10',\n '/kaggle/input/lasso-exp-01',\n '/kaggle/input/lir-exp-01',\n '/kaggle/input/svr-exp-06',\n '/kaggle/input/et-exp-01',\n '/kaggle/input/lasso-exp-02',\n '/kaggle/input/pr-exp-06',\n '/kaggle/input/tr-exp-06',\n '/kaggle/input/lasso-exp-06',\n '/kaggle/input/ransac-exp-01',\n '/kaggle/input/cnn-exp-01',\n '/kaggle/input/ts-exp-01']"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## Step 5: Iterations for hill climbing","metadata":{}},{"cell_type":"code","source":"USE_NEGATIVE_WGT = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:34.806308Z","iopub.execute_input":"2025-03-04T18:22:34.806699Z","iopub.status.idle":"2025-03-04T18:22:34.810666Z","shell.execute_reply.started":"2025-03-04T18:22:34.806669Z","shell.execute_reply":"2025-03-04T18:22:34.809496Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"indices        = [best_index]\nold_best_score = best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:35.032269Z","iopub.execute_input":"2025-03-04T18:22:35.032709Z","iopub.status.idle":"2025-03-04T18:22:35.036669Z","shell.execute_reply.started":"2025-03-04T18:22:35.032675Z","shell.execute_reply":"2025-03-04T18:22:35.035704Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# PREPARE/MOVE VARIABLES TO GPU FOR SPEED UP\nbest_ensemble = best_ensemble\nstart         = -0.50\nif not USE_NEGATIVE_WGT: start = 0.01\nww            = np.arange(start,0.51,0.01) # GPU\nnn            = len(ww)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:35.262344Z","iopub.execute_input":"2025-03-04T18:22:35.262786Z","iopub.status.idle":"2025-03-04T18:22:35.267731Z","shell.execute_reply.started":"2025-03-04T18:22:35.262752Z","shell.execute_reply":"2025-03-04T18:22:35.266396Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# BEGIN HILL CLIMBING\nmodels  = [best_index]\nweights = []\nmetrics = [best_score]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:37.484825Z","iopub.execute_input":"2025-03-04T18:22:37.485246Z","iopub.status.idle":"2025-03-04T18:22:37.489312Z","shell.execute_reply.started":"2025-03-04T18:22:37.485217Z","shell.execute_reply":"2025-03-04T18:22:37.488326Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"models, metrics, ww","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:38.131180Z","iopub.execute_input":"2025-03-04T18:22:38.131554Z","iopub.status.idle":"2025-03-04T18:22:38.138920Z","shell.execute_reply.started":"2025-03-04T18:22:38.131522Z","shell.execute_reply":"2025-03-04T18:22:38.137404Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(['/kaggle/input/prlnn-exp-01'],\n [0.6817974276309455],\n array([-5.0000000e-01, -4.9000000e-01, -4.8000000e-01, -4.7000000e-01,\n        -4.6000000e-01, -4.5000000e-01, -4.4000000e-01, -4.3000000e-01,\n        -4.2000000e-01, -4.1000000e-01, -4.0000000e-01, -3.9000000e-01,\n        -3.8000000e-01, -3.7000000e-01, -3.6000000e-01, -3.5000000e-01,\n        -3.4000000e-01, -3.3000000e-01, -3.2000000e-01, -3.1000000e-01,\n        -3.0000000e-01, -2.9000000e-01, -2.8000000e-01, -2.7000000e-01,\n        -2.6000000e-01, -2.5000000e-01, -2.4000000e-01, -2.3000000e-01,\n        -2.2000000e-01, -2.1000000e-01, -2.0000000e-01, -1.9000000e-01,\n        -1.8000000e-01, -1.7000000e-01, -1.6000000e-01, -1.5000000e-01,\n        -1.4000000e-01, -1.3000000e-01, -1.2000000e-01, -1.1000000e-01,\n        -1.0000000e-01, -9.0000000e-02, -8.0000000e-02, -7.0000000e-02,\n        -6.0000000e-02, -5.0000000e-02, -4.0000000e-02, -3.0000000e-02,\n        -2.0000000e-02, -1.0000000e-02,  4.4408921e-16,  1.0000000e-02,\n         2.0000000e-02,  3.0000000e-02,  4.0000000e-02,  5.0000000e-02,\n         6.0000000e-02,  7.0000000e-02,  8.0000000e-02,  9.0000000e-02,\n         1.0000000e-01,  1.1000000e-01,  1.2000000e-01,  1.3000000e-01,\n         1.4000000e-01,  1.5000000e-01,  1.6000000e-01,  1.7000000e-01,\n         1.8000000e-01,  1.9000000e-01,  2.0000000e-01,  2.1000000e-01,\n         2.2000000e-01,  2.3000000e-01,  2.4000000e-01,  2.5000000e-01,\n         2.6000000e-01,  2.7000000e-01,  2.8000000e-01,  2.9000000e-01,\n         3.0000000e-01,  3.1000000e-01,  3.2000000e-01,  3.3000000e-01,\n         3.4000000e-01,  3.5000000e-01,  3.6000000e-01,  3.7000000e-01,\n         3.8000000e-01,  3.9000000e-01,  4.0000000e-01,  4.1000000e-01,\n         4.2000000e-01,  4.3000000e-01,  4.4000000e-01,  4.5000000e-01,\n         4.6000000e-01,  4.7000000e-01,  4.8000000e-01,  4.9000000e-01,\n         5.0000000e-01]))"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def evaluate_weight(args):\n    \"\"\"Function to evaluate a single weight for a model - designed for parallel execution\"\"\"\n    weight, best_preds, model_oof, solution_data = args\n    \n    # Create potential ensemble using NumPy operations\n    best_ranks = rankdata(best_preds)\n    model_ranks = rankdata(model_oof)\n    potential_ensemble = (1 - weight) * best_ranks + weight * model_ranks\n    \n    # Calculate score\n    new_score = optimized_score(solution_data, potential_ensemble)\n    \n    return weight, new_score\n\ndef optimize_ensemble(experiments, initial_ensemble, weights_range, score_function, max_iterations=100):\n    # Convert initial ensemble to NumPy arrays for faster processing\n    ids = initial_ensemble[\"ID\"].values\n    initial_preds = initial_ensemble[\"predictions\"].values\n    \n    # Prepare solution data as NumPy array\n    solution_data = np.column_stack((\n        preds_df[\"efs\"].values,\n        preds_df[\"efs_time\"].values,\n        preds_df[\"race_group\"].values\n    ))\n    \n    # Initialize variables\n    iteration = 0\n    best_score = score_function(\n        solution_data,\n        initial_preds,\n        None\n    )\n    \n    model_weights = {}\n    remaining_experiments = experiments.copy()\n    best_preds = initial_preds.copy()\n    \n    # Get number of CPU cores for parallel processing\n    num_cores = max(1, multiprocessing.cpu_count() - 1)\n    \n    while remaining_experiments and iteration < max_iterations:\n        print(f\"{iteration}th iteration\")\n        iteration += 1\n        best_iteration = {\n            'index': -1,\n            'weight': 0,\n            'score': best_score\n        }\n        \n        # Try each remaining model\n        for model_path in remaining_experiments:\n            try:\n                # Load model OOF predictions\n                model_name = model_path.split(\"/\")[-1].replace('-', '_')\n                model_oof = preds_df[model_path].values\n                \n                # Prepare arguments for parallel processing\n                args_list = [(weight, best_preds, model_oof, solution_data) \n                             for weight in weights_range]\n                \n                # Process weights in parallel\n                with ProcessPoolExecutor(max_workers=num_cores) as executor:\n                    futures = [executor.submit(evaluate_weight, args) for args in args_list]\n                    \n                    # Process results as they complete\n                    for future in tqdm(as_completed(futures), total=len(futures), \n                                      desc=f\"Testing weights for {model_name}\"):\n                        weight, new_score = future.result()\n                        \n                        # Update best if improved\n                        if new_score > best_iteration['score']:\n                            best_iteration.update({\n                                'index': model_path,\n                                'weight': weight,\n                                'score': new_score\n                            })\n                \n                # Clean up\n                del model_oof\n                gc.collect()\n                \n            except Exception as e:\n                print(f\"Error processing {model_path}: {str(e)}\")\n                continue\n        \n        # Check if we found an improvement\n        if best_iteration['index'] == -1:\n            print(\"No improvement found, stopping\")\n            print(best_iteration)\n            break\n            \n        # Update ensemble with best model found\n        best_score = best_iteration['score']\n        model_weights[best_iteration['index']] = best_iteration['weight']\n        remaining_experiments.remove(best_iteration['index'])\n        \n        print(\n            f\"Iteration {iteration}: Added {best_iteration['index']} \"\n            f\"with weight {best_iteration['weight']:.4f}, \"\n            f\"Score: {best_iteration['score']:.4f}\"\n        )\n        \n        # Update best ensemble for next iteration\n        model_oof = preds_df[best_iteration['index']].values\n        best_ranks = rankdata(best_preds)\n        model_ranks = rankdata(model_oof)\n        best_preds = (1 - best_iteration['weight']) * best_ranks + best_iteration['weight'] * model_ranks\n        \n    # Create final ensemble DataFrame for compatibility\n    final_ensemble = pd.DataFrame({\n        \"ID\": ids,\n        \"predictions\": best_preds\n    })\n    \n    return model_weights, best_score, final_ensemble\n\n# Run the optimized ensemble function\nmodel_weights, best_score, final_ensemble = optimize_ensemble(experiments, best_ensemble, ww, optimized_score)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:40.722575Z","iopub.execute_input":"2025-03-04T18:22:40.722972Z","execution_failed":"2025-03-04T18:37:29.484Z"}},"outputs":[{"name":"stdout","text":"0th iteration\n","output_type":"stream"},{"name":"stderr","text":"Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.21it/s] \nTesting weights for catboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 79.19it/s]\nTesting weights for lgbm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.87it/s]\nTesting weights for xgboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 82.62it/s]\nTesting weights for catboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 80.27it/s]\nTesting weights for lgbm_exp_03: 100%|██████████| 101/101 [00:01<00:00, 81.41it/s]\nTesting weights for catboost_exp_03: 100%|██████████| 101/101 [00:01<00:00, 83.66it/s] \nTesting weights for tabm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.08it/s]\nTesting weights for nn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.06it/s]\nTesting weights for tn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.27it/s] \nTesting weights for tf_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.11it/s]\nTesting weights for svr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 85.29it/s]\nTesting weights for abd_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.16it/s]\nTesting weights for catboost_exp_04: 100%|██████████| 101/101 [00:01<00:00, 81.02it/s]\nTesting weights for lgbm_exp_04: 100%|██████████| 101/101 [00:01<00:00, 83.07it/s]\nTesting weights for tabm_exp_02: 100%|██████████| 101/101 [00:01<00:00, 79.15it/s] \nTesting weights for ds_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.75it/s] \nTesting weights for nn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 80.33it/s]\nTesting weights for nn_exp_04: 100%|██████████| 101/101 [00:01<00:00, 83.58it/s]\nTesting weights for catboost_exp_05: 100%|██████████| 101/101 [00:01<00:00, 87.09it/s]\nTesting weights for xgboost_exp_05: 100%|██████████| 101/101 [00:01<00:00, 82.44it/s]\nTesting weights for lgbm_exp_05: 100%|██████████| 101/101 [00:01<00:00, 84.86it/s]\nTesting weights for tn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 80.67it/s]\nTesting weights for vr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 76.36it/s]\nTesting weights for tt_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.69it/s]\nTesting weights for en_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.54it/s]\nTesting weights for en_exp_02: 100%|██████████| 101/101 [00:01<00:00, 78.08it/s] \nTesting weights for nn_exp_05: 100%|██████████| 101/101 [00:01<00:00, 78.40it/s] \nTesting weights for rf_exp_05: 100%|██████████| 101/101 [00:01<00:00, 79.95it/s]\nTesting weights for mcts_exp_02: 100%|██████████| 101/101 [00:01<00:00, 79.14it/s]\nTesting weights for catboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 84.38it/s] \nTesting weights for xgboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 78.31it/s]\nTesting weights for lgbm_exp_06: 100%|██████████| 101/101 [00:01<00:00, 82.15it/s]\nTesting weights for nn_exp_06: 100%|██████████| 101/101 [00:01<00:00, 85.72it/s]\nTesting weights for xgboost_exp_07: 100%|██████████| 101/101 [00:01<00:00, 77.06it/s]\nTesting weights for ri_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.23it/s]\nTesting weights for xgboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 82.74it/s]\nTesting weights for catboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 77.04it/s]\nTesting weights for lgbm_exp_08: 100%|██████████| 101/101 [00:01<00:00, 83.07it/s]\nTesting weights for xgboost_exp_09: 100%|██████████| 101/101 [00:01<00:00, 78.97it/s]\nTesting weights for ri_exp_06: 100%|██████████| 101/101 [00:01<00:00, 84.55it/s]\nTesting weights for xgboost_exp_10: 100%|██████████| 101/101 [00:01<00:00, 82.62it/s]\nTesting weights for lasso_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.99it/s] \nTesting weights for lir_exp_01: 100%|██████████| 101/101 [00:01<00:00, 78.51it/s] \nTesting weights for svr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 83.77it/s]\nTesting weights for et_exp_01: 100%|██████████| 101/101 [00:01<00:00, 78.23it/s]\nTesting weights for lasso_exp_02: 100%|██████████| 101/101 [00:01<00:00, 85.39it/s]\nTesting weights for pr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 85.10it/s]\nTesting weights for tr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 83.78it/s]\nTesting weights for lasso_exp_06: 100%|██████████| 101/101 [00:01<00:00, 78.80it/s]\nTesting weights for ransac_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.72it/s]\nTesting weights for cnn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 77.00it/s]\nTesting weights for ts_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.42it/s] \n","output_type":"stream"},{"name":"stdout","text":"Iteration 1: Added /kaggle/input/catboost-exp-05 with weight 0.4800, Score: 0.6862\n1th iteration\n","output_type":"stream"},{"name":"stderr","text":"Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.10it/s]\nTesting weights for catboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.52it/s]\nTesting weights for lgbm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.50it/s]\nTesting weights for xgboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 83.96it/s]\nTesting weights for catboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 79.96it/s]\nTesting weights for lgbm_exp_03: 100%|██████████| 101/101 [00:01<00:00, 84.29it/s]\nTesting weights for catboost_exp_03: 100%|██████████| 101/101 [00:01<00:00, 81.32it/s]\nTesting weights for tabm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 86.53it/s]\nTesting weights for nn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.17it/s]\nTesting weights for tn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.92it/s]\nTesting weights for tf_exp_01: 100%|██████████| 101/101 [00:01<00:00, 85.96it/s]\nTesting weights for svr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.05it/s]\nTesting weights for abd_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.02it/s] \nTesting weights for catboost_exp_04: 100%|██████████| 101/101 [00:01<00:00, 84.30it/s]\nTesting weights for lgbm_exp_04: 100%|██████████| 101/101 [00:01<00:00, 82.53it/s]\nTesting weights for tabm_exp_02: 100%|██████████| 101/101 [00:01<00:00, 84.93it/s]\nTesting weights for ds_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.00it/s]\nTesting weights for nn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 85.45it/s]\nTesting weights for nn_exp_04: 100%|██████████| 101/101 [00:01<00:00, 80.86it/s]\nTesting weights for xgboost_exp_05: 100%|██████████| 101/101 [00:01<00:00, 85.65it/s]\nTesting weights for lgbm_exp_05: 100%|██████████| 101/101 [00:01<00:00, 78.91it/s]\nTesting weights for tn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.60it/s]\nTesting weights for vr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.28it/s]\nTesting weights for tt_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.53it/s]\nTesting weights for en_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.65it/s]\nTesting weights for en_exp_02: 100%|██████████| 101/101 [00:01<00:00, 84.04it/s]\nTesting weights for nn_exp_05: 100%|██████████| 101/101 [00:01<00:00, 78.02it/s] \nTesting weights for rf_exp_05: 100%|██████████| 101/101 [00:01<00:00, 85.70it/s]\nTesting weights for mcts_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.40it/s]\nTesting weights for catboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 84.46it/s]\nTesting weights for xgboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 81.53it/s]\nTesting weights for lgbm_exp_06: 100%|██████████| 101/101 [00:01<00:00, 80.78it/s]\nTesting weights for nn_exp_06: 100%|██████████| 101/101 [00:01<00:00, 82.59it/s]\nTesting weights for xgboost_exp_07: 100%|██████████| 101/101 [00:01<00:00, 85.05it/s]\nTesting weights for ri_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.89it/s]\nTesting weights for xgboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 83.19it/s]\nTesting weights for catboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 81.52it/s] \nTesting weights for lgbm_exp_08: 100%|██████████| 101/101 [00:01<00:00, 80.89it/s]\nTesting weights for xgboost_exp_09: 100%|██████████| 101/101 [00:01<00:00, 79.44it/s]\nTesting weights for ri_exp_06: 100%|██████████| 101/101 [00:01<00:00, 84.24it/s]\nTesting weights for xgboost_exp_10: 100%|██████████| 101/101 [00:01<00:00, 81.25it/s]\nTesting weights for lasso_exp_01: 100%|██████████| 101/101 [00:01<00:00, 78.00it/s]\nTesting weights for lir_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.85it/s]\nTesting weights for svr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 85.51it/s]\nTesting weights for et_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.54it/s]\nTesting weights for lasso_exp_02: 100%|██████████| 101/101 [00:01<00:00, 85.81it/s]\nTesting weights for pr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 82.82it/s]\nTesting weights for tr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 79.96it/s]\nTesting weights for lasso_exp_06: 100%|██████████| 101/101 [00:01<00:00, 84.92it/s]\nTesting weights for ransac_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.28it/s]\nTesting weights for cnn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.68it/s]\nTesting weights for ts_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iteration 2: Added /kaggle/input/xgboost-exp-09 with weight 0.2700, Score: 0.6868\n2th iteration\n","output_type":"stream"},{"name":"stderr","text":"Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.62it/s]\nTesting weights for catboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 85.11it/s]\nTesting weights for lgbm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 78.68it/s]\nTesting weights for xgboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 86.06it/s]\nTesting weights for catboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 85.24it/s]\nTesting weights for lgbm_exp_03: 100%|██████████| 101/101 [00:01<00:00, 81.27it/s]\nTesting weights for catboost_exp_03: 100%|██████████| 101/101 [00:01<00:00, 85.30it/s]\nTesting weights for tabm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.87it/s] \nTesting weights for nn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 85.75it/s]\nTesting weights for tn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.80it/s]\nTesting weights for tf_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.96it/s] \nTesting weights for svr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.76it/s]\nTesting weights for abd_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.33it/s]\nTesting weights for catboost_exp_04: 100%|██████████| 101/101 [00:01<00:00, 86.91it/s]\nTesting weights for lgbm_exp_04: 100%|██████████| 101/101 [00:01<00:00, 81.24it/s]\nTesting weights for tabm_exp_02: 100%|██████████| 101/101 [00:01<00:00, 78.89it/s]\nTesting weights for ds_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.52it/s]\nTesting weights for nn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 80.09it/s]\nTesting weights for nn_exp_04: 100%|██████████| 101/101 [00:01<00:00, 80.81it/s]\nTesting weights for xgboost_exp_05: 100%|██████████| 101/101 [00:01<00:00, 85.70it/s]\nTesting weights for lgbm_exp_05: 100%|██████████| 101/101 [00:01<00:00, 84.22it/s]\nTesting weights for tn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 84.17it/s] \nTesting weights for vr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.70it/s]\nTesting weights for tt_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.30it/s]\nTesting weights for en_exp_01: 100%|██████████| 101/101 [00:01<00:00, 78.54it/s]\nTesting weights for en_exp_02: 100%|██████████| 101/101 [00:01<00:00, 86.32it/s]\nTesting weights for nn_exp_05: 100%|██████████| 101/101 [00:01<00:00, 81.95it/s]\nTesting weights for rf_exp_05: 100%|██████████| 101/101 [00:01<00:00, 83.35it/s] \nTesting weights for mcts_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.34it/s] \nTesting weights for catboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 82.05it/s]\nTesting weights for xgboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 83.22it/s]\nTesting weights for lgbm_exp_06: 100%|██████████| 101/101 [00:01<00:00, 84.20it/s]\nTesting weights for nn_exp_06: 100%|██████████| 101/101 [00:01<00:00, 83.64it/s]\nTesting weights for xgboost_exp_07: 100%|██████████| 101/101 [00:01<00:00, 85.71it/s]\nTesting weights for ri_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.40it/s]\nTesting weights for xgboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 82.58it/s]\nTesting weights for catboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 80.17it/s]\nTesting weights for lgbm_exp_08: 100%|██████████| 101/101 [00:01<00:00, 76.41it/s]\nTesting weights for ri_exp_06: 100%|██████████| 101/101 [00:01<00:00, 79.97it/s]\nTesting weights for xgboost_exp_10: 100%|██████████| 101/101 [00:01<00:00, 81.64it/s]\nTesting weights for lasso_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.94it/s]\nTesting weights for lir_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.50it/s]\nTesting weights for svr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 78.94it/s]\nTesting weights for et_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.30it/s]\nTesting weights for lasso_exp_02: 100%|██████████| 101/101 [00:01<00:00, 78.76it/s]\nTesting weights for pr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 89.96it/s]\nTesting weights for tr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 83.03it/s]\nTesting weights for lasso_exp_06: 100%|██████████| 101/101 [00:01<00:00, 83.09it/s]\nTesting weights for ransac_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.35it/s] \nTesting weights for cnn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.40it/s]\nTesting weights for ts_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iteration 3: Added /kaggle/input/lgbm-exp-08 with weight -0.2100, Score: 0.6871\n3th iteration\n","output_type":"stream"},{"name":"stderr","text":"Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.73it/s] \nTesting weights for catboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.37it/s]\nTesting weights for lgbm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.44it/s]\nTesting weights for xgboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 76.07it/s] \nTesting weights for catboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.78it/s]\nTesting weights for lgbm_exp_03: 100%|██████████| 101/101 [00:01<00:00, 83.36it/s]\nTesting weights for catboost_exp_03: 100%|██████████| 101/101 [00:01<00:00, 80.63it/s]\nTesting weights for tabm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 77.94it/s]\nTesting weights for nn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.28it/s]\nTesting weights for tn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 77.44it/s]\nTesting weights for tf_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.56it/s]\nTesting weights for svr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 76.74it/s]\nTesting weights for abd_exp_01: 100%|██████████| 101/101 [00:01<00:00, 78.95it/s]\nTesting weights for catboost_exp_04: 100%|██████████| 101/101 [00:01<00:00, 82.08it/s]\nTesting weights for lgbm_exp_04: 100%|██████████| 101/101 [00:01<00:00, 80.23it/s]\nTesting weights for tabm_exp_02: 100%|██████████| 101/101 [00:01<00:00, 83.31it/s]\nTesting weights for ds_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.47it/s]\nTesting weights for nn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.86it/s]\nTesting weights for nn_exp_04: 100%|██████████| 101/101 [00:01<00:00, 80.63it/s] \nTesting weights for xgboost_exp_05: 100%|██████████| 101/101 [00:01<00:00, 81.96it/s]\nTesting weights for lgbm_exp_05: 100%|██████████| 101/101 [00:01<00:00, 83.06it/s]\nTesting weights for tn_exp_02: 100%|██████████| 101/101 [00:01<00:00, 77.08it/s]\nTesting weights for vr_exp_01: 100%|██████████| 101/101 [00:01<00:00, 79.24it/s]\nTesting weights for tt_exp_01: 100%|██████████| 101/101 [00:01<00:00, 78.76it/s]\nTesting weights for en_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.28it/s]\nTesting weights for en_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.54it/s]\nTesting weights for nn_exp_05: 100%|██████████| 101/101 [00:01<00:00, 79.72it/s]\nTesting weights for rf_exp_05: 100%|██████████| 101/101 [00:01<00:00, 81.80it/s]\nTesting weights for mcts_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.13it/s]\nTesting weights for catboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 84.18it/s]\nTesting weights for xgboost_exp_06: 100%|██████████| 101/101 [00:01<00:00, 81.70it/s]\nTesting weights for lgbm_exp_06: 100%|██████████| 101/101 [00:01<00:00, 80.35it/s] \nTesting weights for nn_exp_06: 100%|██████████| 101/101 [00:01<00:00, 82.48it/s]\nTesting weights for xgboost_exp_07: 100%|██████████| 101/101 [00:01<00:00, 81.08it/s]\nTesting weights for ri_exp_01: 100%|██████████| 101/101 [00:01<00:00, 82.53it/s]\nTesting weights for xgboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 81.62it/s]\nTesting weights for catboost_exp_08: 100%|██████████| 101/101 [00:01<00:00, 82.97it/s]\nTesting weights for ri_exp_06: 100%|██████████| 101/101 [00:01<00:00, 80.83it/s] \nTesting weights for xgboost_exp_10: 100%|██████████| 101/101 [00:01<00:00, 78.93it/s]\nTesting weights for lasso_exp_01: 100%|██████████| 101/101 [00:01<00:00, 81.22it/s]\nTesting weights for lir_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.05it/s]\nTesting weights for svr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 79.06it/s]\nTesting weights for et_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.65it/s]\nTesting weights for lasso_exp_02: 100%|██████████| 101/101 [00:01<00:00, 83.14it/s]\nTesting weights for pr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 83.35it/s]\nTesting weights for tr_exp_06: 100%|██████████| 101/101 [00:01<00:00, 82.98it/s]\nTesting weights for lasso_exp_06: 100%|██████████| 101/101 [00:01<00:00, 77.48it/s]\nTesting weights for ransac_exp_01: 100%|██████████| 101/101 [00:01<00:00, 85.19it/s]\nTesting weights for cnn_exp_01: 100%|██████████| 101/101 [00:01<00:00, 84.02it/s]\nTesting weights for ts_exp_01: 100%|██████████| 101/101 [00:01<00:00, 77.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Iteration 4: Added /kaggle/input/catboost-exp-01 with weight 0.1000, Score: 0.6873\n4th iteration\n","output_type":"stream"},{"name":"stderr","text":"Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:01<00:00, 83.67it/s] \nTesting weights for lgbm_exp_01: 100%|██████████| 101/101 [00:01<00:00, 80.84it/s]\nTesting weights for xgboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 78.62it/s] \nTesting weights for catboost_exp_02: 100%|██████████| 101/101 [00:01<00:00, 81.08it/s]\nTesting weights for lgbm_exp_03: 100%|██████████| 101/101 [00:01<00:00, 83.58it/s]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# %%time\n\n# from tqdm import tqdm\n# import pandas as pd\n# import numpy as np\n# from typing import List, Dict, Tuple\n# import logging\n# import gc\n\n# def optimize_ensemble(experiments, initial_ensemble, weights_range, score_function, max_iterations = 100):\n    \n#     # Initialize variables\n#     iteration  = 0\n#     best_score = score_function(\n#         initial_ensemble[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n#         initial_ensemble[[\"ID\", \"predictions\"]].copy(),\n#         \"ID\"\n#     )\n    \n#     model_weights         = {}\n#     remaining_experiments = experiments.copy()\n#     best_ensemble         = initial_ensemble.copy()\n    \n#     while remaining_experiments and iteration < max_iterations:\n#         print(f\"{iteration}th iteration\")\n#         iteration += 1\n#         best_iteration = {\n#             'index' : -1,\n#             'weight': 0,\n#             'score' : best_score\n#         }\n        \n#         # Try each remaining model\n#         for model_path in remaining_experiments:\n#             try:\n#                 #print(f\"Iteration {iteration}: Trying model {model_path}\")\n                \n#                 # Load model OOF predictions\n#                 model_name = model_path.split(\"/\")[-1].replace('-', '_')\n#                 model_oof  = preds_df[model_path]\n                \n#                 # Try different weights\n#                 for weight in tqdm(weights_range, desc=f\"Testing weights for {model_name}\"):\n#                     # Create potential ensemble\n#                     potential_ensemble = pd.DataFrame({\n#                         \"ID\": best_ensemble[\"ID\"],\n#                         \"predictions\": (1 - weight) * rankdata(best_ensemble[\"predictions\"]) + \n#                                      weight * rankdata(model_oof)\n#                     })\n                    \n#                     # Evaluate new ensemble\n#                     new_score = score_function(\n#                         preds_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n#                         potential_ensemble.copy(),\n#                         \"ID\"\n#                     )\n                    \n#                     # Update best if improved\n#                     if new_score > best_iteration['score']:\n#                         best_iteration.update({\n#                             'index' : model_path,\n#                             'weight': weight,\n#                             'score' : new_score\n#                         })\n                \n#                 # Clean up\n#                 del model_oof\n#                 gc.collect()\n                \n#             except Exception as e:\n#                 print(f\"Error processing {model_path}: {str(e)}\")\n#                 continue\n        \n#         # Check if we found an improvement\n#         if best_iteration['index'] == -1:\n#             print(\"No improvement found, stopping\")\n#             print(best_iteration)\n#             break\n            \n#         # Update ensemble with best model found\n#         best_score                             = best_iteration['score']\n#         model_weights[best_iteration['index']] = best_iteration['weight']\n#         remaining_experiments.remove(best_iteration['index'])\n        \n#         print(\n#             f\"Iteration {iteration}: Added {best_iteration['index']} \"\n#             f\"with weight {best_iteration['weight']:.4f}, \"\n#             f\"Score: {best_iteration['score']:.4f}\"\n#         )\n        \n#         # Update best ensemble for next iteration\n#         model_oof = preds_df[best_iteration['index']]\n#         best_ensemble[\"predictions\"] = (\n#             (1 - best_iteration['weight']) * rankdata(best_ensemble[\"predictions\"]) + \n#             best_iteration['weight'] * rankdata(model_oof)\n#         )\n        \n#     return model_weights, best_score\n\n\n# model_weights, best_score = optimize_ensemble(experiments, best_ensemble, ww, score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T03:43:36.692068Z","iopub.execute_input":"2025-03-04T03:43:36.692313Z","iopub.status.idle":"2025-03-04T03:43:36.700214Z","shell.execute_reply.started":"2025-03-04T03:43:36.692291Z","shell.execute_reply":"2025-03-04T03:43:36.698862Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"model_weights, best_score, final_ensemble","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T03:43:36.701045Z","iopub.execute_input":"2025-03-04T03:43:36.701265Z","iopub.status.idle":"2025-03-04T03:43:36.722962Z","shell.execute_reply.started":"2025-03-04T03:43:36.701244Z","shell.execute_reply":"2025-03-04T03:43:36.722011Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"({'/kaggle/input/catboost-exp-05': 0.48000000000000087,\n  '/kaggle/input/xgboost-exp-09': 0.2700000000000007,\n  '/kaggle/input/lgbm-exp-08': -0.20999999999999974,\n  '/kaggle/input/catboost-exp-01': 0.10000000000000053,\n  '/kaggle/input/lasso-exp-01': -0.03999999999999959,\n  '/kaggle/input/nn-exp-04': 0.12000000000000055,\n  '/kaggle/input/svr-exp-06': -0.0499999999999996,\n  '/kaggle/input/ds-exp-01': 0.04000000000000048,\n  '/kaggle/input/rf-exp-05': -0.05999999999999961,\n  '/kaggle/input/svr-exp-01': -0.03999999999999959,\n  '/kaggle/input/tf-exp-01': 0.04000000000000048,\n  '/kaggle/input/catboost-exp-03': -0.03999999999999959,\n  '/kaggle/input/catboost-exp-06': 0.0600000000000005,\n  '/kaggle/input/tn-exp-02': 0.03000000000000047,\n  '/kaggle/input/xgboost-exp-02': -0.0499999999999996,\n  '/kaggle/input/catboost-exp-04': 0.020000000000000462,\n  '/kaggle/input/lgbm-exp-03': -0.029999999999999583,\n  '/kaggle/input/nn-exp-06': -0.05999999999999961,\n  '/kaggle/input/lir-exp-01': -0.009999999999999565,\n  '/kaggle/input/en-exp-02': 0.03000000000000047,\n  '/kaggle/input/ri-exp-06': -0.029999999999999583,\n  '/kaggle/input/tabm-exp-02': 0.04000000000000048,\n  '/kaggle/input/lgbm-exp-06': -0.0499999999999996,\n  '/kaggle/input/nn-exp-01': -0.029999999999999583,\n  '/kaggle/input/xgboost-exp-10': 0.03000000000000047,\n  '/kaggle/input/xgboost-exp-07': -0.03999999999999959,\n  '/kaggle/input/xgboost-exp-05': 0.0600000000000005,\n  '/kaggle/input/xgboost-exp-06': -0.0499999999999996,\n  '/kaggle/input/catboost-exp-02': 0.010000000000000453,\n  '/kaggle/input/mcts-exp-02': 0.010000000000000453,\n  '/kaggle/input/nn-exp-05': 0.04000000000000048,\n  '/kaggle/input/lgbm-exp-05': 0.010000000000000453,\n  '/kaggle/input/lgbm-exp-01': -0.019999999999999574,\n  '/kaggle/input/xgboost-exp-01': 0.010000000000000453,\n  '/kaggle/input/tt-exp-01': 4.440892098500626e-16},\n 0.6887243282521093,\n           ID  predictions\n 0          0       1743.0\n 1          1      20187.0\n 2          2        167.0\n 3          3      22886.0\n 4          4      12168.0\n ...      ...          ...\n 28795  28795       5566.0\n 28796  28796      26674.0\n 28797  28797      24262.0\n 28798  28798       3317.0\n 28799  28799        627.0\n \n [28800 rows x 2 columns])"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# first_best_index, experiments","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Inference on test","metadata":{}},{"cell_type":"code","source":"# class CFG:\n#     folds = 10\n\n# # https://www.kaggle.com/datasets/jsday96/mcts-tabm-models/data?select=TabMRegressor.py\n# class TabMRegressor:\n#     def __init__(\n#         self,\n#         arch_type: str        = 'tabm-mini',\n#         backbone: dict        = {'type': 'MLP', 'n_blocks': 3, 'd_block': 512, 'dropout': 0.1},\n#         d_embedding: int      = 64,  # Only used for 'tabm-mini'\n#         bin_count: int        = 48,  # Only used for 'tabm-mini'\n#         k: int                = 32,\n#         learning_rate: float  = 1e-4,\n#         weight_decay: float   = 1e-3,\n#         clip_grad_norm: bool  = True,\n#         max_epochs: int       = 100,\n#         patience: int         = 15,\n#         batch_size: int       = 32,\n#         compile_model: bool   = False,\n#         device: Optional[str] = 'cuda:0',\n#         random_state: int     = 0,\n#         verbose: bool         = True\n#     ):\n#         self.arch_type = arch_type\n#         self.backbone = backbone\n#         self.d_embedding = d_embedding\n#         self.bin_count = bin_count\n#         self.k = k\n#         self.learning_rate = learning_rate\n#         self.weight_decay = weight_decay\n#         self.clip_grad_norm = clip_grad_norm\n#         self.max_epochs = max_epochs\n#         self.patience = patience\n#         self.batch_size = batch_size\n#         self.compile_model = compile_model\n#         self.device = torch.device(device if device else ('cuda' if torch.cuda.is_available() else 'cpu'))\n#         self.random_state = random_state\n#         self.verbose = verbose\n\n#     def fit(\n#         self,\n#         X: pd.DataFrame,\n#         y: np.array,\n#         eval_set: Tuple[pd.DataFrame, np.array]\n#     ):\n#         # PREPROCESS DATA.\n#         X_cat_train, X_cont_train, cat_cardinalities, y_train = self._preprocess_data(X, y, training=True)\n#         X_cat_val, X_cont_val, _, y_val = self._preprocess_data(eval_set[0], eval_set[1], training=False)\n\n#         # CREATE MODEL & TRAINING ALGO.\n#         bins = rtdl_num_embeddings.compute_bins(X_cont_train, n_bins=self.bin_count) if self.arch_type == 'tabm-mini' else None\n#         self.model = Model(\n#             n_num_features=X_cont_train.shape[1],\n#             cat_cardinalities=cat_cardinalities,\n#             n_classes=None,\n#             backbone=self.backbone,\n#             bins=bins,\n#             num_embeddings=(\n#                 None\n#                 if bins is None\n#                 else {\n#                     'type': 'PiecewiseLinearEmbeddings',\n#                     'd_embedding': self.d_embedding,\n#                     'activation': True,\n#                     'version': 'B',\n#                 }\n#             ),\n#             arch_type=self.arch_type,\n#             k=self.k,\n#         ).to(self.device)\n#         optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.learning_rate, weight_decay=self.weight_decay)\n#         if self.compile_model:\n#             self.model = torch.compile(self.model)\n\n#         loss_fn = torch.nn.MSELoss().to(self.device)\n#         # TRAIN & TEST MODEL.\n#         best = {\n#             'epoch': -1,\n#             'eval_loss': math.inf,\n#             'model_state_dict': None,\n#         }\n#         remaining_patience = self.patience\n#         epoch_size = math.ceil(len(X) / self.batch_size)\n\n\n#         for epoch in range(self.max_epochs):\n#             # TRAIN.\n#             optimizer.zero_grad()\n#             train_losses = []\n#             progress_bar = torch.randperm(len(y_train), device=self.device).split(self.batch_size)\n#             progress_bar = tqdm(progress_bar, desc=f'Epoch {epoch}', total=epoch_size) if self.verbose else progress_bar\n#             for batch_idx in progress_bar:\n#                 self.model.train()\n\n#                 with torch.amp.autocast(device_type='cuda', dtype = torch.bfloat16):\n#                     y_pred = self.model(\n#                         X_cont_train[batch_idx],\n#                         X_cat_train[batch_idx],\n#                     ).squeeze(-1).float()\n\n#                 loss = loss_fn(y_pred.flatten(0, 1), y_train[batch_idx].repeat_interleave(self.k))\n#                 loss.backward()\n#                 if self.clip_grad_norm:\n#                     torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n#                 optimizer.step()\n\n#                 train_losses.append(loss.item())\n\n\n#              # EVALUATE.\n#             self.model.eval()\n#             val_losses = []\n#             with torch.no_grad():\n#                 for batch_idx in torch.arange(0, len(y_val), self.batch_size, device=self.device):\n#                     y_pred = self.model(\n#                         X_cont_val[batch_idx:batch_idx+self.batch_size],\n#                         X_cat_val[batch_idx:batch_idx+self.batch_size],\n#                     ).squeeze(-1).float()\n\n#                     loss = loss_fn(y_pred.flatten(0, 1), y_val[batch_idx:batch_idx+self.batch_size].repeat_interleave(self.k))\n#                     val_losses.append(loss.item())\n\n\n#             # PRINT INFO.\n#             mean_train_loss = np.mean(train_losses)\n#             mean_val_loss = np.mean(val_losses)\n#             if self.verbose:\n#                 print(f'Epoch {epoch} | Train Loss: {mean_train_loss} | Val Loss: {mean_val_loss}')\n\n\n#             # COMPARE TO BEST.\n#             if mean_val_loss < best['eval_loss']:\n#                 best['epoch'] = epoch\n#                 best['eval_loss'] = mean_val_loss\n#                 best['model_state_dict'] = self.model.state_dict()\n#                 remaining_patience = self.patience\n                \n#                 if self.verbose:\n#                     print('🌸 New best epoch! 🌸')\n#             else:\n#                 remaining_patience -= 1\n\n#             # EARLY STOPPING.\n#             if remaining_patience == 0:\n#                 break\n\n#             # RESTORE BEST MODEL.\n#             self.model.load_state_dict(best['model_state_dict'])\n\n\n#     def predict(\n#         self,\n#         X: pd.DataFrame,\n#         batch_size: Optional[int] = 8096\n#     ) -> np.ndarray:\n#         # PREPROCESS DATA.\n#         X_cat, X_cont, _, _ = self._preprocess_data(X, y=None, training=False)\n\n#         # PREDICT.\n#         self.model.eval()\n#         y_pred = []\n#         with torch.no_grad():\n#             for batch_idx in torch.arange(0, len(X), batch_size, device=self.device):\n#                 y_pred.append(\n#                     self.model(\n#                         X_cont[batch_idx:batch_idx+batch_size],\n#                         X_cat[batch_idx:batch_idx+batch_size],\n#                     ).squeeze(-1).float().cpu().numpy()\n#                 )\n\n#         y_pred = np.concatenate(y_pred)\n\n\n#         # DENORMALIZE TARGETS.\n#         y_pred = y_pred * self._target_std + self._target_mean\n\n\n#         # COMPUTE ENSEMBLE MEAN.\n#         y_pred = np.mean(y_pred, axis=1)\n\n#         return y_pred\n\n\n#     def _preprocess_data(self, X: pd.DataFrame, y: pd.Series, training: bool):\n#         # PICK NON-CONSTANT COLUMNS.\n#         if training:\n#             self._non_constant_columns = X.columns[X.nunique() > 1]\n\n#         X = X[self._non_constant_columns]\n\n#         # SEPARATE CATEGORICAL & CONTINUOUS FEATURES.\n#         categorical_features = [col for col in X.columns if X[col].dtype.name == 'object']\n#         X_cat = X[categorical_features].to_numpy()\n#         X_cont = X.drop(columns=categorical_features).to_numpy()\n\n#         # ENCODE CATEGORICAL FEATURES.\n#         cat_cardinalities = [X[col].nunique() for col in categorical_features]\n\n#         if training:\n#             self._categorical_encoders = [\n#                 OrdinalEncoder()\n#                 for _ in range(X_cat.shape[1])\n#             ]\n#         X_cat = np.concatenate([\n#             encoder.fit_transform(X_cat[:, i:i+1])\n#             for i, encoder in enumerate(self._categorical_encoders)\n#         ], axis=1)\n\n#         # NORMALIZE TARGETS.\n#         if training:\n#             self._target_mean = y.mean()\n#             self._target_std = y.std()\n\n#             y = (y - self._target_mean) / self._target_std\n\n\n#         # SCALE CONTINUOUS FEATURES.\n#         if training:\n#             noise = (\n#                 np.random.default_rng(0)\n#                 .normal(0.0, 1e-5, X_cont.shape)\n#                 .astype(X_cont.dtype)\n#             )\n#             self._cont_feature_preprocessor = QuantileTransformer(\n#                 n_quantiles=max(min(len(X) // 30, 1000), 10),\n#                 output_distribution='normal',\n#                 subsample=10**9,\n#             ).fit(X_cont + noise)\n\n#         X_cont = self._cont_feature_preprocessor.transform(X_cont)\n\n\n#         # CONVERT TO TENSORS.\n#         X_cat = torch.tensor(X_cat, dtype=torch.long, device=self.device)\n#         X_cont = torch.tensor(X_cont, dtype=torch.float32, device=self.device)\n\n#         if y is not None:\n#             y = torch.tensor(y, dtype=torch.float32, device=self.device)\n\n#         return X_cat, X_cont, cat_cardinalities, y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:38.013044Z","iopub.execute_input":"2025-01-22T15:52:38.013333Z","iopub.status.idle":"2025-01-22T15:52:38.021341Z","shell.execute_reply.started":"2025-01-22T15:52:38.013310Z","shell.execute_reply":"2025-01-22T15:52:38.020210Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_tabm_features(data):\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n#     FEATURES = [c for c in data.columns if not c in RMV]\n    \n#     RMV              = ['ID']\n#     X_test           = data.drop(RMV, axis=1)\n#     y_pred           = data[['ID']]\n    \n#     #print(\"X_test shape:\", X_test.shape, '\\n')\n    \n#     cat_cols         = X_test.select_dtypes(include=['object']).columns.tolist()\n#     num_cols         = X_test.select_dtypes(exclude=['object']).columns.tolist()\n    \n#     # Preprocessing categorical\n#     imputer          = SimpleImputer(strategy='constant', fill_value='NAN')\n#     X_test[cat_cols] = imputer.fit_transform(X_test[cat_cols])\n\n#     # Preprocessing numerical\n#     imputer          = SimpleImputer(strategy=\"median\")\n#     X_test[num_cols] = imputer.fit_transform(X_test[num_cols])\n\n#     return X_test,FEATURES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:27.416912Z","iopub.execute_input":"2025-01-22T15:52:27.417188Z","iopub.status.idle":"2025-01-22T15:52:27.420357Z","shell.execute_reply.started":"2025-01-22T15:52:27.417167Z","shell.execute_reply":"2025-01-22T15:52:27.419366Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def prepare_features(model_path, train, test):\n\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\"]\n#     FEATURES = [c for c in train.columns if not c in RMV]\n#     #print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n    \n\n#     CATS = []\n#     for c in FEATURES:\n#         if train[c].dtype==\"object\":\n#             CATS.append(c)\n#             train[c] = train[c].fillna(\"NAN\")\n#             test[c]  = test[c].fillna(\"NAN\")\n#         elif \"DeepTabels\" in model_path or \"tn\" in model_path or \"svr\" in model_path:\n#             train[c] = train[c].fillna(-1)\n#             test[c]  = test[c].fillna(-1)\n            \n        \n#     #print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n    \n#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n#     #print(\"Combined data shape:\", combined.shape )\n    \n#     # LABEL ENCODE CATEGORICAL FEATURES\n#     #print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n#     for c in FEATURES:\n    \n#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n#         if c in CATS:\n#             #print(f\"{c}, \",end=\"\")\n#             combined[c],_ = combined[c].factorize()\n#             combined[c]  -= combined[c].min()\n#             combined[c]   = combined[c].astype(\"int32\")\n#             combined[c]   = combined[c].astype(\"category\")\n            \n#         # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n#         else:\n#             if combined[c].dtype ==\"float64\":\n#                 combined[c]      = combined[c].astype(\"float32\")\n#             if combined[c].dtype ==\"int64\":\n#                 combined[c]      = combined[c].astype(\"int32\")\n        \n#     train = combined.iloc[:len(train)].copy()\n#     test  = combined.iloc[len(train):].reset_index(drop=True).copy()\n                \n#     return train, test, FEATURES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:22.261913Z","iopub.execute_input":"2025-01-22T15:52:22.262226Z","iopub.status.idle":"2025-01-22T15:52:22.265689Z","shell.execute_reply.started":"2025-01-22T15:52:22.262197Z","shell.execute_reply":"2025-01-22T15:52:22.264976Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_nn_features(train, test):\n    \n#     CAT_SIZE = []\n#     CAT_EMB  = []\n#     NUMS     = []\n#     CATS     = []\n\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n#     FEATURES = [c for c in train.columns if not c in RMV]\n    \n#     for c in FEATURES:\n#         if train[c].dtype==\"object\":\n#             train[c] = train[c].fillna(\"NAN\")\n#             test[c]  = test[c].fillna(\"NAN\")\n#             CATS.append(c)\n#         elif not \"age\" in c:\n#             train[c] = train[c].astype(\"str\")\n#             test[c]  = test[c].astype(\"str\")\n#             CATS.append(c)\n\n\n#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n#     for c in FEATURES:\n#         if c in CATS:\n#             # LABEL ENCODE\n#             combined[c],_ = combined[c].factorize()\n#             combined[c] -= combined[c].min()\n#             combined[c] = combined[c].astype(\"int32\")\n#             #combined[c] = combined[c].astype(\"category\")\n\n#             n = combined[c].nunique()\n#             mn = combined[c].min()\n#             mx = combined[c].max()\n#             #print(f'{c} has ({n}) unique values')\n    \n#             CAT_SIZE.append(mx+1) \n#             CAT_EMB.append( int(np.ceil( np.sqrt(mx+1))) ) \n#         else:\n#             if combined[c].dtype==\"float64\":\n#                 combined[c] = combined[c].astype(\"float32\")\n#             if combined[c].dtype==\"int64\":\n#                 combined[c] = combined[c].astype(\"int32\")\n                \n#             m = combined[c].mean()\n#             s = combined[c].std()\n#             combined[c] = (combined[c]-m)/s\n#             combined[c] = combined[c].fillna(0)\n            \n#             NUMS.append(c)\n\n#     train = combined.iloc[:len(train)].copy()\n#     test = combined.iloc[len(train):].reset_index(drop=True).copy()\n\n#     return test[CATS], test[NUMS]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:18.343995Z","iopub.execute_input":"2025-01-22T15:52:18.344275Z","iopub.status.idle":"2025-01-22T15:52:18.347993Z","shell.execute_reply.started":"2025-01-22T15:52:18.344254Z","shell.execute_reply":"2025-01-22T15:52:18.347104Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_tf_features(train, test):\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"y_na\",\"fold\"]\n#     FEATURES = [c for c in train.columns if not c in RMV]\n\n\n#     test                             = test.replace('Not done', 'missing')\n#     test                             = test.replace('Not tested', 'missing')\n    \n#     test['na_count']                 = test.isna().sum(axis=1)\n#     test['age_karnofsky']            = test['age_at_hct'] * test['karnofsky_score']\n#     test['age_comorbidity']          = test['age_at_hct'] * test['comorbidity_score']\n#     test['donor_recipient_age_diff'] = abs(test['donor_age'] - test['age_at_hct'])\n#     test['hla_match_ratio']          = (test['hla_high_res_8'] + test['hla_low_res_8']) / 16\n#     test['age_squared']              = test['age_at_hct'] ** 2\n#     test['karnofsky_squared']        = test['karnofsky_score'] ** 2\n#     test['16?']                      = np.where(test['age_at_hct']<=16,1,0)\n    \n#     FEATURES.extend([\"na_count\", \"age_karnofsky\", \"age_comorbidity\", \"donor_recipient_age_diff\", \"hla_match_ratio\", \"age_squared\", \"karnofsky_squared\", \"16?\"])\n\n#     CATS = []\n#     for c in FEATURES:\n#         if test[c].dtype==\"object\":\n#             CATS.append(c)\n#             test[c] = test[c].fillna(\"missing\")\n\n#     for c in FEATURES:\n#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n#         if c in CATS:\n#             #print(f\"{c}, \",end=\"\")\n#             test[c],_ = test[c].factorize()\n#             test[c]  -= test[c].min()\n#             test[c]   = test[c].astype(\"int32\")\n#             test[c]   = test[c].astype(\"category\")\n#         else:\n#             if test[c].dtype == \"float64\":\n#                 test[c]      = test[c].astype(\"float32\")\n#             if test[c].dtype ==\"int64\":\n#                 test[c]      = test[c].astype(\"int32\")\n    \n#     return test, FEATURES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:14.653655Z","iopub.execute_input":"2025-01-22T15:52:14.653930Z","iopub.status.idle":"2025-01-22T15:52:14.657340Z","shell.execute_reply.started":"2025-01-22T15:52:14.653909Z","shell.execute_reply":"2025-01-22T15:52:14.656475Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pickle\n# from tqdm import tqdm\n# from sklearn.svm import SVR\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.impute import KNNImputer\n\n# imputer               = KNNImputer(n_neighbors=5, weights='uniform')\n\n# scaler = StandardScaler()\n\n# FOLDS = 10\n\n# def inference(model_path, train, test_df):\n    \n#     path = model_path.split('/')[-1]\n#     file = path.replace('-','_')\n\n#     if \"dt\" not in model_path:\n#         with open(f\"/kaggle/input/{path}/{file}.pkl\", 'rb') as f:\n#             models = pickle.load(f)\n            \n#     print(\"All models are loaded successfully....!\")\n\n#     test_predictions = np.zeros(len(test_df))\n\n#     for fold in tqdm(range(FOLDS)):\n#         if \"dt\" in model_path:\n#             # model = keras.models.load_model(model_path, custom_objects=custom_objects)\n#             # train, test, FEATURES   = prepare_features(model_path, train, test_df)\n#             # model                   = tf.keras.models.load_model(model_path+f\"/model_fold_{fold}.keras\", custom_objects=dt.__dict__, compile=)\n#             # fold_preds              = model.predict(test.copy())\n#             # fold_preds              = fold_preds.flatten()\n#             pass\n#         else:\n#             model  = models[fold]\n            \n            \n#         if \"svr\" in model_path:\n#             if fold==0:\n#                 train, test, FEATURES = prepare_features(model_path, train.copy(), test_df.copy())\n\n#             # Handle missing values\n#             train_imputed         = imputer.fit_transform(train[FEATURES].copy())\n#             test_imputed          = imputer.transform(test[FEATURES])\n\n#             # Convert back to DataFrame to maintain feature names\n#             train_imputed         = pd.DataFrame(train_imputed, columns=FEATURES, index=train.index)\n#             test_imputed          = pd.DataFrame(test_imputed, columns=FEATURES, index=test.index)\n            \n#             # Scale features\n#             scaler.fit(train_imputed)\n#             test_scaled           = scaler.transform(test_imputed)\n            \n#             fold_preds            = model.predict(test_scaled)\n\n#         elif \"tn\" in model_path:\n#             if fold == 0:\n#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n                \n#             fold_preds              = model.predict(test[FEATURES].values).flatten()\n            \n#         elif \"nn\" in model_path:\n#             if fold == 0:\n#                 X_cat, X_num      = get_nn_features(train, test_df.copy())\n#             fold_preds        = model.predict([X_cat.values, X_num.values])\n#             fold_preds        = fold_preds.flatten()\n\n#         elif \"tf\" in model_path:\n#             if fold == 0:\n#                 test, FEATURES = get_tf_features(train.copy(),test_df.copy())\n#                 fold_preds     = model.predict(test[FEATURES].copy())\n\n#         elif \"tabm\" in model_path:\n#             if fold == 0:\n#                 test, FEATURES = get_tabm_features(test_df.copy())\n#             fold_preds              = model.predict(test[FEATURES].copy())\n            \n#         else: \n#             if fold == 0:\n#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n#             fold_preds              = model.predict(test[FEATURES].copy())\n            \n#         test_predictions += fold_preds\n    \n#     # Get the average predictionr\n#     test_predictions /= FOLDS\n        \n#     return test_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:11.189637Z","iopub.execute_input":"2025-01-22T15:52:11.189923Z","iopub.status.idle":"2025-01-22T15:52:11.193648Z","shell.execute_reply.started":"2025-01-22T15:52:11.189903Z","shell.execute_reply":"2025-01-22T15:52:11.192819Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n# test_df  = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-22T15:51:51.162801Z","iopub.execute_input":"2025-01-22T15:51:51.163120Z","iopub.status.idle":"2025-01-22T15:51:51.166096Z","shell.execute_reply.started":"2025-01-22T15:51:51.163097Z","shell.execute_reply":"2025-01-22T15:51:51.165367Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# first_best_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:54.701659Z","iopub.execute_input":"2025-01-22T15:51:54.701943Z","iopub.status.idle":"2025-01-22T15:51:54.704832Z","shell.execute_reply.started":"2025-01-22T15:51:54.701923Z","shell.execute_reply":"2025-01-22T15:51:54.704065Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# initial_test_preds = inference(first_best_index, train_df, test_df)\n# initial_test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:57.348357Z","iopub.execute_input":"2025-01-22T15:51:57.348690Z","iopub.status.idle":"2025-01-22T15:51:57.351830Z","shell.execute_reply.started":"2025-01-22T15:51:57.348663Z","shell.execute_reply":"2025-01-22T15:51:57.351159Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:01.335658Z","iopub.execute_input":"2025-01-22T15:52:01.335938Z","iopub.status.idle":"2025-01-22T15:52:01.338972Z","shell.execute_reply.started":"2025-01-22T15:52:01.335916Z","shell.execute_reply":"2025-01-22T15:52:01.338017Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_preds = []\n# for model, weight in model_weights.items():\n#     print(f\"Using model : {model}\")\n#     test_df            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n    \n#     test_preds         = inference(model, train_df.copy(), test_df)\n#     test_preds         = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n#     initial_test_preds = test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:25:28.022763Z","iopub.execute_input":"2025-01-22T15:25:28.023081Z","iopub.status.idle":"2025-01-22T15:25:28.027486Z","shell.execute_reply.started":"2025-01-22T15:25:28.023052Z","shell.execute_reply":"2025-01-22T15:25:28.026444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df               = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n# test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n# test_preds             = np.zeros(len(test_df))\n\n\n# preds_dict = {}\n# for model, weight in model_weights.items():\n#     print(f\"exp name : {model}\\n\")\n#     test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n#     test_preds             = inference(model, train_df.copy(), test_df.copy())\n#     test_preds             = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n#     initial_test_preds     = test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:34.790171Z","iopub.execute_input":"2025-01-22T15:51:34.790539Z","iopub.status.idle":"2025-01-22T15:51:34.795219Z","shell.execute_reply.started":"2025-01-22T15:51:34.790484Z","shell.execute_reply":"2025-01-22T15:51:34.793900Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:38.332302Z","iopub.execute_input":"2025-01-22T15:51:38.332656Z","iopub.status.idle":"2025-01-22T15:51:38.335669Z","shell.execute_reply.started":"2025-01-22T15:51:38.332625Z","shell.execute_reply":"2025-01-22T15:51:38.334872Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# potential_ensemble                = pd.DataFrame()\n# potential_ensemble[\"predictions\"] = test_preds\n# potential_ensemble[\"ID\"]          = test_df[\"ID\"]\n# new_score                         = score(test_df[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy(), potential_ensemble.copy(), \"ID\")\n# new_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:42:13.951997Z","iopub.execute_input":"2025-01-22T15:42:13.952261Z","iopub.status.idle":"2025-01-22T15:42:13.955904Z","shell.execute_reply.started":"2025-01-22T15:42:13.952239Z","shell.execute_reply":"2025-01-22T15:42:13.955011Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:41.520933Z","iopub.execute_input":"2025-01-22T15:51:41.521214Z","iopub.status.idle":"2025-01-22T15:51:41.524083Z","shell.execute_reply.started":"2025-01-22T15:51:41.521193Z","shell.execute_reply":"2025-01-22T15:51:41.523309Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7: Create submission file","metadata":{}},{"cell_type":"code","source":"# sub            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n# sub.prediction = test_preds\n# sub.to_csv(\"submission.csv\",index=False)\n# print(\"Sub shape:\",sub.shape)\n# sub.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:44.807144Z","iopub.execute_input":"2025-01-22T15:51:44.807435Z","iopub.status.idle":"2025-01-22T15:51:44.810222Z","shell.execute_reply.started":"2025-01-22T15:51:44.807409Z","shell.execute_reply":"2025-01-22T15:51:44.809395Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}