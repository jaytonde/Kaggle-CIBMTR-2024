{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b77c80b",
   "metadata": {
    "_cell_guid": "46a264b2-b97f-487b-9a3d-2597a0ecdc21",
    "_uuid": "9daabf89-8847-4537-a0b7-2a722b5c452d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009803,
     "end_time": "2025-01-25T14:24:59.892365",
     "exception": false,
     "start_time": "2025-01-25T14:24:59.882562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370ef0e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:24:59.911554Z",
     "iopub.status.busy": "2025-01-25T14:24:59.911214Z",
     "iopub.status.idle": "2025-01-25T14:25:24.266296Z",
     "shell.execute_reply": "2025-01-25T14:25:24.265113Z"
    },
    "papermill": {
     "duration": 24.367502,
     "end_time": "2025-01-25T14:25:24.268915",
     "exception": false,
     "start_time": "2025-01-25T14:24:59.901413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd==1.7.0) (1.26.4)\r\n",
      "autograd is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.7.0)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.13.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\r\n",
      "Building wheels for collected packages: autograd-gamma\r\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=7ba62838a86a27e07f47f2f06897e6e23867a44e74440b63a720427d1e681e4e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/b5/e0/4c79e15c0b5f2c15ecf613c720bb20daab20a666eb67135155\r\n",
      "Successfully built autograd-gamma\r\n",
      "Installing collected packages: autograd-gamma\r\n",
      "Successfully installed autograd-gamma-0.5.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\r\n",
      "Installing collected packages: interface-meta\r\n",
      "Successfully installed interface-meta-1.3.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (2.1.4)\r\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.0.2) (1.16.0)\r\n",
      "Installing collected packages: formulaic\r\n",
      "Successfully installed formulaic-1.0.2\r\n",
      "Processing /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.13.1)\r\n",
      "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (2.1.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (3.7.1)\r\n",
      "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.7.0)\r\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (0.5.0)\r\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.0.2)\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.16.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.16.0)\r\n",
      "Installing collected packages: lifelines\r\n",
      "Successfully installed lifelines-0.30.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
    "!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b021f9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:25:24.291496Z",
     "iopub.status.busy": "2025-01-25T14:25:24.291165Z",
     "iopub.status.idle": "2025-01-25T14:25:32.522834Z",
     "shell.execute_reply": "2025-01-25T14:25:32.521528Z"
    },
    "papermill": {
     "duration": 8.246569,
     "end_time": "2025-01-25T14:25:32.525692",
     "exception": false,
     "start_time": "2025-01-25T14:25:24.279123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/tabm-tabular-dl-library\r\n",
      "Processing /kaggle/input/tabm-tabular-dl-library/tabm-0.0.1.dev0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch<3,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tabm==0.0.1.dev0) (2.4.1+cu121)\r\n",
      "Processing /kaggle/input/tabm-tabular-dl-library/rtdl_num_embeddings-0.0.11-py3-none-any.whl (from tabm==0.0.1.dev0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.12->tabm==0.0.1.dev0) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.12->tabm==0.0.1.dev0) (1.3.0)\r\n",
      "Installing collected packages: rtdl_num_embeddings, tabm\r\n",
      "Successfully installed rtdl_num_embeddings-0.0.11 tabm-0.0.1.dev0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index -U --find-links=/kaggle/input/tabm-tabular-dl-library tabm==0.0.1.dev0\n",
    "!pip -q install /kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be4449b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:25:32.548567Z",
     "iopub.status.busy": "2025-01-25T14:25:32.548185Z",
     "iopub.status.idle": "2025-01-25T14:25:36.807196Z",
     "shell.execute_reply": "2025-01-25T14:25:36.805795Z"
    },
    "papermill": {
     "duration": 4.272521,
     "end_time": "2025-01-25T14:25:36.809254",
     "exception": false,
     "start_time": "2025-01-25T14:25:32.536733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install /kaggle/input/tabpfn-v2/tabpfn-2.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59fdbd",
   "metadata": {
    "papermill": {
     "duration": 0.00992,
     "end_time": "2025-01-25T14:25:36.829764",
     "exception": false,
     "start_time": "2025-01-25T14:25:36.819844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1 : Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7360cb8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:25:36.852182Z",
     "iopub.status.busy": "2025-01-25T14:25:36.851758Z",
     "iopub.status.idle": "2025-01-25T14:25:54.555080Z",
     "shell.execute_reply": "2025-01-25T14:25:54.553967Z"
    },
    "papermill": {
     "duration": 17.71679,
     "end_time": "2025-01-25T14:25:54.557110",
     "exception": false,
     "start_time": "2025-01-25T14:25:36.840320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata \n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/tabm-tabular-dl-library')\n",
    "\n",
    "import os\n",
    "import tabm\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rtdl_num_embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import rankdata \n",
    "from colorama import Fore, Style\n",
    "from typing import Optional, Tuple\n",
    "from numpy.typing import ArrayLike\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "from sklearn.preprocessing import OrdinalEncoder, QuantileTransformer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.layers import Concatenate, BatchNormalization\n",
    "import tensorflow.keras.backend as K\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from tabpfn import TabPFNRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a418b0d",
   "metadata": {
    "papermill": {
     "duration": 0.009991,
     "end_time": "2025-01-25T14:25:54.577566",
     "exception": false,
     "start_time": "2025-01-25T14:25:54.567575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Experiments Paths  to add in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c6277a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:25:54.599692Z",
     "iopub.status.busy": "2025-01-25T14:25:54.598999Z",
     "iopub.status.idle": "2025-01-25T14:25:54.603856Z",
     "shell.execute_reply": "2025-01-25T14:25:54.602838Z"
    },
    "papermill": {
     "duration": 0.017842,
     "end_time": "2025-01-25T14:25:54.605669",
     "exception": false,
     "start_time": "2025-01-25T14:25:54.587827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "\"/kaggle/input/xgboost-exp-01\",\n",
    "\"/kaggle/input/catboost-exp-01\", \n",
    "\"/kaggle/input/lgbm-exp-01\",\n",
    "\"/kaggle/input/xgboost-exp-02\",\n",
    "\"/kaggle/input/catboost-exp-02\",\n",
    "\"/kaggle/input/lgbm-exp-03\",\n",
    "\"/kaggle/input/catboost-exp-03\",\n",
    "\"/kaggle/input/tabm-exp-01\",\n",
    "\"/kaggle/input/nn-exp-01\",\n",
    "\"/kaggle/input/tn-exp-01\",\n",
    "\"/kaggle/input/tf-exp-01\",\n",
    "\"/kaggle/input/svr-exp-01\",\n",
    "\"/kaggle/input/abd-exp-01\",\n",
    "\"/kaggle/input/catboost-exp-04\",\n",
    "\"/kaggle/input/lgbm-exp-04\"\n",
    "# \"/kaggle/input/suv-ran-exp-01\" -> File not found\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddfbda",
   "metadata": {
    "papermill": {
     "duration": 0.009971,
     "end_time": "2025-01-25T14:25:54.626078",
     "exception": false,
     "start_time": "2025-01-25T14:25:54.616107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3 : Competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f367ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:25:54.648802Z",
     "iopub.status.busy": "2025-01-25T14:25:54.648400Z",
     "iopub.status.idle": "2025-01-25T14:25:54.763984Z",
     "shell.execute_reply": "2025-01-25T14:25:54.763085Z"
    },
    "papermill": {
     "duration": 0.129071,
     "end_time": "2025-01-25T14:25:54.765841",
     "exception": false,
     "start_time": "2025-01-25T14:25:54.636770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import numpy as np\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> y_pred = {'prediction': {0: 1.0, 1: 0.0, 2: 1.0}}\n",
    "    >>> y_pred = pd.DataFrame(y_pred)\n",
    "    >>> y_pred.insert(0, row_id_column_name, range(len(y_pred)))\n",
    "    >>> y_true = { 'efs': {0: 1.0, 1: 0.0, 2: 0.0}, 'efs_time': {0: 25.1234,1: 250.1234,2: 2500.1234}, 'race_group': {0: 'race_group_1', 1: 'race_group_1', 2: 'race_group_1'}}\n",
    "    >>> y_true = pd.DataFrame(y_true)\n",
    "    >>> y_true.insert(0, row_id_column_name, range(len(y_true)))\n",
    "    >>> score(y_true.copy(), y_pred.copy(), row_id_column_name)\n",
    "    0.75\n",
    "    \"\"\"\n",
    "\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    \n",
    "    event_label = 'efs'\n",
    "    interval_label = 'efs_time'\n",
    "    prediction_label = 'predictions'\n",
    "    for col in submission.columns:\n",
    "        if not pandas.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
    "    # Merging solution and submission dfs on ID\n",
    "    merged_df = pd.concat([solution, submission], axis=1)\n",
    "    merged_df.reset_index(inplace=True)\n",
    "    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n",
    "    metric_list = []\n",
    "\n",
    "    for race in merged_df_race_dict.keys():\n",
    "        # Retrieving values from y_test based on index\n",
    "        indices = sorted(merged_df_race_dict[race])\n",
    "        merged_df_race = merged_df.iloc[indices]\n",
    "        # Calculate the concordance index\n",
    "        c_index_race = concordance_index(\n",
    "                        merged_df_race[interval_label],\n",
    "                        -merged_df_race[prediction_label],\n",
    "                        merged_df_race[event_label])\n",
    "        metric_list.append(c_index_race)\n",
    "    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860b0b1",
   "metadata": {
    "papermill": {
     "duration": 0.009773,
     "end_time": "2025-01-25T14:25:54.786195",
     "exception": false,
     "start_time": "2025-01-25T14:25:54.776422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4: Find best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af8eb70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:25:54.807665Z",
     "iopub.status.busy": "2025-01-25T14:25:54.807275Z",
     "iopub.status.idle": "2025-01-25T14:25:54.813042Z",
     "shell.execute_reply": "2025-01-25T14:25:54.812069Z"
    },
    "papermill": {
     "duration": 0.018458,
     "end_time": "2025-01-25T14:25:54.814755",
     "exception": false,
     "start_time": "2025-01-25T14:25:54.796297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metric_cindex(exp_name):\n",
    "    if exp_name in [\"/kaggle/input/abd-exp-01\",\"/kaggle/input/lgbm-exp-04\", \"/kaggle/input/catboost-exp-01\", \"/kaggle/input/lgbm-exp-01\", \"/kaggle/input/lgbm-exp-03\"]:\n",
    "        oof    = pd.read_parquet(exp_name+'/'+(exp_name.split('/')[-1]).replace('-','_')+'_oof.parquet')\n",
    "    else:\n",
    "        oof    = pd.read_excel(exp_name+'/'+(exp_name.split('/')[-1]).replace('-','_')+'_oof.xlsx')\n",
    "        \n",
    "    y_true = oof[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "    y_pred = oof[[\"ID\",\"predictions\"]].copy()\n",
    "    return score(y_true.copy(), y_pred.copy(), \"ID\"), oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12531697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:25:54.836784Z",
     "iopub.status.busy": "2025-01-25T14:25:54.836360Z",
     "iopub.status.idle": "2025-01-25T14:29:56.248071Z",
     "shell.execute_reply": "2025-01-25T14:29:56.246932Z"
    },
    "papermill": {
     "duration": 241.424877,
     "end_time": "2025-01-25T14:29:56.250017",
     "exception": false,
     "start_time": "2025-01-25T14:25:54.825140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index 0.6743662038463064 /kaggle/input/xgboost-exp-01\n",
      "C-index 0.673797469068503 /kaggle/input/catboost-exp-01\n",
      "C-index 0.6735659109490936 /kaggle/input/lgbm-exp-01\n",
      "C-index 0.6719739976829171 /kaggle/input/xgboost-exp-02\n",
      "C-index 0.6715438291634074 /kaggle/input/catboost-exp-02\n",
      "C-index 0.6744113273004797 /kaggle/input/lgbm-exp-03\n",
      "C-index 0.6750446351219317 /kaggle/input/catboost-exp-03\n",
      "C-index 0.6692934020445873 /kaggle/input/tabm-exp-01\n",
      "C-index 0.6672504731273489 /kaggle/input/nn-exp-01\n",
      "C-index 0.6082304286386713 /kaggle/input/tn-exp-01\n",
      "C-index 0.6609106027219831 /kaggle/input/tf-exp-01\n",
      "C-index 0.6061054384127524 /kaggle/input/svr-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d61cf6b7d348>:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index 0.6775546112659996 /kaggle/input/abd-exp-01\n",
      "C-index 0.6228381497451487 /kaggle/input/catboost-exp-04\n",
      "C-index 0.6216961934710434 /kaggle/input/lgbm-exp-04\n",
      "\n",
      "Best single model is /kaggle/input/abd-exp-01 with C-Index = 0.6775546112659996\n"
     ]
    }
   ],
   "source": [
    "best_score    = 0\n",
    "best_index    = -1\n",
    "best_ensemble = 0\n",
    "\n",
    "for k,name in enumerate(experiments):\n",
    "    s, oof = compute_metric_cindex(name)\n",
    "    if s > best_score:\n",
    "        best_score    = s\n",
    "        best_index    = name\n",
    "        best_ensemble = oof\n",
    "        \n",
    "    print(f'C-index {s} {name}') \n",
    "print()\n",
    "print(f'Best single model is {best_index} with C-Index = {best_score}')\n",
    "experiments.remove(best_index)\n",
    "first_best_index = best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd9cdd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:29:56.274043Z",
     "iopub.status.busy": "2025-01-25T14:29:56.273339Z",
     "iopub.status.idle": "2025-01-25T14:29:56.280502Z",
     "shell.execute_reply": "2025-01-25T14:29:56.279617Z"
    },
    "papermill": {
     "duration": 0.020654,
     "end_time": "2025-01-25T14:29:56.282073",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.261419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/xgboost-exp-01',\n",
       " '/kaggle/input/catboost-exp-01',\n",
       " '/kaggle/input/lgbm-exp-01',\n",
       " '/kaggle/input/xgboost-exp-02',\n",
       " '/kaggle/input/catboost-exp-02',\n",
       " '/kaggle/input/lgbm-exp-03',\n",
       " '/kaggle/input/catboost-exp-03',\n",
       " '/kaggle/input/tabm-exp-01',\n",
       " '/kaggle/input/nn-exp-01',\n",
       " '/kaggle/input/tn-exp-01',\n",
       " '/kaggle/input/tf-exp-01',\n",
       " '/kaggle/input/svr-exp-01',\n",
       " '/kaggle/input/catboost-exp-04',\n",
       " '/kaggle/input/lgbm-exp-04']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a248369",
   "metadata": {
    "papermill": {
     "duration": 0.010927,
     "end_time": "2025-01-25T14:29:56.304202",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.293275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 5: Iterations for hill climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "094a9ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:29:56.327516Z",
     "iopub.status.busy": "2025-01-25T14:29:56.327184Z",
     "iopub.status.idle": "2025-01-25T14:29:56.331020Z",
     "shell.execute_reply": "2025-01-25T14:29:56.330158Z"
    },
    "papermill": {
     "duration": 0.017081,
     "end_time": "2025-01-25T14:29:56.332438",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.315357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_NEGATIVE_WGT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a45e0f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:29:56.356044Z",
     "iopub.status.busy": "2025-01-25T14:29:56.355639Z",
     "iopub.status.idle": "2025-01-25T14:29:56.359820Z",
     "shell.execute_reply": "2025-01-25T14:29:56.358877Z"
    },
    "papermill": {
     "duration": 0.017655,
     "end_time": "2025-01-25T14:29:56.361372",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.343717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices        = [best_index]\n",
    "old_best_score = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b772d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:29:56.385036Z",
     "iopub.status.busy": "2025-01-25T14:29:56.384689Z",
     "iopub.status.idle": "2025-01-25T14:29:56.389198Z",
     "shell.execute_reply": "2025-01-25T14:29:56.388199Z"
    },
    "papermill": {
     "duration": 0.017956,
     "end_time": "2025-01-25T14:29:56.390819",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.372863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREPARE/MOVE VARIABLES TO GPU FOR SPEED UP\n",
    "best_ensemble = best_ensemble\n",
    "start         = -0.50\n",
    "if not USE_NEGATIVE_WGT: start = 0.01\n",
    "ww            = np.arange(start,0.51,0.01) # GPU\n",
    "nn            = len(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cffd4f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:29:56.414184Z",
     "iopub.status.busy": "2025-01-25T14:29:56.413841Z",
     "iopub.status.idle": "2025-01-25T14:29:56.418090Z",
     "shell.execute_reply": "2025-01-25T14:29:56.417043Z"
    },
    "papermill": {
     "duration": 0.017763,
     "end_time": "2025-01-25T14:29:56.419675",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.401912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HILL CLIMBING\n",
    "models  = [best_index]\n",
    "weights = []\n",
    "metrics = [best_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9050fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:29:56.443107Z",
     "iopub.status.busy": "2025-01-25T14:29:56.442766Z",
     "iopub.status.idle": "2025-01-25T14:29:56.449656Z",
     "shell.execute_reply": "2025-01-25T14:29:56.448811Z"
    },
    "papermill": {
     "duration": 0.020376,
     "end_time": "2025-01-25T14:29:56.451226",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.430850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/kaggle/input/abd-exp-01'],\n",
       " [0.6775546112659996],\n",
       " array([-5.0000000e-01, -4.9000000e-01, -4.8000000e-01, -4.7000000e-01,\n",
       "        -4.6000000e-01, -4.5000000e-01, -4.4000000e-01, -4.3000000e-01,\n",
       "        -4.2000000e-01, -4.1000000e-01, -4.0000000e-01, -3.9000000e-01,\n",
       "        -3.8000000e-01, -3.7000000e-01, -3.6000000e-01, -3.5000000e-01,\n",
       "        -3.4000000e-01, -3.3000000e-01, -3.2000000e-01, -3.1000000e-01,\n",
       "        -3.0000000e-01, -2.9000000e-01, -2.8000000e-01, -2.7000000e-01,\n",
       "        -2.6000000e-01, -2.5000000e-01, -2.4000000e-01, -2.3000000e-01,\n",
       "        -2.2000000e-01, -2.1000000e-01, -2.0000000e-01, -1.9000000e-01,\n",
       "        -1.8000000e-01, -1.7000000e-01, -1.6000000e-01, -1.5000000e-01,\n",
       "        -1.4000000e-01, -1.3000000e-01, -1.2000000e-01, -1.1000000e-01,\n",
       "        -1.0000000e-01, -9.0000000e-02, -8.0000000e-02, -7.0000000e-02,\n",
       "        -6.0000000e-02, -5.0000000e-02, -4.0000000e-02, -3.0000000e-02,\n",
       "        -2.0000000e-02, -1.0000000e-02,  4.4408921e-16,  1.0000000e-02,\n",
       "         2.0000000e-02,  3.0000000e-02,  4.0000000e-02,  5.0000000e-02,\n",
       "         6.0000000e-02,  7.0000000e-02,  8.0000000e-02,  9.0000000e-02,\n",
       "         1.0000000e-01,  1.1000000e-01,  1.2000000e-01,  1.3000000e-01,\n",
       "         1.4000000e-01,  1.5000000e-01,  1.6000000e-01,  1.7000000e-01,\n",
       "         1.8000000e-01,  1.9000000e-01,  2.0000000e-01,  2.1000000e-01,\n",
       "         2.2000000e-01,  2.3000000e-01,  2.4000000e-01,  2.5000000e-01,\n",
       "         2.6000000e-01,  2.7000000e-01,  2.8000000e-01,  2.9000000e-01,\n",
       "         3.0000000e-01,  3.1000000e-01,  3.2000000e-01,  3.3000000e-01,\n",
       "         3.4000000e-01,  3.5000000e-01,  3.6000000e-01,  3.7000000e-01,\n",
       "         3.8000000e-01,  3.9000000e-01,  4.0000000e-01,  4.1000000e-01,\n",
       "         4.2000000e-01,  4.3000000e-01,  4.4000000e-01,  4.5000000e-01,\n",
       "         4.6000000e-01,  4.7000000e-01,  4.8000000e-01,  4.9000000e-01,\n",
       "         5.0000000e-01]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models, metrics, ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d86360b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T14:29:56.475240Z",
     "iopub.status.busy": "2025-01-25T14:29:56.474860Z",
     "iopub.status.idle": "2025-01-25T16:06:41.719945Z",
     "shell.execute_reply": "2025-01-25T16:06:41.718736Z"
    },
    "papermill": {
     "duration": 5805.259026,
     "end_time": "2025-01-25T16:06:41.721566",
     "exception": false,
     "start_time": "2025-01-25T14:29:56.462540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d61cf6b7d348>:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration\n",
      "here -> /kaggle/input/xgboost-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tabm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/nn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tf-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/svr-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Added /kaggle/input/catboost-exp-02 with weight 0.3400, Score: 0.6795\n",
      "1th iteration\n",
      "here -> /kaggle/input/xgboost-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tabm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/nn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tf-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/svr-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: Added /kaggle/input/catboost-exp-01 with weight 0.3100, Score: 0.6813\n",
      "2th iteration\n",
      "here -> /kaggle/input/xgboost-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tabm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/nn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tf-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/svr-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3: Added /kaggle/input/nn-exp-01 with weight 0.1600, Score: 0.6817\n",
      "3th iteration\n",
      "here -> /kaggle/input/xgboost-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tabm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tf-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/svr-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4: Added /kaggle/input/tabm-exp-01 with weight 0.0900, Score: 0.6819\n",
      "4th iteration\n",
      "here -> /kaggle/input/xgboost-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tf-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/svr-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5: Added /kaggle/input/xgboost-exp-01 with weight 0.1200, Score: 0.6821\n",
      "5th iteration\n",
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tf-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/svr-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6: Added /kaggle/input/svr-exp-01 with weight -0.0200, Score: 0.6821\n",
      "6th iteration\n",
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tf-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7: Added /kaggle/input/tf-exp-01 with weight 0.0600, Score: 0.6822\n",
      "7th iteration\n",
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/tn-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8: Added /kaggle/input/tn-exp-01 with weight -0.0200, Score: 0.6822\n",
      "8th iteration\n",
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/xgboost-exp-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9: Added /kaggle/input/xgboost-exp-02 with weight 0.0500, Score: 0.6822\n",
      "9th iteration\n",
      "here -> /kaggle/input/lgbm-exp-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: Added /kaggle/input/lgbm-exp-01 with weight 0.0400, Score: 0.6823\n",
      "10th iteration\n",
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11: Added /kaggle/input/catboost-exp-03 with weight -0.0600, Score: 0.6823\n",
      "11th iteration\n",
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/catboost-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12: Added /kaggle/input/catboost-exp-04 with weight 0.0200, Score: 0.6823\n",
      "12th iteration\n",
      "here -> /kaggle/input/lgbm-exp-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13: Added /kaggle/input/lgbm-exp-03 with weight 0.0600, Score: 0.6823\n",
      "13th iteration\n",
      "here -> /kaggle/input/lgbm-exp-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14: Added /kaggle/input/lgbm-exp-04 with weight 0.0000, Score: 0.6823\n",
      "CPU times: user 1h 36min 45s, sys: 6.85 s, total: 1h 36min 52s\n",
      "Wall time: 1h 36min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "def optimize_ensemble(experiments, initial_ensemble, weights_range, score_function, max_iterations = 100):\n",
    "    \n",
    "    # Initialize variables\n",
    "    iteration  = 0\n",
    "    best_score = score_function(\n",
    "        initial_ensemble[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n",
    "        initial_ensemble[[\"ID\", \"predictions\"]].copy(),\n",
    "        \"ID\"\n",
    "    )\n",
    "    \n",
    "    model_weights         = {}\n",
    "    remaining_experiments = experiments.copy()\n",
    "    best_ensemble         = initial_ensemble.copy()\n",
    "    \n",
    "    while remaining_experiments and iteration < max_iterations:\n",
    "        print(f\"{iteration}th iteration\")\n",
    "        iteration += 1\n",
    "        best_iteration = {\n",
    "            'index' : -1,\n",
    "            'weight': 0,\n",
    "            'score' : best_score\n",
    "        }\n",
    "        \n",
    "        # Try each remaining model\n",
    "        for model_path in remaining_experiments:\n",
    "            try:\n",
    "                #print(f\"Iteration {iteration}: Trying model {model_path}\")\n",
    "                \n",
    "                # Load model OOF predictions\n",
    "                model_name = model_path.split(\"/\")[-1].replace('-', '_')\n",
    "                print(f\"here -> {model_path}\")\n",
    "                if model_path in [\"/kaggle/input/abd-exp-01\",\"/kaggle/input/lgbm-exp-04\", \"/kaggle/input/catboost-exp-01\", \"/kaggle/input/lgbm-exp-01\", \"/kaggle/input/lgbm-exp-03\"]:\n",
    "                    oof_path   = f\"{model_path}/{model_name}_oof.parquet\"\n",
    "                    model_oof  = pd.read_parquet(oof_path)\n",
    "                else:\n",
    "                    oof_path   = f\"{model_path}/{model_name}_oof.xlsx\"\n",
    "                    model_oof  = pd.read_excel(oof_path)\n",
    "                \n",
    "                # Try different weights\n",
    "                for weight in tqdm(weights_range, desc=f\"Testing weights for {model_name}\"):\n",
    "                    # Create potential ensemble\n",
    "                    potential_ensemble = pd.DataFrame({\n",
    "                        \"ID\": best_ensemble[\"ID\"],\n",
    "                        \"predictions\": (1 - weight) * rankdata(best_ensemble[\"predictions\"]) + \n",
    "                                     weight * rankdata(model_oof[\"predictions\"])\n",
    "                    })\n",
    "                    \n",
    "                    # Evaluate new ensemble\n",
    "                    new_score = score_function(\n",
    "                        model_oof[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n",
    "                        potential_ensemble.copy(),\n",
    "                        \"ID\"\n",
    "                    )\n",
    "                    \n",
    "                    # Update best if improved\n",
    "                    if new_score > best_iteration['score']:\n",
    "                        best_iteration.update({\n",
    "                            'index' : model_path,\n",
    "                            'weight': weight,\n",
    "                            'score' : new_score\n",
    "                        })\n",
    "                \n",
    "                # Clean up\n",
    "                del model_oof\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {model_path}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Check if we found an improvement\n",
    "        if best_iteration['index'] == -1:\n",
    "            print(\"No improvement found, stopping\")\n",
    "            print(best_iteration)\n",
    "            break\n",
    "            \n",
    "        # Update ensemble with best model found\n",
    "        best_score                             = best_iteration['score']\n",
    "        model_weights[best_iteration['index']] = best_iteration['weight']\n",
    "        remaining_experiments.remove(best_iteration['index'])\n",
    "        \n",
    "        print(\n",
    "            f\"Iteration {iteration}: Added {best_iteration['index']} \"\n",
    "            f\"with weight {best_iteration['weight']:.4f}, \"\n",
    "            f\"Score: {best_iteration['score']:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Update best ensemble for next iteration\n",
    "        if best_iteration['index'] in [\"/kaggle/input/abd-exp-01\",\"/kaggle/input/lgbm-exp-04\", \"/kaggle/input/catboost-exp-01\", \"/kaggle/input/lgbm-exp-01\", \"/kaggle/input/lgbm-exp-03\"]:\n",
    "            model_oof = pd.read_parquet(\n",
    "            f\"{best_iteration['index']}/{best_iteration['index'].split('/')[-1].replace('-', '_')}_oof.parquet\"\n",
    "            )\n",
    "        else:\n",
    "            model_oof = pd.read_excel(\n",
    "            f\"{best_iteration['index']}/{best_iteration['index'].split('/')[-1].replace('-', '_')}_oof.xlsx\"\n",
    "            )\n",
    "                    \n",
    "        \n",
    "        best_ensemble[\"predictions\"] = (\n",
    "            (1 - best_iteration['weight']) * rankdata(best_ensemble[\"predictions\"]) + \n",
    "            best_iteration['weight'] * rankdata(model_oof[\"predictions\"])\n",
    "        )\n",
    "        \n",
    "    return model_weights, best_score\n",
    "\n",
    "\n",
    "model_weights, best_score = optimize_ensemble(experiments, best_ensemble, ww, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97425a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:42.922058Z",
     "iopub.status.busy": "2025-01-25T16:06:42.921700Z",
     "iopub.status.idle": "2025-01-25T16:06:42.928123Z",
     "shell.execute_reply": "2025-01-25T16:06:42.927093Z"
    },
    "papermill": {
     "duration": 0.60675,
     "end_time": "2025-01-25T16:06:42.929780",
     "exception": false,
     "start_time": "2025-01-25T16:06:42.323030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'/kaggle/input/catboost-exp-02': 0.34000000000000075,\n",
       "  '/kaggle/input/catboost-exp-01': 0.3100000000000007,\n",
       "  '/kaggle/input/nn-exp-01': 0.1600000000000006,\n",
       "  '/kaggle/input/tabm-exp-01': 0.09000000000000052,\n",
       "  '/kaggle/input/xgboost-exp-01': 0.12000000000000055,\n",
       "  '/kaggle/input/svr-exp-01': -0.019999999999999574,\n",
       "  '/kaggle/input/tf-exp-01': 0.0600000000000005,\n",
       "  '/kaggle/input/tn-exp-01': -0.019999999999999574,\n",
       "  '/kaggle/input/xgboost-exp-02': 0.05000000000000049,\n",
       "  '/kaggle/input/lgbm-exp-01': 0.04000000000000048,\n",
       "  '/kaggle/input/catboost-exp-03': -0.05999999999999961,\n",
       "  '/kaggle/input/catboost-exp-04': 0.020000000000000462,\n",
       "  '/kaggle/input/lgbm-exp-03': 0.0600000000000005,\n",
       "  '/kaggle/input/lgbm-exp-04': 4.440892098500626e-16},\n",
       " 0.682315760808041)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b20df10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:44.242070Z",
     "iopub.status.busy": "2025-01-25T16:06:44.241683Z",
     "iopub.status.idle": "2025-01-25T16:06:44.247734Z",
     "shell.execute_reply": "2025-01-25T16:06:44.246695Z"
    },
    "papermill": {
     "duration": 0.610065,
     "end_time": "2025-01-25T16:06:44.249379",
     "exception": false,
     "start_time": "2025-01-25T16:06:43.639314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/input/abd-exp-01',\n",
       " ['/kaggle/input/xgboost-exp-01',\n",
       "  '/kaggle/input/catboost-exp-01',\n",
       "  '/kaggle/input/lgbm-exp-01',\n",
       "  '/kaggle/input/xgboost-exp-02',\n",
       "  '/kaggle/input/catboost-exp-02',\n",
       "  '/kaggle/input/lgbm-exp-03',\n",
       "  '/kaggle/input/catboost-exp-03',\n",
       "  '/kaggle/input/tabm-exp-01',\n",
       "  '/kaggle/input/nn-exp-01',\n",
       "  '/kaggle/input/tn-exp-01',\n",
       "  '/kaggle/input/tf-exp-01',\n",
       "  '/kaggle/input/svr-exp-01',\n",
       "  '/kaggle/input/catboost-exp-04',\n",
       "  '/kaggle/input/lgbm-exp-04'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_best_index, experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d48256",
   "metadata": {
    "papermill": {
     "duration": 0.676312,
     "end_time": "2025-01-25T16:06:45.525490",
     "exception": false,
     "start_time": "2025-01-25T16:06:44.849178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 6: Inference on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e9549dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:46.851287Z",
     "iopub.status.busy": "2025-01-25T16:06:46.850829Z",
     "iopub.status.idle": "2025-01-25T16:06:46.860624Z",
     "shell.execute_reply": "2025-01-25T16:06:46.859631Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.738684,
     "end_time": "2025-01-25T16:06:46.862216",
     "exception": false,
     "start_time": "2025-01-25T16:06:46.123532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CFG:\n",
    "#     folds = 10\n",
    "\n",
    "# # https://www.kaggle.com/datasets/jsday96/mcts-tabm-models/data?select=TabMRegressor.py\n",
    "# class TabMRegressor:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         arch_type: str        = 'tabm-mini',\n",
    "#         backbone: dict        = {'type': 'MLP', 'n_blocks': 3, 'd_block': 512, 'dropout': 0.1},\n",
    "#         d_embedding: int      = 64,  # Only used for 'tabm-mini'\n",
    "#         bin_count: int        = 48,  # Only used for 'tabm-mini'\n",
    "#         k: int                = 32,\n",
    "#         learning_rate: float  = 1e-4,\n",
    "#         weight_decay: float   = 1e-3,\n",
    "#         clip_grad_norm: bool  = True,\n",
    "#         max_epochs: int       = 100,\n",
    "#         patience: int         = 15,\n",
    "#         batch_size: int       = 32,\n",
    "#         compile_model: bool   = False,\n",
    "#         device: Optional[str] = 'cuda:0',\n",
    "#         random_state: int     = 0,\n",
    "#         verbose: bool         = True\n",
    "#     ):\n",
    "#         self.arch_type = arch_type\n",
    "#         self.backbone = backbone\n",
    "#         self.d_embedding = d_embedding\n",
    "#         self.bin_count = bin_count\n",
    "#         self.k = k\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.weight_decay = weight_decay\n",
    "#         self.clip_grad_norm = clip_grad_norm\n",
    "#         self.max_epochs = max_epochs\n",
    "#         self.patience = patience\n",
    "#         self.batch_size = batch_size\n",
    "#         self.compile_model = compile_model\n",
    "#         self.device = torch.device(device if device else ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "#         self.random_state = random_state\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#     def fit(\n",
    "#         self,\n",
    "#         X: pd.DataFrame,\n",
    "#         y: np.array,\n",
    "#         eval_set: Tuple[pd.DataFrame, np.array]\n",
    "#     ):\n",
    "#         # PREPROCESS DATA.\n",
    "#         X_cat_train, X_cont_train, cat_cardinalities, y_train = self._preprocess_data(X, y, training=True)\n",
    "#         X_cat_val, X_cont_val, _, y_val = self._preprocess_data(eval_set[0], eval_set[1], training=False)\n",
    "\n",
    "#         # CREATE MODEL & TRAINING ALGO.\n",
    "#         bins = rtdl_num_embeddings.compute_bins(X_cont_train, n_bins=self.bin_count) if self.arch_type == 'tabm-mini' else None\n",
    "#         self.model = Model(\n",
    "#             n_num_features=X_cont_train.shape[1],\n",
    "#             cat_cardinalities=cat_cardinalities,\n",
    "#             n_classes=None,\n",
    "#             backbone=self.backbone,\n",
    "#             bins=bins,\n",
    "#             num_embeddings=(\n",
    "#                 None\n",
    "#                 if bins is None\n",
    "#                 else {\n",
    "#                     'type': 'PiecewiseLinearEmbeddings',\n",
    "#                     'd_embedding': self.d_embedding,\n",
    "#                     'activation': True,\n",
    "#                     'version': 'B',\n",
    "#                 }\n",
    "#             ),\n",
    "#             arch_type=self.arch_type,\n",
    "#             k=self.k,\n",
    "#         ).to(self.device)\n",
    "#         optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "#         if self.compile_model:\n",
    "#             self.model = torch.compile(self.model)\n",
    "\n",
    "#         loss_fn = torch.nn.MSELoss().to(self.device)\n",
    "#         # TRAIN & TEST MODEL.\n",
    "#         best = {\n",
    "#             'epoch': -1,\n",
    "#             'eval_loss': math.inf,\n",
    "#             'model_state_dict': None,\n",
    "#         }\n",
    "#         remaining_patience = self.patience\n",
    "#         epoch_size = math.ceil(len(X) / self.batch_size)\n",
    "\n",
    "\n",
    "#         for epoch in range(self.max_epochs):\n",
    "#             # TRAIN.\n",
    "#             optimizer.zero_grad()\n",
    "#             train_losses = []\n",
    "#             progress_bar = torch.randperm(len(y_train), device=self.device).split(self.batch_size)\n",
    "#             progress_bar = tqdm(progress_bar, desc=f'Epoch {epoch}', total=epoch_size) if self.verbose else progress_bar\n",
    "#             for batch_idx in progress_bar:\n",
    "#                 self.model.train()\n",
    "\n",
    "#                 with torch.amp.autocast(device_type='cuda', dtype = torch.bfloat16):\n",
    "#                     y_pred = self.model(\n",
    "#                         X_cont_train[batch_idx],\n",
    "#                         X_cat_train[batch_idx],\n",
    "#                     ).squeeze(-1).float()\n",
    "\n",
    "#                 loss = loss_fn(y_pred.flatten(0, 1), y_train[batch_idx].repeat_interleave(self.k))\n",
    "#                 loss.backward()\n",
    "#                 if self.clip_grad_norm:\n",
    "#                     torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "#                 optimizer.step()\n",
    "\n",
    "#                 train_losses.append(loss.item())\n",
    "\n",
    "\n",
    "#              # EVALUATE.\n",
    "#             self.model.eval()\n",
    "#             val_losses = []\n",
    "#             with torch.no_grad():\n",
    "#                 for batch_idx in torch.arange(0, len(y_val), self.batch_size, device=self.device):\n",
    "#                     y_pred = self.model(\n",
    "#                         X_cont_val[batch_idx:batch_idx+self.batch_size],\n",
    "#                         X_cat_val[batch_idx:batch_idx+self.batch_size],\n",
    "#                     ).squeeze(-1).float()\n",
    "\n",
    "#                     loss = loss_fn(y_pred.flatten(0, 1), y_val[batch_idx:batch_idx+self.batch_size].repeat_interleave(self.k))\n",
    "#                     val_losses.append(loss.item())\n",
    "\n",
    "\n",
    "#             # PRINT INFO.\n",
    "#             mean_train_loss = np.mean(train_losses)\n",
    "#             mean_val_loss = np.mean(val_losses)\n",
    "#             if self.verbose:\n",
    "#                 print(f'Epoch {epoch} | Train Loss: {mean_train_loss} | Val Loss: {mean_val_loss}')\n",
    "\n",
    "\n",
    "#             # COMPARE TO BEST.\n",
    "#             if mean_val_loss < best['eval_loss']:\n",
    "#                 best['epoch'] = epoch\n",
    "#                 best['eval_loss'] = mean_val_loss\n",
    "#                 best['model_state_dict'] = self.model.state_dict()\n",
    "#                 remaining_patience = self.patience\n",
    "                \n",
    "#                 if self.verbose:\n",
    "#                     print('🌸 New best epoch! 🌸')\n",
    "#             else:\n",
    "#                 remaining_patience -= 1\n",
    "\n",
    "#             # EARLY STOPPING.\n",
    "#             if remaining_patience == 0:\n",
    "#                 break\n",
    "\n",
    "#             # RESTORE BEST MODEL.\n",
    "#             self.model.load_state_dict(best['model_state_dict'])\n",
    "\n",
    "\n",
    "#     def predict(\n",
    "#         self,\n",
    "#         X: pd.DataFrame,\n",
    "#         batch_size: Optional[int] = 8096\n",
    "#     ) -> np.ndarray:\n",
    "#         # PREPROCESS DATA.\n",
    "#         X_cat, X_cont, _, _ = self._preprocess_data(X, y=None, training=False)\n",
    "\n",
    "#         # PREDICT.\n",
    "#         self.model.eval()\n",
    "#         y_pred = []\n",
    "#         with torch.no_grad():\n",
    "#             for batch_idx in torch.arange(0, len(X), batch_size, device=self.device):\n",
    "#                 y_pred.append(\n",
    "#                     self.model(\n",
    "#                         X_cont[batch_idx:batch_idx+batch_size],\n",
    "#                         X_cat[batch_idx:batch_idx+batch_size],\n",
    "#                     ).squeeze(-1).float().cpu().numpy()\n",
    "#                 )\n",
    "\n",
    "#         y_pred = np.concatenate(y_pred)\n",
    "\n",
    "\n",
    "#         # DENORMALIZE TARGETS.\n",
    "#         y_pred = y_pred * self._target_std + self._target_mean\n",
    "\n",
    "\n",
    "#         # COMPUTE ENSEMBLE MEAN.\n",
    "#         y_pred = np.mean(y_pred, axis=1)\n",
    "\n",
    "#         return y_pred\n",
    "\n",
    "\n",
    "#     def _preprocess_data(self, X: pd.DataFrame, y: pd.Series, training: bool):\n",
    "#         # PICK NON-CONSTANT COLUMNS.\n",
    "#         if training:\n",
    "#             self._non_constant_columns = X.columns[X.nunique() > 1]\n",
    "\n",
    "#         X = X[self._non_constant_columns]\n",
    "\n",
    "#         # SEPARATE CATEGORICAL & CONTINUOUS FEATURES.\n",
    "#         categorical_features = [col for col in X.columns if X[col].dtype.name == 'object']\n",
    "#         X_cat = X[categorical_features].to_numpy()\n",
    "#         X_cont = X.drop(columns=categorical_features).to_numpy()\n",
    "\n",
    "#         # ENCODE CATEGORICAL FEATURES.\n",
    "#         cat_cardinalities = [X[col].nunique() for col in categorical_features]\n",
    "\n",
    "#         if training:\n",
    "#             self._categorical_encoders = [\n",
    "#                 OrdinalEncoder()\n",
    "#                 for _ in range(X_cat.shape[1])\n",
    "#             ]\n",
    "#         X_cat = np.concatenate([\n",
    "#             encoder.fit_transform(X_cat[:, i:i+1])\n",
    "#             for i, encoder in enumerate(self._categorical_encoders)\n",
    "#         ], axis=1)\n",
    "\n",
    "#         # NORMALIZE TARGETS.\n",
    "#         if training:\n",
    "#             self._target_mean = y.mean()\n",
    "#             self._target_std = y.std()\n",
    "\n",
    "#             y = (y - self._target_mean) / self._target_std\n",
    "\n",
    "\n",
    "#         # SCALE CONTINUOUS FEATURES.\n",
    "#         if training:\n",
    "#             noise = (\n",
    "#                 np.random.default_rng(0)\n",
    "#                 .normal(0.0, 1e-5, X_cont.shape)\n",
    "#                 .astype(X_cont.dtype)\n",
    "#             )\n",
    "#             self._cont_feature_preprocessor = QuantileTransformer(\n",
    "#                 n_quantiles=max(min(len(X) // 30, 1000), 10),\n",
    "#                 output_distribution='normal',\n",
    "#                 subsample=10**9,\n",
    "#             ).fit(X_cont + noise)\n",
    "\n",
    "#         X_cont = self._cont_feature_preprocessor.transform(X_cont)\n",
    "\n",
    "\n",
    "#         # CONVERT TO TENSORS.\n",
    "#         X_cat = torch.tensor(X_cat, dtype=torch.long, device=self.device)\n",
    "#         X_cont = torch.tensor(X_cont, dtype=torch.float32, device=self.device)\n",
    "\n",
    "#         if y is not None:\n",
    "#             y = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "\n",
    "#         return X_cat, X_cont, cat_cardinalities, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a792b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:48.094770Z",
     "iopub.status.busy": "2025-01-25T16:06:48.094372Z",
     "iopub.status.idle": "2025-01-25T16:06:48.098306Z",
     "shell.execute_reply": "2025-01-25T16:06:48.097307Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.61844,
     "end_time": "2025-01-25T16:06:48.099899",
     "exception": false,
     "start_time": "2025-01-25T16:06:47.481459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_tabm_features(data):\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n",
    "#     FEATURES = [c for c in data.columns if not c in RMV]\n",
    "    \n",
    "#     RMV              = ['ID']\n",
    "#     X_test           = data.drop(RMV, axis=1)\n",
    "#     y_pred           = data[['ID']]\n",
    "    \n",
    "#     #print(\"X_test shape:\", X_test.shape, '\\n')\n",
    "    \n",
    "#     cat_cols         = X_test.select_dtypes(include=['object']).columns.tolist()\n",
    "#     num_cols         = X_test.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    \n",
    "#     # Preprocessing categorical\n",
    "#     imputer          = SimpleImputer(strategy='constant', fill_value='NAN')\n",
    "#     X_test[cat_cols] = imputer.fit_transform(X_test[cat_cols])\n",
    "\n",
    "#     # Preprocessing numerical\n",
    "#     imputer          = SimpleImputer(strategy=\"median\")\n",
    "#     X_test[num_cols] = imputer.fit_transform(X_test[num_cols])\n",
    "\n",
    "#     return X_test,FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ff7848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:49.385154Z",
     "iopub.status.busy": "2025-01-25T16:06:49.384804Z",
     "iopub.status.idle": "2025-01-25T16:06:49.389193Z",
     "shell.execute_reply": "2025-01-25T16:06:49.388169Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.607584,
     "end_time": "2025-01-25T16:06:49.390982",
     "exception": false,
     "start_time": "2025-01-25T16:06:48.783398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def prepare_features(model_path, train, test):\n",
    "\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\"]\n",
    "#     FEATURES = [c for c in train.columns if not c in RMV]\n",
    "#     #print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n",
    "    \n",
    "\n",
    "#     CATS = []\n",
    "#     for c in FEATURES:\n",
    "#         if train[c].dtype==\"object\":\n",
    "#             CATS.append(c)\n",
    "#             train[c] = train[c].fillna(\"NAN\")\n",
    "#             test[c]  = test[c].fillna(\"NAN\")\n",
    "#         elif \"DeepTabels\" in model_path or \"tn\" in model_path or \"svr\" in model_path:\n",
    "#             train[c] = train[c].fillna(-1)\n",
    "#             test[c]  = test[c].fillna(-1)\n",
    "            \n",
    "        \n",
    "#     #print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n",
    "    \n",
    "#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#     #print(\"Combined data shape:\", combined.shape )\n",
    "    \n",
    "#     # LABEL ENCODE CATEGORICAL FEATURES\n",
    "#     #print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n",
    "#     for c in FEATURES:\n",
    "    \n",
    "#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "#         if c in CATS:\n",
    "#             #print(f\"{c}, \",end=\"\")\n",
    "#             combined[c],_ = combined[c].factorize()\n",
    "#             combined[c]  -= combined[c].min()\n",
    "#             combined[c]   = combined[c].astype(\"int32\")\n",
    "#             combined[c]   = combined[c].astype(\"category\")\n",
    "            \n",
    "#         # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "#         else:\n",
    "#             if combined[c].dtype ==\"float64\":\n",
    "#                 combined[c]      = combined[c].astype(\"float32\")\n",
    "#             if combined[c].dtype ==\"int64\":\n",
    "#                 combined[c]      = combined[c].astype(\"int32\")\n",
    "        \n",
    "#     train = combined.iloc[:len(train)].copy()\n",
    "#     test  = combined.iloc[len(train):].reset_index(drop=True).copy()\n",
    "                \n",
    "#     return train, test, FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e17a6ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:50.673716Z",
     "iopub.status.busy": "2025-01-25T16:06:50.673330Z",
     "iopub.status.idle": "2025-01-25T16:06:50.677846Z",
     "shell.execute_reply": "2025-01-25T16:06:50.676804Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.688866,
     "end_time": "2025-01-25T16:06:50.679554",
     "exception": false,
     "start_time": "2025-01-25T16:06:49.990688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_nn_features(train, test):\n",
    "    \n",
    "#     CAT_SIZE = []\n",
    "#     CAT_EMB  = []\n",
    "#     NUMS     = []\n",
    "#     CATS     = []\n",
    "\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n",
    "#     FEATURES = [c for c in train.columns if not c in RMV]\n",
    "    \n",
    "#     for c in FEATURES:\n",
    "#         if train[c].dtype==\"object\":\n",
    "#             train[c] = train[c].fillna(\"NAN\")\n",
    "#             test[c]  = test[c].fillna(\"NAN\")\n",
    "#             CATS.append(c)\n",
    "#         elif not \"age\" in c:\n",
    "#             train[c] = train[c].astype(\"str\")\n",
    "#             test[c]  = test[c].astype(\"str\")\n",
    "#             CATS.append(c)\n",
    "\n",
    "\n",
    "#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#     for c in FEATURES:\n",
    "#         if c in CATS:\n",
    "#             # LABEL ENCODE\n",
    "#             combined[c],_ = combined[c].factorize()\n",
    "#             combined[c] -= combined[c].min()\n",
    "#             combined[c] = combined[c].astype(\"int32\")\n",
    "#             #combined[c] = combined[c].astype(\"category\")\n",
    "\n",
    "#             n = combined[c].nunique()\n",
    "#             mn = combined[c].min()\n",
    "#             mx = combined[c].max()\n",
    "#             #print(f'{c} has ({n}) unique values')\n",
    "    \n",
    "#             CAT_SIZE.append(mx+1) \n",
    "#             CAT_EMB.append( int(np.ceil( np.sqrt(mx+1))) ) \n",
    "#         else:\n",
    "#             if combined[c].dtype==\"float64\":\n",
    "#                 combined[c] = combined[c].astype(\"float32\")\n",
    "#             if combined[c].dtype==\"int64\":\n",
    "#                 combined[c] = combined[c].astype(\"int32\")\n",
    "                \n",
    "#             m = combined[c].mean()\n",
    "#             s = combined[c].std()\n",
    "#             combined[c] = (combined[c]-m)/s\n",
    "#             combined[c] = combined[c].fillna(0)\n",
    "            \n",
    "#             NUMS.append(c)\n",
    "\n",
    "#     train = combined.iloc[:len(train)].copy()\n",
    "#     test = combined.iloc[len(train):].reset_index(drop=True).copy()\n",
    "\n",
    "#     return test[CATS], test[NUMS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c36f8356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:51.888410Z",
     "iopub.status.busy": "2025-01-25T16:06:51.888029Z",
     "iopub.status.idle": "2025-01-25T16:06:51.892262Z",
     "shell.execute_reply": "2025-01-25T16:06:51.891194Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.605372,
     "end_time": "2025-01-25T16:06:51.893838",
     "exception": false,
     "start_time": "2025-01-25T16:06:51.288466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_tf_features(train, test):\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"y_na\",\"fold\"]\n",
    "#     FEATURES = [c for c in train.columns if not c in RMV]\n",
    "\n",
    "\n",
    "#     test                             = test.replace('Not done', 'missing')\n",
    "#     test                             = test.replace('Not tested', 'missing')\n",
    "    \n",
    "#     test['na_count']                 = test.isna().sum(axis=1)\n",
    "#     test['age_karnofsky']            = test['age_at_hct'] * test['karnofsky_score']\n",
    "#     test['age_comorbidity']          = test['age_at_hct'] * test['comorbidity_score']\n",
    "#     test['donor_recipient_age_diff'] = abs(test['donor_age'] - test['age_at_hct'])\n",
    "#     test['hla_match_ratio']          = (test['hla_high_res_8'] + test['hla_low_res_8']) / 16\n",
    "#     test['age_squared']              = test['age_at_hct'] ** 2\n",
    "#     test['karnofsky_squared']        = test['karnofsky_score'] ** 2\n",
    "#     test['16?']                      = np.where(test['age_at_hct']<=16,1,0)\n",
    "    \n",
    "#     FEATURES.extend([\"na_count\", \"age_karnofsky\", \"age_comorbidity\", \"donor_recipient_age_diff\", \"hla_match_ratio\", \"age_squared\", \"karnofsky_squared\", \"16?\"])\n",
    "\n",
    "#     CATS = []\n",
    "#     for c in FEATURES:\n",
    "#         if test[c].dtype==\"object\":\n",
    "#             CATS.append(c)\n",
    "#             test[c] = test[c].fillna(\"missing\")\n",
    "\n",
    "#     for c in FEATURES:\n",
    "#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "#         if c in CATS:\n",
    "#             #print(f\"{c}, \",end=\"\")\n",
    "#             test[c],_ = test[c].factorize()\n",
    "#             test[c]  -= test[c].min()\n",
    "#             test[c]   = test[c].astype(\"int32\")\n",
    "#             test[c]   = test[c].astype(\"category\")\n",
    "#         else:\n",
    "#             if test[c].dtype == \"float64\":\n",
    "#                 test[c]      = test[c].astype(\"float32\")\n",
    "#             if test[c].dtype ==\"int64\":\n",
    "#                 test[c]      = test[c].astype(\"int32\")\n",
    "    \n",
    "#     return test, FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2ed39a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:53.192227Z",
     "iopub.status.busy": "2025-01-25T16:06:53.191675Z",
     "iopub.status.idle": "2025-01-25T16:06:53.198566Z",
     "shell.execute_reply": "2025-01-25T16:06:53.197413Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.6151,
     "end_time": "2025-01-25T16:06:53.200578",
     "exception": false,
     "start_time": "2025-01-25T16:06:52.585478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# imputer               = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# FOLDS = 10\n",
    "\n",
    "# def inference(model_path, train, test_df):\n",
    "    \n",
    "#     path = model_path.split('/')[-1]\n",
    "#     file = path.replace('-','_')\n",
    "\n",
    "#     if \"dt\" not in model_path:\n",
    "#         with open(f\"/kaggle/input/{path}/{file}.pkl\", 'rb') as f:\n",
    "#             models = pickle.load(f)\n",
    "            \n",
    "#     print(\"All models are loaded successfully....!\")\n",
    "\n",
    "#     test_predictions = np.zeros(len(test_df))\n",
    "\n",
    "#     for fold in tqdm(range(FOLDS)):\n",
    "#         if \"dt\" in model_path:\n",
    "#             # model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "#             # train, test, FEATURES   = prepare_features(model_path, train, test_df)\n",
    "#             # model                   = tf.keras.models.load_model(model_path+f\"/model_fold_{fold}.keras\", custom_objects=dt.__dict__, compile=)\n",
    "#             # fold_preds              = model.predict(test.copy())\n",
    "#             # fold_preds              = fold_preds.flatten()\n",
    "#             pass\n",
    "#         else:\n",
    "#             model  = models[fold]\n",
    "            \n",
    "            \n",
    "#         if \"svr\" in model_path:\n",
    "#             if fold==0:\n",
    "#                 train, test, FEATURES = prepare_features(model_path, train.copy(), test_df.copy())\n",
    "\n",
    "#             # Handle missing values\n",
    "#             train_imputed         = imputer.fit_transform(train[FEATURES].copy())\n",
    "#             test_imputed          = imputer.transform(test[FEATURES])\n",
    "\n",
    "#             # Convert back to DataFrame to maintain feature names\n",
    "#             train_imputed         = pd.DataFrame(train_imputed, columns=FEATURES, index=train.index)\n",
    "#             test_imputed          = pd.DataFrame(test_imputed, columns=FEATURES, index=test.index)\n",
    "            \n",
    "#             # Scale features\n",
    "#             scaler.fit(train_imputed)\n",
    "#             test_scaled           = scaler.transform(test_imputed)\n",
    "            \n",
    "#             fold_preds            = model.predict(test_scaled)\n",
    "\n",
    "#         elif \"tn\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n",
    "                \n",
    "#             fold_preds              = model.predict(test[FEATURES].values).flatten()\n",
    "            \n",
    "#         elif \"nn\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 X_cat, X_num      = get_nn_features(train, test_df.copy())\n",
    "#             fold_preds        = model.predict([X_cat.values, X_num.values])\n",
    "#             fold_preds        = fold_preds.flatten()\n",
    "\n",
    "#         elif \"tf\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 test, FEATURES = get_tf_features(train.copy(),test_df.copy())\n",
    "#                 fold_preds     = model.predict(test[FEATURES].copy())\n",
    "\n",
    "#         elif \"tabm\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 test, FEATURES = get_tabm_features(test_df.copy())\n",
    "#             fold_preds              = model.predict(test[FEATURES].copy())\n",
    "            \n",
    "#         else: \n",
    "#             if fold == 0:\n",
    "#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n",
    "#             fold_preds              = model.predict(test[FEATURES].copy())\n",
    "            \n",
    "#         test_predictions += fold_preds\n",
    "    \n",
    "#     # Get the average predictionr\n",
    "#     test_predictions /= FOLDS\n",
    "        \n",
    "#     return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bd90124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:54.505158Z",
     "iopub.status.busy": "2025-01-25T16:06:54.504788Z",
     "iopub.status.idle": "2025-01-25T16:06:54.508568Z",
     "shell.execute_reply": "2025-01-25T16:06:54.507693Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.607091,
     "end_time": "2025-01-25T16:06:54.510160",
     "exception": false,
     "start_time": "2025-01-25T16:06:53.903069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
    "# test_df  = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ec43872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:55.796474Z",
     "iopub.status.busy": "2025-01-25T16:06:55.796137Z",
     "iopub.status.idle": "2025-01-25T16:06:55.799760Z",
     "shell.execute_reply": "2025-01-25T16:06:55.798796Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.689574,
     "end_time": "2025-01-25T16:06:55.801502",
     "exception": false,
     "start_time": "2025-01-25T16:06:55.111928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first_best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2377f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:57.084656Z",
     "iopub.status.busy": "2025-01-25T16:06:57.084281Z",
     "iopub.status.idle": "2025-01-25T16:06:57.088022Z",
     "shell.execute_reply": "2025-01-25T16:06:57.087027Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.687387,
     "end_time": "2025-01-25T16:06:57.089802",
     "exception": false,
     "start_time": "2025-01-25T16:06:56.402415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial_test_preds = inference(first_best_index, train_df, test_df)\n",
    "# initial_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "606d8ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:58.301223Z",
     "iopub.status.busy": "2025-01-25T16:06:58.300865Z",
     "iopub.status.idle": "2025-01-25T16:06:58.304893Z",
     "shell.execute_reply": "2025-01-25T16:06:58.303741Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.613138,
     "end_time": "2025-01-25T16:06:58.306517",
     "exception": false,
     "start_time": "2025-01-25T16:06:57.693379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc8dc5ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:06:59.593148Z",
     "iopub.status.busy": "2025-01-25T16:06:59.592759Z",
     "iopub.status.idle": "2025-01-25T16:06:59.596469Z",
     "shell.execute_reply": "2025-01-25T16:06:59.595663Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.612779,
     "end_time": "2025-01-25T16:06:59.597896",
     "exception": false,
     "start_time": "2025-01-25T16:06:58.985117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_preds = []\n",
    "# for model, weight in model_weights.items():\n",
    "#     print(f\"Using model : {model}\")\n",
    "#     test_df            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "    \n",
    "#     test_preds         = inference(model, train_df.copy(), test_df)\n",
    "#     test_preds         = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n",
    "#     initial_test_preds = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efc8861b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:07:00.882042Z",
     "iopub.status.busy": "2025-01-25T16:07:00.881646Z",
     "iopub.status.idle": "2025-01-25T16:07:00.885532Z",
     "shell.execute_reply": "2025-01-25T16:07:00.884680Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.609662,
     "end_time": "2025-01-25T16:07:00.886949",
     "exception": false,
     "start_time": "2025-01-25T16:07:00.277287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df               = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
    "# test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "# test_preds             = np.zeros(len(test_df))\n",
    "\n",
    "\n",
    "# preds_dict = {}\n",
    "# for model, weight in model_weights.items():\n",
    "#     print(f\"exp name : {model}\\n\")\n",
    "#     test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "#     test_preds             = inference(model, train_df.copy(), test_df.copy())\n",
    "#     test_preds             = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n",
    "#     initial_test_preds     = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06ee3877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:07:02.169450Z",
     "iopub.status.busy": "2025-01-25T16:07:02.169120Z",
     "iopub.status.idle": "2025-01-25T16:07:02.172698Z",
     "shell.execute_reply": "2025-01-25T16:07:02.171822Z"
    },
    "papermill": {
     "duration": 0.680107,
     "end_time": "2025-01-25T16:07:02.174245",
     "exception": false,
     "start_time": "2025-01-25T16:07:01.494138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "430410c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:07:03.403375Z",
     "iopub.status.busy": "2025-01-25T16:07:03.402886Z",
     "iopub.status.idle": "2025-01-25T16:07:03.407362Z",
     "shell.execute_reply": "2025-01-25T16:07:03.405978Z"
    },
    "papermill": {
     "duration": 0.630286,
     "end_time": "2025-01-25T16:07:03.409458",
     "exception": false,
     "start_time": "2025-01-25T16:07:02.779172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# potential_ensemble                = pd.DataFrame()\n",
    "# potential_ensemble[\"predictions\"] = test_preds\n",
    "# potential_ensemble[\"ID\"]          = test_df[\"ID\"]\n",
    "# new_score                         = score(test_df[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy(), potential_ensemble.copy(), \"ID\")\n",
    "# new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0c72a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:07:04.692872Z",
     "iopub.status.busy": "2025-01-25T16:07:04.692476Z",
     "iopub.status.idle": "2025-01-25T16:07:04.696345Z",
     "shell.execute_reply": "2025-01-25T16:07:04.695475Z"
    },
    "papermill": {
     "duration": 0.608159,
     "end_time": "2025-01-25T16:07:04.697973",
     "exception": false,
     "start_time": "2025-01-25T16:07:04.089814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ddfa8",
   "metadata": {
    "papermill": {
     "duration": 0.599049,
     "end_time": "2025-01-25T16:07:05.981613",
     "exception": false,
     "start_time": "2025-01-25T16:07:05.382564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 7: Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "135997d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-25T16:07:07.286686Z",
     "iopub.status.busy": "2025-01-25T16:07:07.286309Z",
     "iopub.status.idle": "2025-01-25T16:07:07.290073Z",
     "shell.execute_reply": "2025-01-25T16:07:07.289115Z"
    },
    "papermill": {
     "duration": 0.697216,
     "end_time": "2025-01-25T16:07:07.291707",
     "exception": false,
     "start_time": "2025-01-25T16:07:06.594491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n",
    "# sub.prediction = test_preds\n",
    "# sub.to_csv(\"submission.csv\",index=False)\n",
    "# print(\"Sub shape:\",sub.shape)\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ca642",
   "metadata": {
    "papermill": {
     "duration": 0.615669,
     "end_time": "2025-01-25T16:07:08.509418",
     "exception": false,
     "start_time": "2025-01-25T16:07:07.893749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6226248,
     "sourceId": 10097128,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6415434,
     "sourceId": 10370860,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6450507,
     "sourceId": 10409094,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211322530,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 216172723,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 216836411,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217481514,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217558741,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217813503,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217931837,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217941306,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218131499,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218144682,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218801338,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218802756,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219153168,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219154661,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219185495,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219195490,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6135.45991,
   "end_time": "2025-01-25T16:07:12.561058",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-25T14:24:57.101148",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
