{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49260117",
   "metadata": {
    "_cell_guid": "46a264b2-b97f-487b-9a3d-2597a0ecdc21",
    "_uuid": "9daabf89-8847-4537-a0b7-2a722b5c452d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012096,
     "end_time": "2025-02-18T06:47:37.309891",
     "exception": false,
     "start_time": "2025-02-18T06:47:37.297795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3862ace6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:47:37.333907Z",
     "iopub.status.busy": "2025-02-18T06:47:37.333542Z",
     "iopub.status.idle": "2025-02-18T06:48:03.146602Z",
     "shell.execute_reply": "2025-02-18T06:48:03.144790Z"
    },
    "papermill": {
     "duration": 25.828373,
     "end_time": "2025-02-18T06:48:03.149972",
     "exception": false,
     "start_time": "2025-02-18T06:47:37.321599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd==1.7.0) (1.26.4)\r\n",
      "autograd is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.7.0)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.13.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\r\n",
      "Building wheels for collected packages: autograd-gamma\r\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=c39c78a5080c06d73dad09c10c9a6dcd109390265c5db84ed2b08c6e914a56c9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/b5/e0/4c79e15c0b5f2c15ecf613c720bb20daab20a666eb67135155\r\n",
      "Successfully built autograd-gamma\r\n",
      "Installing collected packages: autograd-gamma\r\n",
      "Successfully installed autograd-gamma-0.5.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\r\n",
      "Installing collected packages: interface-meta\r\n",
      "Successfully installed interface-meta-1.3.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (2.1.4)\r\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.0.2) (1.16.0)\r\n",
      "Installing collected packages: formulaic\r\n",
      "Successfully installed formulaic-1.0.2\r\n",
      "Processing /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.13.1)\r\n",
      "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (2.1.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (3.7.1)\r\n",
      "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.7.0)\r\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (0.5.0)\r\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.0.2)\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.16.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.16.0)\r\n",
      "Installing collected packages: lifelines\r\n",
      "Successfully installed lifelines-0.30.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
    "!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30596aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:03.176239Z",
     "iopub.status.busy": "2025-02-18T06:48:03.175779Z",
     "iopub.status.idle": "2025-02-18T06:48:11.779593Z",
     "shell.execute_reply": "2025-02-18T06:48:11.778035Z"
    },
    "papermill": {
     "duration": 8.619282,
     "end_time": "2025-02-18T06:48:11.781612",
     "exception": false,
     "start_time": "2025-02-18T06:48:03.162330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/tabm-tabular-dl-library\r\n",
      "Processing /kaggle/input/tabm-tabular-dl-library/tabm-0.0.1.dev0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch<3,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tabm==0.0.1.dev0) (2.4.1+cu121)\r\n",
      "Processing /kaggle/input/tabm-tabular-dl-library/rtdl_num_embeddings-0.0.11-py3-none-any.whl (from tabm==0.0.1.dev0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.12->tabm==0.0.1.dev0) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.12->tabm==0.0.1.dev0) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.12->tabm==0.0.1.dev0) (1.3.0)\r\n",
      "Installing collected packages: rtdl_num_embeddings, tabm\r\n",
      "Successfully installed rtdl_num_embeddings-0.0.11 tabm-0.0.1.dev0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index -U --find-links=/kaggle/input/tabm-tabular-dl-library tabm==0.0.1.dev0\n",
    "!pip -q install /kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e919c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:11.806975Z",
     "iopub.status.busy": "2025-02-18T06:48:11.806528Z",
     "iopub.status.idle": "2025-02-18T06:48:16.081908Z",
     "shell.execute_reply": "2025-02-18T06:48:16.080448Z"
    },
    "papermill": {
     "duration": 4.29135,
     "end_time": "2025-02-18T06:48:16.085007",
     "exception": false,
     "start_time": "2025-02-18T06:48:11.793657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install /kaggle/input/tabpfn-v2/tabpfn-2.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20398faf",
   "metadata": {
    "papermill": {
     "duration": 0.012503,
     "end_time": "2025-02-18T06:48:16.110810",
     "exception": false,
     "start_time": "2025-02-18T06:48:16.098307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1 : Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671c4531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:16.137972Z",
     "iopub.status.busy": "2025-02-18T06:48:16.137559Z",
     "iopub.status.idle": "2025-02-18T06:48:36.054796Z",
     "shell.execute_reply": "2025-02-18T06:48:36.053130Z"
    },
    "papermill": {
     "duration": 19.933685,
     "end_time": "2025-02-18T06:48:36.057301",
     "exception": false,
     "start_time": "2025-02-18T06:48:16.123616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata \n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/tabm-tabular-dl-library')\n",
    "\n",
    "import os\n",
    "import tabm\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rtdl_num_embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import rankdata \n",
    "from colorama import Fore, Style\n",
    "from typing import Optional, Tuple\n",
    "from numpy.typing import ArrayLike\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "from sklearn.preprocessing import OrdinalEncoder, QuantileTransformer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.layers import Concatenate, BatchNormalization\n",
    "import tensorflow.keras.backend as K\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from tabpfn import TabPFNRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b3cae",
   "metadata": {
    "papermill": {
     "duration": 0.012475,
     "end_time": "2025-02-18T06:48:36.082313",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.069838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Experiments Paths  to add in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d91cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:36.110535Z",
     "iopub.status.busy": "2025-02-18T06:48:36.109715Z",
     "iopub.status.idle": "2025-02-18T06:48:36.117332Z",
     "shell.execute_reply": "2025-02-18T06:48:36.115523Z"
    },
    "papermill": {
     "duration": 0.023734,
     "end_time": "2025-02-18T06:48:36.119389",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.095655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "\"/kaggle/input/xgboost-exp-01\",\n",
    "\"/kaggle/input/catboost-exp-01\", \n",
    "\"/kaggle/input/lgbm-exp-01\",\n",
    "\"/kaggle/input/xgboost-exp-02\",\n",
    "\"/kaggle/input/catboost-exp-02\",\n",
    "\"/kaggle/input/lgbm-exp-03\",\n",
    "\"/kaggle/input/catboost-exp-03\",\n",
    "\"/kaggle/input/tabm-exp-01\",\n",
    "\"/kaggle/input/nn-exp-01\",\n",
    "\"/kaggle/input/tn-exp-01\",\n",
    "\"/kaggle/input/tf-exp-01\",\n",
    "\"/kaggle/input/svr-exp-01\",\n",
    "\"/kaggle/input/abd-exp-01\",\n",
    "\"/kaggle/input/catboost-exp-04\",\n",
    "\"/kaggle/input/lgbm-exp-04\",\n",
    "\"/kaggle/input/tabm-exp-02\",\n",
    "\"/kaggle/input/ds-exp-01\",\n",
    "\"/kaggle/input/nn-exp-02\",\n",
    "\"/kaggle/input/nn-exp-04\",\n",
    "#\"/kaggle/input/tabm-exp-03\",\n",
    "\"/kaggle/input/catboost-exp-05\",\n",
    "\"/kaggle/input/xgboost-exp-05\",\n",
    "\"/kaggle/input/lgbm-exp-05\",\n",
    "\"/kaggle/input/tn-exp-02\",\n",
    "#\"/kaggle/input/ag-exp-01\",\n",
    "\"/kaggle/input/vr-exp-01\",\n",
    "\"/kaggle/input/tt-exp-01\",\n",
    "\"/kaggle/input/en-exp-01\",\n",
    "\"/kaggle/input/en-exp-02\",\n",
    "\"/kaggle/input/nn-exp-05\",\n",
    "\"/kaggle/input/rf-exp-05\",\n",
    "\"/kaggle/input/mcts-exp-02\",\n",
    "\"/kaggle/input/catboost-exp-06\",\n",
    "\"/kaggle/input/xgboost-exp-06\",\n",
    "\"/kaggle/input/lgbm-exp-06\",\n",
    "\"/kaggle/input/nn-exp-06\",\n",
    "\"/kaggle/input/xgboost-exp-07\"\n",
    "# \"/kaggle/input/suv-ran-exp-01\" -> File not found\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb276d3a",
   "metadata": {
    "papermill": {
     "duration": 0.013908,
     "end_time": "2025-02-18T06:48:36.146228",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.132320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3 : Competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97e983c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:36.174377Z",
     "iopub.status.busy": "2025-02-18T06:48:36.173906Z",
     "iopub.status.idle": "2025-02-18T06:48:36.315752Z",
     "shell.execute_reply": "2025-02-18T06:48:36.314323Z"
    },
    "papermill": {
     "duration": 0.158824,
     "end_time": "2025-02-18T06:48:36.318283",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.159459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import numpy as np\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> y_pred = {'prediction': {0: 1.0, 1: 0.0, 2: 1.0}}\n",
    "    >>> y_pred = pd.DataFrame(y_pred)\n",
    "    >>> y_pred.insert(0, row_id_column_name, range(len(y_pred)))\n",
    "    >>> y_true = { 'efs': {0: 1.0, 1: 0.0, 2: 0.0}, 'efs_time': {0: 25.1234,1: 250.1234,2: 2500.1234}, 'race_group': {0: 'race_group_1', 1: 'race_group_1', 2: 'race_group_1'}}\n",
    "    >>> y_true = pd.DataFrame(y_true)\n",
    "    >>> y_true.insert(0, row_id_column_name, range(len(y_true)))\n",
    "    >>> score(y_true.copy(), y_pred.copy(), row_id_column_name)\n",
    "    0.75\n",
    "    \"\"\"\n",
    "\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    \n",
    "    event_label = 'efs'\n",
    "    interval_label = 'efs_time'\n",
    "    prediction_label = 'predictions'\n",
    "    for col in submission.columns:\n",
    "        if not pandas.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
    "    # Merging solution and submission dfs on ID\n",
    "    merged_df = pd.concat([solution, submission], axis=1)\n",
    "    merged_df.reset_index(inplace=True)\n",
    "    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n",
    "    metric_list = []\n",
    "\n",
    "    for race in merged_df_race_dict.keys():\n",
    "        # Retrieving values from y_test based on index\n",
    "        indices = sorted(merged_df_race_dict[race])\n",
    "        merged_df_race = merged_df.iloc[indices]\n",
    "        # Calculate the concordance index\n",
    "        c_index_race = concordance_index(\n",
    "                        merged_df_race[interval_label],\n",
    "                        -merged_df_race[prediction_label],\n",
    "                        merged_df_race[event_label])\n",
    "        metric_list.append(c_index_race)\n",
    "    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb4b3f",
   "metadata": {
    "papermill": {
     "duration": 0.011642,
     "end_time": "2025-02-18T06:48:36.342718",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.331076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4: Find best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138be2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:36.368853Z",
     "iopub.status.busy": "2025-02-18T06:48:36.368462Z",
     "iopub.status.idle": "2025-02-18T06:48:36.373685Z",
     "shell.execute_reply": "2025-02-18T06:48:36.372573Z"
    },
    "papermill": {
     "duration": 0.021206,
     "end_time": "2025-02-18T06:48:36.375832",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.354626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parquet_experiments = [\n",
    "    \"/kaggle/input/abd-exp-01\",\n",
    "    \"/kaggle/input/lgbm-exp-04\", \n",
    "    \"/kaggle/input/catboost-exp-01\", \n",
    "    \"/kaggle/input/lgbm-exp-01\", \n",
    "    \"/kaggle/input/lgbm-exp-03\", \n",
    "    \"/kaggle/input/ds-exp-01\",\n",
    "    \"/kaggle/input/nn-exp-02\",\n",
    "    \"/kaggle/input/nn-exp-04\",\n",
    "    \"/kaggle/input/tabm-exp-03\",\n",
    "    \"/kaggle/input/catboost-exp-05\",\n",
    "    \"/kaggle/input/xgboost-exp-05\",\n",
    "    \"/kaggle/input/lgbm-exp-05\",\n",
    "    \"/kaggle/input/tn-exp-02\",\n",
    "    #\"/kaggle/input/ag-exp-01\",\n",
    "    \"/kaggle/input/vr-exp-01\",\n",
    "    \"/kaggle/input/tt-exp-01\",\n",
    "    \"/kaggle/input/en-exp-01\",\n",
    "    \"/kaggle/input/svr-exp-01\",\n",
    "    \"/kaggle/input/en-exp-02\",\n",
    "    \"/kaggle/input/nn-exp-05\",\n",
    "    \"/kaggle/input/rf-exp-05\",\n",
    "    \"/kaggle/input/mcts-exp-02\",\n",
    "    \"/kaggle/input/catboost-exp-06\",\n",
    "    \"/kaggle/input/xgboost-exp-06\",\n",
    "    \"/kaggle/input/lgbm-exp-06\",\n",
    "    \"/kaggle/input/nn-exp-06\",\n",
    "    \"/kaggle/input/xgboost-exp-07\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa03e11a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:36.402911Z",
     "iopub.status.busy": "2025-02-18T06:48:36.402552Z",
     "iopub.status.idle": "2025-02-18T06:48:36.407803Z",
     "shell.execute_reply": "2025-02-18T06:48:36.406570Z"
    },
    "papermill": {
     "duration": 0.020817,
     "end_time": "2025-02-18T06:48:36.409584",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.388767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metric_cindex(oof, exp_name):    \n",
    "    y_true = oof[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "    y_pred = oof[[\"ID\",\"predictions\"]].copy()\n",
    "    return score(y_true.copy(), y_pred.copy(), \"ID\"), oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31ae4b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:48:36.435035Z",
     "iopub.status.busy": "2025-02-18T06:48:36.434655Z",
     "iopub.status.idle": "2025-02-18T06:53:09.503788Z",
     "shell.execute_reply": "2025-02-18T06:53:09.502518Z"
    },
    "papermill": {
     "duration": 273.08374,
     "end_time": "2025-02-18T06:53:09.505659",
     "exception": false,
     "start_time": "2025-02-18T06:48:36.421919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [04:09<00:00,  7.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize empty list to store individual prediction dataframes\n",
    "dfs_to_merge = []\n",
    "\n",
    "# Load first experiment to get the base structure\n",
    "base_exp = experiments[0]\n",
    "if base_exp in parquet_experiments:\n",
    "    base_df = pd.read_parquet(base_exp + '/' + (base_exp.split('/')[-1]).replace('-','_') + '_oof.parquet')\n",
    "else:\n",
    "    base_df = pd.read_excel(base_exp + '/' + (base_exp.split('/')[-1]).replace('-','_') + '_oof.xlsx')\n",
    "\n",
    "# Create base dataframe with ID and target variables\n",
    "preds_df = base_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "\n",
    "# Load and merge predictions from each experiment\n",
    "for exp_name in tqdm(experiments):\n",
    "    # Read the prediction file\n",
    "    if exp_name in parquet_experiments:\n",
    "        if \"mcts-exp-02\" in exp_name:\n",
    "            curr_df = pd.read_parquet(exp_name + '/mcts_exp_01' + '_oof.parquet')\n",
    "        else:\n",
    "            curr_df = pd.read_parquet(exp_name + '/' + (exp_name.split('/')[-1]).replace('-','_') + '_oof.parquet')\n",
    "    else:\n",
    "        curr_df = pd.read_excel(exp_name + '/' + (exp_name.split('/')[-1]).replace('-','_') + '_oof.xlsx')\n",
    "    \n",
    "    # Create a temporary dataframe with ID and predictions\n",
    "    temp_df = curr_df[[\"ID\", \"predictions\"]].copy()\n",
    "    temp_df = temp_df.rename(columns={\"predictions\": exp_name})\n",
    "    \n",
    "    # Merge with the main dataframe\n",
    "    preds_df = preds_df.merge(temp_df, on=\"ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08046f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:09.535007Z",
     "iopub.status.busy": "2025-02-18T06:53:09.534266Z",
     "iopub.status.idle": "2025-02-18T06:53:09.543050Z",
     "shell.execute_reply": "2025-02-18T06:53:09.541670Z"
    },
    "papermill": {
     "duration": 0.025039,
     "end_time": "2025-02-18T06:53:09.545253",
     "exception": false,
     "start_time": "2025-02-18T06:53:09.520214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28800, 39),\n",
       " Index(['ID', 'efs', 'efs_time', 'race_group', '/kaggle/input/xgboost-exp-01',\n",
       "        '/kaggle/input/catboost-exp-01', '/kaggle/input/lgbm-exp-01',\n",
       "        '/kaggle/input/xgboost-exp-02', '/kaggle/input/catboost-exp-02',\n",
       "        '/kaggle/input/lgbm-exp-03', '/kaggle/input/catboost-exp-03',\n",
       "        '/kaggle/input/tabm-exp-01', '/kaggle/input/nn-exp-01',\n",
       "        '/kaggle/input/tn-exp-01', '/kaggle/input/tf-exp-01',\n",
       "        '/kaggle/input/svr-exp-01', '/kaggle/input/abd-exp-01',\n",
       "        '/kaggle/input/catboost-exp-04', '/kaggle/input/lgbm-exp-04',\n",
       "        '/kaggle/input/tabm-exp-02', '/kaggle/input/ds-exp-01',\n",
       "        '/kaggle/input/nn-exp-02', '/kaggle/input/nn-exp-04',\n",
       "        '/kaggle/input/catboost-exp-05', '/kaggle/input/xgboost-exp-05',\n",
       "        '/kaggle/input/lgbm-exp-05', '/kaggle/input/tn-exp-02',\n",
       "        '/kaggle/input/vr-exp-01', '/kaggle/input/tt-exp-01',\n",
       "        '/kaggle/input/en-exp-01', '/kaggle/input/en-exp-02',\n",
       "        '/kaggle/input/nn-exp-05', '/kaggle/input/rf-exp-05',\n",
       "        '/kaggle/input/mcts-exp-02', '/kaggle/input/catboost-exp-06',\n",
       "        '/kaggle/input/xgboost-exp-06', '/kaggle/input/lgbm-exp-06',\n",
       "        '/kaggle/input/nn-exp-06', '/kaggle/input/xgboost-exp-07'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.shape, preds_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86fff4cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:09.574553Z",
     "iopub.status.busy": "2025-02-18T06:53:09.574165Z",
     "iopub.status.idle": "2025-02-18T06:53:09.581001Z",
     "shell.execute_reply": "2025-02-18T06:53:09.579926Z"
    },
    "papermill": {
     "duration": 0.023421,
     "end_time": "2025-02-18T06:53:09.582693",
     "exception": false,
     "start_time": "2025-02-18T06:53:09.559272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/xgboost-exp-01',\n",
       " '/kaggle/input/catboost-exp-01',\n",
       " '/kaggle/input/lgbm-exp-01',\n",
       " '/kaggle/input/xgboost-exp-02',\n",
       " '/kaggle/input/catboost-exp-02',\n",
       " '/kaggle/input/lgbm-exp-03',\n",
       " '/kaggle/input/catboost-exp-03',\n",
       " '/kaggle/input/tabm-exp-01',\n",
       " '/kaggle/input/nn-exp-01',\n",
       " '/kaggle/input/tn-exp-01',\n",
       " '/kaggle/input/tf-exp-01',\n",
       " '/kaggle/input/svr-exp-01',\n",
       " '/kaggle/input/abd-exp-01',\n",
       " '/kaggle/input/catboost-exp-04',\n",
       " '/kaggle/input/lgbm-exp-04',\n",
       " '/kaggle/input/tabm-exp-02',\n",
       " '/kaggle/input/ds-exp-01',\n",
       " '/kaggle/input/nn-exp-02',\n",
       " '/kaggle/input/nn-exp-04',\n",
       " '/kaggle/input/catboost-exp-05',\n",
       " '/kaggle/input/xgboost-exp-05',\n",
       " '/kaggle/input/lgbm-exp-05',\n",
       " '/kaggle/input/tn-exp-02',\n",
       " '/kaggle/input/vr-exp-01',\n",
       " '/kaggle/input/tt-exp-01',\n",
       " '/kaggle/input/en-exp-01',\n",
       " '/kaggle/input/en-exp-02',\n",
       " '/kaggle/input/nn-exp-05',\n",
       " '/kaggle/input/rf-exp-05',\n",
       " '/kaggle/input/mcts-exp-02',\n",
       " '/kaggle/input/catboost-exp-06',\n",
       " '/kaggle/input/xgboost-exp-06',\n",
       " '/kaggle/input/lgbm-exp-06',\n",
       " '/kaggle/input/nn-exp-06',\n",
       " '/kaggle/input/xgboost-exp-07']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e26d5542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:09.612319Z",
     "iopub.status.busy": "2025-02-18T06:53:09.611869Z",
     "iopub.status.idle": "2025-02-18T06:53:23.231726Z",
     "shell.execute_reply": "2025-02-18T06:53:23.230591Z"
    },
    "papermill": {
     "duration": 13.637211,
     "end_time": "2025-02-18T06:53:23.233587",
     "exception": false,
     "start_time": "2025-02-18T06:53:09.596376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index 0.6743662038463064 /kaggle/input/xgboost-exp-01\n",
      "C-index 0.673797469068503 /kaggle/input/catboost-exp-01\n",
      "C-index 0.6735659109490936 /kaggle/input/lgbm-exp-01\n",
      "C-index 0.6719739976829171 /kaggle/input/xgboost-exp-02\n",
      "C-index 0.6715438291634074 /kaggle/input/catboost-exp-02\n",
      "C-index 0.6744113273004797 /kaggle/input/lgbm-exp-03\n",
      "C-index 0.6750446351219317 /kaggle/input/catboost-exp-03\n",
      "C-index 0.6698445972872783 /kaggle/input/tabm-exp-01\n",
      "C-index 0.6672504731273489 /kaggle/input/nn-exp-01\n",
      "C-index 0.6082304286386713 /kaggle/input/tn-exp-01\n",
      "C-index 0.6609386133349129 /kaggle/input/tf-exp-01\n",
      "C-index 0.6204664346764159 /kaggle/input/svr-exp-01\n",
      "C-index 0.6775546112659996 /kaggle/input/abd-exp-01\n",
      "C-index 0.6228381497451487 /kaggle/input/catboost-exp-04\n",
      "C-index 0.6216961934710434 /kaggle/input/lgbm-exp-04\n",
      "C-index 0.6777472728532595 /kaggle/input/tabm-exp-02\n",
      "C-index 0.6427991982766068 /kaggle/input/ds-exp-01\n",
      "C-index 0.6541867987232884 /kaggle/input/nn-exp-02\n",
      "C-index 0.6794831551153862 /kaggle/input/nn-exp-04\n",
      "I am here\n",
      "C-index 0.680734863930053 /kaggle/input/catboost-exp-05\n",
      "C-index 0.6801801958617659 /kaggle/input/xgboost-exp-05\n",
      "C-index 0.6791851357350963 /kaggle/input/lgbm-exp-05\n",
      "C-index 0.659742829229569 /kaggle/input/tn-exp-02\n",
      "C-index 0.6754542289908226 /kaggle/input/vr-exp-01\n",
      "C-index 0.6051212359506114 /kaggle/input/tt-exp-01\n",
      "C-index 0.6244728416862964 /kaggle/input/en-exp-01\n",
      "C-index 0.6417663206377346 /kaggle/input/en-exp-02\n",
      "C-index 0.6794831551153862 /kaggle/input/nn-exp-05\n",
      "C-index 0.6511582598647447 /kaggle/input/rf-exp-05\n",
      "C-index 0.6113856489762708 /kaggle/input/mcts-exp-02\n",
      "C-index 0.6805225213899068 /kaggle/input/catboost-exp-06\n",
      "C-index 0.6795077628167032 /kaggle/input/xgboost-exp-06\n",
      "C-index 0.6791063706461627 /kaggle/input/lgbm-exp-06\n",
      "C-index 0.6804090466531342 /kaggle/input/nn-exp-06\n",
      "C-index 0.6797980742985197 /kaggle/input/xgboost-exp-07\n",
      "\n",
      "Best single model is /kaggle/input/catboost-exp-05 with C-Index = 0.680734863930053\n"
     ]
    }
   ],
   "source": [
    "best_score    = 0\n",
    "best_index    = -1\n",
    "best_ensemble = 0\n",
    "\n",
    "for k,name in enumerate(experiments):\n",
    "    if \"catboost-exp-05\" in name:\n",
    "        print(\"I am here\")\n",
    "    oof_pre = preds_df[[\"ID\",\"efs\",\"efs_time\",\"race_group\",name]]\n",
    "    oof_pre = oof_pre.rename(columns={name: \"predictions\"})\n",
    "    s, oof = compute_metric_cindex(oof_pre, name)\n",
    "    if s > best_score:\n",
    "        best_score    = s\n",
    "        best_index    = name\n",
    "        best_ensemble = oof\n",
    "        \n",
    "    print(f'C-index {s} {name}') \n",
    "print()\n",
    "print(f'Best single model is {best_index} with C-Index = {best_score}')\n",
    "experiments.remove(best_index)\n",
    "first_best_index = best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740cf9ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:23.265292Z",
     "iopub.status.busy": "2025-02-18T06:53:23.264871Z",
     "iopub.status.idle": "2025-02-18T06:53:23.271835Z",
     "shell.execute_reply": "2025-02-18T06:53:23.270662Z"
    },
    "papermill": {
     "duration": 0.024677,
     "end_time": "2025-02-18T06:53:23.273699",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.249022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/xgboost-exp-01',\n",
       " '/kaggle/input/catboost-exp-01',\n",
       " '/kaggle/input/lgbm-exp-01',\n",
       " '/kaggle/input/xgboost-exp-02',\n",
       " '/kaggle/input/catboost-exp-02',\n",
       " '/kaggle/input/lgbm-exp-03',\n",
       " '/kaggle/input/catboost-exp-03',\n",
       " '/kaggle/input/tabm-exp-01',\n",
       " '/kaggle/input/nn-exp-01',\n",
       " '/kaggle/input/tn-exp-01',\n",
       " '/kaggle/input/tf-exp-01',\n",
       " '/kaggle/input/svr-exp-01',\n",
       " '/kaggle/input/abd-exp-01',\n",
       " '/kaggle/input/catboost-exp-04',\n",
       " '/kaggle/input/lgbm-exp-04',\n",
       " '/kaggle/input/tabm-exp-02',\n",
       " '/kaggle/input/ds-exp-01',\n",
       " '/kaggle/input/nn-exp-02',\n",
       " '/kaggle/input/nn-exp-04',\n",
       " '/kaggle/input/xgboost-exp-05',\n",
       " '/kaggle/input/lgbm-exp-05',\n",
       " '/kaggle/input/tn-exp-02',\n",
       " '/kaggle/input/vr-exp-01',\n",
       " '/kaggle/input/tt-exp-01',\n",
       " '/kaggle/input/en-exp-01',\n",
       " '/kaggle/input/en-exp-02',\n",
       " '/kaggle/input/nn-exp-05',\n",
       " '/kaggle/input/rf-exp-05',\n",
       " '/kaggle/input/mcts-exp-02',\n",
       " '/kaggle/input/catboost-exp-06',\n",
       " '/kaggle/input/xgboost-exp-06',\n",
       " '/kaggle/input/lgbm-exp-06',\n",
       " '/kaggle/input/nn-exp-06',\n",
       " '/kaggle/input/xgboost-exp-07']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8cd8b",
   "metadata": {
    "papermill": {
     "duration": 0.014371,
     "end_time": "2025-02-18T06:53:23.303109",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.288738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 5: Iterations for hill climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f5c722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:23.334101Z",
     "iopub.status.busy": "2025-02-18T06:53:23.333684Z",
     "iopub.status.idle": "2025-02-18T06:53:23.338240Z",
     "shell.execute_reply": "2025-02-18T06:53:23.337103Z"
    },
    "papermill": {
     "duration": 0.022007,
     "end_time": "2025-02-18T06:53:23.340000",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.317993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_NEGATIVE_WGT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce0931d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:23.372604Z",
     "iopub.status.busy": "2025-02-18T06:53:23.372216Z",
     "iopub.status.idle": "2025-02-18T06:53:23.376674Z",
     "shell.execute_reply": "2025-02-18T06:53:23.375532Z"
    },
    "papermill": {
     "duration": 0.023308,
     "end_time": "2025-02-18T06:53:23.378642",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.355334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices        = [best_index]\n",
    "old_best_score = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13b4a8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:23.410524Z",
     "iopub.status.busy": "2025-02-18T06:53:23.410098Z",
     "iopub.status.idle": "2025-02-18T06:53:23.415087Z",
     "shell.execute_reply": "2025-02-18T06:53:23.413898Z"
    },
    "papermill": {
     "duration": 0.022958,
     "end_time": "2025-02-18T06:53:23.416784",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.393826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREPARE/MOVE VARIABLES TO GPU FOR SPEED UP\n",
    "best_ensemble = best_ensemble\n",
    "start         = -0.50\n",
    "if not USE_NEGATIVE_WGT: start = 0.01\n",
    "ww            = np.arange(start,0.51,0.01) # GPU\n",
    "nn            = len(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8d9a913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:23.450052Z",
     "iopub.status.busy": "2025-02-18T06:53:23.449637Z",
     "iopub.status.idle": "2025-02-18T06:53:23.454194Z",
     "shell.execute_reply": "2025-02-18T06:53:23.453026Z"
    },
    "papermill": {
     "duration": 0.023078,
     "end_time": "2025-02-18T06:53:23.455924",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.432846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HILL CLIMBING\n",
    "models  = [best_index]\n",
    "weights = []\n",
    "metrics = [best_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f506e76c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:23.488702Z",
     "iopub.status.busy": "2025-02-18T06:53:23.488254Z",
     "iopub.status.idle": "2025-02-18T06:53:23.496038Z",
     "shell.execute_reply": "2025-02-18T06:53:23.494852Z"
    },
    "papermill": {
     "duration": 0.026452,
     "end_time": "2025-02-18T06:53:23.497838",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.471386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/kaggle/input/catboost-exp-05'],\n",
       " [0.680734863930053],\n",
       " array([-5.0000000e-01, -4.9000000e-01, -4.8000000e-01, -4.7000000e-01,\n",
       "        -4.6000000e-01, -4.5000000e-01, -4.4000000e-01, -4.3000000e-01,\n",
       "        -4.2000000e-01, -4.1000000e-01, -4.0000000e-01, -3.9000000e-01,\n",
       "        -3.8000000e-01, -3.7000000e-01, -3.6000000e-01, -3.5000000e-01,\n",
       "        -3.4000000e-01, -3.3000000e-01, -3.2000000e-01, -3.1000000e-01,\n",
       "        -3.0000000e-01, -2.9000000e-01, -2.8000000e-01, -2.7000000e-01,\n",
       "        -2.6000000e-01, -2.5000000e-01, -2.4000000e-01, -2.3000000e-01,\n",
       "        -2.2000000e-01, -2.1000000e-01, -2.0000000e-01, -1.9000000e-01,\n",
       "        -1.8000000e-01, -1.7000000e-01, -1.6000000e-01, -1.5000000e-01,\n",
       "        -1.4000000e-01, -1.3000000e-01, -1.2000000e-01, -1.1000000e-01,\n",
       "        -1.0000000e-01, -9.0000000e-02, -8.0000000e-02, -7.0000000e-02,\n",
       "        -6.0000000e-02, -5.0000000e-02, -4.0000000e-02, -3.0000000e-02,\n",
       "        -2.0000000e-02, -1.0000000e-02,  4.4408921e-16,  1.0000000e-02,\n",
       "         2.0000000e-02,  3.0000000e-02,  4.0000000e-02,  5.0000000e-02,\n",
       "         6.0000000e-02,  7.0000000e-02,  8.0000000e-02,  9.0000000e-02,\n",
       "         1.0000000e-01,  1.1000000e-01,  1.2000000e-01,  1.3000000e-01,\n",
       "         1.4000000e-01,  1.5000000e-01,  1.6000000e-01,  1.7000000e-01,\n",
       "         1.8000000e-01,  1.9000000e-01,  2.0000000e-01,  2.1000000e-01,\n",
       "         2.2000000e-01,  2.3000000e-01,  2.4000000e-01,  2.5000000e-01,\n",
       "         2.6000000e-01,  2.7000000e-01,  2.8000000e-01,  2.9000000e-01,\n",
       "         3.0000000e-01,  3.1000000e-01,  3.2000000e-01,  3.3000000e-01,\n",
       "         3.4000000e-01,  3.5000000e-01,  3.6000000e-01,  3.7000000e-01,\n",
       "         3.8000000e-01,  3.9000000e-01,  4.0000000e-01,  4.1000000e-01,\n",
       "         4.2000000e-01,  4.3000000e-01,  4.4000000e-01,  4.5000000e-01,\n",
       "         4.6000000e-01,  4.7000000e-01,  4.8000000e-01,  4.9000000e-01,\n",
       "         5.0000000e-01]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models, metrics, ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c0b7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T06:53:23.530970Z",
     "iopub.status.busy": "2025-02-18T06:53:23.530521Z",
     "iopub.status.idle": "2025-02-18T13:23:55.007089Z",
     "shell.execute_reply": "2025-02-18T13:23:55.005795Z"
    },
    "papermill": {
     "duration": 23431.495921,
     "end_time": "2025-02-18T13:23:55.009145",
     "exception": false,
     "start_time": "2025-02-18T06:53:23.513224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for catboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tabm_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for ds_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for rf_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for nn_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Added /kaggle/input/nn-exp-06 with weight 0.4800, Score: 0.6857\n",
      "1th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for tabm_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for ds_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for rf_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: Added /kaggle/input/catboost-exp-01 with weight 0.1600, Score: 0.6861\n",
      "2th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tabm_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for ds_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for en_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for rf_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3: Added /kaggle/input/tabm-exp-02 with weight 0.1200, Score: 0.6863\n",
      "3th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:40<00:00,  2.48it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:41<00:00,  2.45it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:41<00:00,  2.45it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for svr_exp_01: 100%|██████████| 101/101 [00:40<00:00,  2.51it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.53it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for ds_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for en_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for rf_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4: Added /kaggle/input/svr-exp-01 with weight -0.0500, Score: 0.6865\n",
      "4th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for ds_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for rf_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5: Added /kaggle/input/ds-exp-01 with weight 0.0500, Score: 0.6867\n",
      "5th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for rf_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6: Added /kaggle/input/rf-exp-05 with weight -0.0800, Score: 0.6868\n",
      "6th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.53it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.53it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7: Added /kaggle/input/en-exp-02 with weight 0.0400, Score: 0.6869\n",
      "7th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:40<00:00,  2.51it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8: Added /kaggle/input/xgboost-exp-06 with weight -0.0800, Score: 0.6870\n",
      "8th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:40<00:00,  2.52it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9: Added /kaggle/input/tn-exp-02 with weight 0.0300, Score: 0.6870\n",
      "9th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: Added /kaggle/input/nn-exp-02 with weight -0.0200, Score: 0.6870\n",
      "10th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tf_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11: Added /kaggle/input/tf-exp-01 with weight 0.0300, Score: 0.6871\n",
      "11th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:40<00:00,  2.51it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for catboost_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12: Added /kaggle/input/catboost-exp-03 with weight -0.0600, Score: 0.6871\n",
      "12th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for tt_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:40<00:00,  2.52it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.53it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:40<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13: Added /kaggle/input/tt-exp-01 with weight -0.0100, Score: 0.6871\n",
      "13th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:40<00:00,  2.52it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for vr_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14: Added /kaggle/input/vr-exp-01 with weight 0.0600, Score: 0.6871\n",
      "14th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15: Added /kaggle/input/xgboost-exp-02 with weight -0.0400, Score: 0.6872\n",
      "15th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:40<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16: Added /kaggle/input/lgbm-exp-06 with weight -0.0100, Score: 0.6872\n",
      "16th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17: Added /kaggle/input/xgboost-exp-05 with weight 0.0100, Score: 0.6872\n",
      "17th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18: Added /kaggle/input/catboost-exp-02 with weight 0.0100, Score: 0.6872\n",
      "18th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_03: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19: Added /kaggle/input/lgbm-exp-03 with weight -0.0100, Score: 0.6872\n",
      "19th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.53it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_06: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20: Added /kaggle/input/catboost-exp-06 with weight 0.0100, Score: 0.6872\n",
      "20th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:40<00:00,  2.52it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21: Added /kaggle/input/nn-exp-04 with weight 0.0300, Score: 0.6872\n",
      "21th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.53it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for tn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22: Added /kaggle/input/tn-exp-01 with weight -0.0100, Score: 0.6872\n",
      "22th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for catboost_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.55it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:40<00:00,  2.49it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23: Added /kaggle/input/catboost-exp-04 with weight 0.0100, Score: 0.6872\n",
      "23th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for xgboost_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24: Added /kaggle/input/xgboost-exp-01 with weight 0.0100, Score: 0.6872\n",
      "24th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_01: 100%|██████████| 101/101 [00:40<00:00,  2.48it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25: Added /kaggle/input/nn-exp-01 with weight -0.0200, Score: 0.6872\n",
      "25th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for tabm_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26: Added /kaggle/input/tabm-exp-01 with weight 0.0200, Score: 0.6873\n",
      "26th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for lgbm_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.53it/s]\n",
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27: Added /kaggle/input/lgbm-exp-01 with weight -0.0300, Score: 0.6873\n",
      "27th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for en_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28: Added /kaggle/input/en-exp-01 with weight -0.0200, Score: 0.6873\n",
      "28th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.59it/s]\n",
      "Testing weights for lgbm_exp_04: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29: Added /kaggle/input/lgbm-exp-04 with weight 0.0100, Score: 0.6873\n",
      "29th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.56it/s]\n",
      "Testing weights for xgboost_exp_07: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30: Added /kaggle/input/xgboost-exp-07 with weight 0.0400, Score: 0.6873\n",
      "30th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for nn_exp_05: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:39<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31: Added /kaggle/input/nn-exp-05 with weight -0.0100, Score: 0.6873\n",
      "31th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:39<00:00,  2.58it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for mcts_exp_02: 100%|██████████| 101/101 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32: Added /kaggle/input/mcts-exp-02 with weight 0.0000, Score: 0.6873\n",
      "32th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing weights for abd_exp_01: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n",
      "Testing weights for lgbm_exp_05: 100%|██████████| 101/101 [00:38<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement found, stopping\n",
      "{'index': -1, 'weight': 0, 'score': 0.6873160374015983}\n",
      "CPU times: user 6h 30min 25s, sys: 28.8 s, total: 6h 30min 54s\n",
      "Wall time: 6h 30min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "def optimize_ensemble(experiments, initial_ensemble, weights_range, score_function, max_iterations = 100):\n",
    "    \n",
    "    # Initialize variables\n",
    "    iteration  = 0\n",
    "    best_score = score_function(\n",
    "        initial_ensemble[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n",
    "        initial_ensemble[[\"ID\", \"predictions\"]].copy(),\n",
    "        \"ID\"\n",
    "    )\n",
    "    \n",
    "    model_weights         = {}\n",
    "    remaining_experiments = experiments.copy()\n",
    "    best_ensemble         = initial_ensemble.copy()\n",
    "    \n",
    "    while remaining_experiments and iteration < max_iterations:\n",
    "        print(f\"{iteration}th iteration\")\n",
    "        iteration += 1\n",
    "        best_iteration = {\n",
    "            'index' : -1,\n",
    "            'weight': 0,\n",
    "            'score' : best_score\n",
    "        }\n",
    "        \n",
    "        # Try each remaining model\n",
    "        for model_path in remaining_experiments:\n",
    "            try:\n",
    "                #print(f\"Iteration {iteration}: Trying model {model_path}\")\n",
    "                \n",
    "                # Load model OOF predictions\n",
    "                model_name = model_path.split(\"/\")[-1].replace('-', '_')\n",
    "                model_oof  = preds_df[model_path]\n",
    "                \n",
    "                # Try different weights\n",
    "                for weight in tqdm(weights_range, desc=f\"Testing weights for {model_name}\"):\n",
    "                    # Create potential ensemble\n",
    "                    potential_ensemble = pd.DataFrame({\n",
    "                        \"ID\": best_ensemble[\"ID\"],\n",
    "                        \"predictions\": (1 - weight) * rankdata(best_ensemble[\"predictions\"]) + \n",
    "                                     weight * rankdata(model_oof)\n",
    "                    })\n",
    "                    \n",
    "                    # Evaluate new ensemble\n",
    "                    new_score = score_function(\n",
    "                        preds_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n",
    "                        potential_ensemble.copy(),\n",
    "                        \"ID\"\n",
    "                    )\n",
    "                    \n",
    "                    # Update best if improved\n",
    "                    if new_score > best_iteration['score']:\n",
    "                        best_iteration.update({\n",
    "                            'index' : model_path,\n",
    "                            'weight': weight,\n",
    "                            'score' : new_score\n",
    "                        })\n",
    "                \n",
    "                # Clean up\n",
    "                del model_oof\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {model_path}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Check if we found an improvement\n",
    "        if best_iteration['index'] == -1:\n",
    "            print(\"No improvement found, stopping\")\n",
    "            print(best_iteration)\n",
    "            break\n",
    "            \n",
    "        # Update ensemble with best model found\n",
    "        best_score                             = best_iteration['score']\n",
    "        model_weights[best_iteration['index']] = best_iteration['weight']\n",
    "        remaining_experiments.remove(best_iteration['index'])\n",
    "        \n",
    "        print(\n",
    "            f\"Iteration {iteration}: Added {best_iteration['index']} \"\n",
    "            f\"with weight {best_iteration['weight']:.4f}, \"\n",
    "            f\"Score: {best_iteration['score']:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Update best ensemble for next iteration\n",
    "        model_oof = preds_df[best_iteration['index']]\n",
    "        best_ensemble[\"predictions\"] = (\n",
    "            (1 - best_iteration['weight']) * rankdata(best_ensemble[\"predictions\"]) + \n",
    "            best_iteration['weight'] * rankdata(model_oof)\n",
    "        )\n",
    "        \n",
    "    return model_weights, best_score\n",
    "\n",
    "\n",
    "model_weights, best_score = optimize_ensemble(experiments, best_ensemble, ww, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4acd8b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:24:02.444686Z",
     "iopub.status.busy": "2025-02-18T13:24:02.444190Z",
     "iopub.status.idle": "2025-02-18T13:24:02.453426Z",
     "shell.execute_reply": "2025-02-18T13:24:02.452314Z"
    },
    "papermill": {
     "duration": 3.70244,
     "end_time": "2025-02-18T13:24:02.455269",
     "exception": false,
     "start_time": "2025-02-18T13:23:58.752829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'/kaggle/input/nn-exp-06': 0.48000000000000087,\n",
       "  '/kaggle/input/catboost-exp-01': 0.1600000000000006,\n",
       "  '/kaggle/input/tabm-exp-02': 0.12000000000000055,\n",
       "  '/kaggle/input/svr-exp-01': -0.0499999999999996,\n",
       "  '/kaggle/input/ds-exp-01': 0.05000000000000049,\n",
       "  '/kaggle/input/rf-exp-05': -0.07999999999999963,\n",
       "  '/kaggle/input/en-exp-02': 0.04000000000000048,\n",
       "  '/kaggle/input/xgboost-exp-06': -0.07999999999999963,\n",
       "  '/kaggle/input/tn-exp-02': 0.03000000000000047,\n",
       "  '/kaggle/input/nn-exp-02': -0.019999999999999574,\n",
       "  '/kaggle/input/tf-exp-01': 0.03000000000000047,\n",
       "  '/kaggle/input/catboost-exp-03': -0.05999999999999961,\n",
       "  '/kaggle/input/tt-exp-01': -0.009999999999999565,\n",
       "  '/kaggle/input/vr-exp-01': 0.0600000000000005,\n",
       "  '/kaggle/input/xgboost-exp-02': -0.03999999999999959,\n",
       "  '/kaggle/input/lgbm-exp-06': -0.009999999999999565,\n",
       "  '/kaggle/input/xgboost-exp-05': 0.010000000000000453,\n",
       "  '/kaggle/input/catboost-exp-02': 0.010000000000000453,\n",
       "  '/kaggle/input/lgbm-exp-03': -0.009999999999999565,\n",
       "  '/kaggle/input/catboost-exp-06': 0.010000000000000453,\n",
       "  '/kaggle/input/nn-exp-04': 0.03000000000000047,\n",
       "  '/kaggle/input/tn-exp-01': -0.009999999999999565,\n",
       "  '/kaggle/input/catboost-exp-04': 0.010000000000000453,\n",
       "  '/kaggle/input/xgboost-exp-01': 0.010000000000000453,\n",
       "  '/kaggle/input/nn-exp-01': -0.019999999999999574,\n",
       "  '/kaggle/input/tabm-exp-01': 0.020000000000000462,\n",
       "  '/kaggle/input/lgbm-exp-01': -0.029999999999999583,\n",
       "  '/kaggle/input/en-exp-01': -0.019999999999999574,\n",
       "  '/kaggle/input/lgbm-exp-04': 0.010000000000000453,\n",
       "  '/kaggle/input/xgboost-exp-07': 0.04000000000000048,\n",
       "  '/kaggle/input/nn-exp-05': -0.009999999999999565,\n",
       "  '/kaggle/input/mcts-exp-02': 4.440892098500626e-16},\n",
       " 0.6873160374015983)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c56877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:24:09.737613Z",
     "iopub.status.busy": "2025-02-18T13:24:09.737039Z",
     "iopub.status.idle": "2025-02-18T13:24:09.743868Z",
     "shell.execute_reply": "2025-02-18T13:24:09.742916Z"
    },
    "papermill": {
     "duration": 3.629098,
     "end_time": "2025-02-18T13:24:09.745516",
     "exception": false,
     "start_time": "2025-02-18T13:24:06.116418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/input/catboost-exp-05',\n",
       " ['/kaggle/input/xgboost-exp-01',\n",
       "  '/kaggle/input/catboost-exp-01',\n",
       "  '/kaggle/input/lgbm-exp-01',\n",
       "  '/kaggle/input/xgboost-exp-02',\n",
       "  '/kaggle/input/catboost-exp-02',\n",
       "  '/kaggle/input/lgbm-exp-03',\n",
       "  '/kaggle/input/catboost-exp-03',\n",
       "  '/kaggle/input/tabm-exp-01',\n",
       "  '/kaggle/input/nn-exp-01',\n",
       "  '/kaggle/input/tn-exp-01',\n",
       "  '/kaggle/input/tf-exp-01',\n",
       "  '/kaggle/input/svr-exp-01',\n",
       "  '/kaggle/input/abd-exp-01',\n",
       "  '/kaggle/input/catboost-exp-04',\n",
       "  '/kaggle/input/lgbm-exp-04',\n",
       "  '/kaggle/input/tabm-exp-02',\n",
       "  '/kaggle/input/ds-exp-01',\n",
       "  '/kaggle/input/nn-exp-02',\n",
       "  '/kaggle/input/nn-exp-04',\n",
       "  '/kaggle/input/xgboost-exp-05',\n",
       "  '/kaggle/input/lgbm-exp-05',\n",
       "  '/kaggle/input/tn-exp-02',\n",
       "  '/kaggle/input/vr-exp-01',\n",
       "  '/kaggle/input/tt-exp-01',\n",
       "  '/kaggle/input/en-exp-01',\n",
       "  '/kaggle/input/en-exp-02',\n",
       "  '/kaggle/input/nn-exp-05',\n",
       "  '/kaggle/input/rf-exp-05',\n",
       "  '/kaggle/input/mcts-exp-02',\n",
       "  '/kaggle/input/catboost-exp-06',\n",
       "  '/kaggle/input/xgboost-exp-06',\n",
       "  '/kaggle/input/lgbm-exp-06',\n",
       "  '/kaggle/input/nn-exp-06',\n",
       "  '/kaggle/input/xgboost-exp-07'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_best_index, experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870e652",
   "metadata": {
    "papermill": {
     "duration": 3.587837,
     "end_time": "2025-02-18T13:24:17.008146",
     "exception": false,
     "start_time": "2025-02-18T13:24:13.420309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 6: Inference on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "375872d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:24:24.284544Z",
     "iopub.status.busy": "2025-02-18T13:24:24.284109Z",
     "iopub.status.idle": "2025-02-18T13:24:24.291238Z",
     "shell.execute_reply": "2025-02-18T13:24:24.290250Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.679728,
     "end_time": "2025-02-18T13:24:24.292928",
     "exception": false,
     "start_time": "2025-02-18T13:24:20.613200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CFG:\n",
    "#     folds = 10\n",
    "\n",
    "# # https://www.kaggle.com/datasets/jsday96/mcts-tabm-models/data?select=TabMRegressor.py\n",
    "# class TabMRegressor:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         arch_type: str        = 'tabm-mini',\n",
    "#         backbone: dict        = {'type': 'MLP', 'n_blocks': 3, 'd_block': 512, 'dropout': 0.1},\n",
    "#         d_embedding: int      = 64,  # Only used for 'tabm-mini'\n",
    "#         bin_count: int        = 48,  # Only used for 'tabm-mini'\n",
    "#         k: int                = 32,\n",
    "#         learning_rate: float  = 1e-4,\n",
    "#         weight_decay: float   = 1e-3,\n",
    "#         clip_grad_norm: bool  = True,\n",
    "#         max_epochs: int       = 100,\n",
    "#         patience: int         = 15,\n",
    "#         batch_size: int       = 32,\n",
    "#         compile_model: bool   = False,\n",
    "#         device: Optional[str] = 'cuda:0',\n",
    "#         random_state: int     = 0,\n",
    "#         verbose: bool         = True\n",
    "#     ):\n",
    "#         self.arch_type = arch_type\n",
    "#         self.backbone = backbone\n",
    "#         self.d_embedding = d_embedding\n",
    "#         self.bin_count = bin_count\n",
    "#         self.k = k\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.weight_decay = weight_decay\n",
    "#         self.clip_grad_norm = clip_grad_norm\n",
    "#         self.max_epochs = max_epochs\n",
    "#         self.patience = patience\n",
    "#         self.batch_size = batch_size\n",
    "#         self.compile_model = compile_model\n",
    "#         self.device = torch.device(device if device else ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "#         self.random_state = random_state\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#     def fit(\n",
    "#         self,\n",
    "#         X: pd.DataFrame,\n",
    "#         y: np.array,\n",
    "#         eval_set: Tuple[pd.DataFrame, np.array]\n",
    "#     ):\n",
    "#         # PREPROCESS DATA.\n",
    "#         X_cat_train, X_cont_train, cat_cardinalities, y_train = self._preprocess_data(X, y, training=True)\n",
    "#         X_cat_val, X_cont_val, _, y_val = self._preprocess_data(eval_set[0], eval_set[1], training=False)\n",
    "\n",
    "#         # CREATE MODEL & TRAINING ALGO.\n",
    "#         bins = rtdl_num_embeddings.compute_bins(X_cont_train, n_bins=self.bin_count) if self.arch_type == 'tabm-mini' else None\n",
    "#         self.model = Model(\n",
    "#             n_num_features=X_cont_train.shape[1],\n",
    "#             cat_cardinalities=cat_cardinalities,\n",
    "#             n_classes=None,\n",
    "#             backbone=self.backbone,\n",
    "#             bins=bins,\n",
    "#             num_embeddings=(\n",
    "#                 None\n",
    "#                 if bins is None\n",
    "#                 else {\n",
    "#                     'type': 'PiecewiseLinearEmbeddings',\n",
    "#                     'd_embedding': self.d_embedding,\n",
    "#                     'activation': True,\n",
    "#                     'version': 'B',\n",
    "#                 }\n",
    "#             ),\n",
    "#             arch_type=self.arch_type,\n",
    "#             k=self.k,\n",
    "#         ).to(self.device)\n",
    "#         optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "#         if self.compile_model:\n",
    "#             self.model = torch.compile(self.model)\n",
    "\n",
    "#         loss_fn = torch.nn.MSELoss().to(self.device)\n",
    "#         # TRAIN & TEST MODEL.\n",
    "#         best = {\n",
    "#             'epoch': -1,\n",
    "#             'eval_loss': math.inf,\n",
    "#             'model_state_dict': None,\n",
    "#         }\n",
    "#         remaining_patience = self.patience\n",
    "#         epoch_size = math.ceil(len(X) / self.batch_size)\n",
    "\n",
    "\n",
    "#         for epoch in range(self.max_epochs):\n",
    "#             # TRAIN.\n",
    "#             optimizer.zero_grad()\n",
    "#             train_losses = []\n",
    "#             progress_bar = torch.randperm(len(y_train), device=self.device).split(self.batch_size)\n",
    "#             progress_bar = tqdm(progress_bar, desc=f'Epoch {epoch}', total=epoch_size) if self.verbose else progress_bar\n",
    "#             for batch_idx in progress_bar:\n",
    "#                 self.model.train()\n",
    "\n",
    "#                 with torch.amp.autocast(device_type='cuda', dtype = torch.bfloat16):\n",
    "#                     y_pred = self.model(\n",
    "#                         X_cont_train[batch_idx],\n",
    "#                         X_cat_train[batch_idx],\n",
    "#                     ).squeeze(-1).float()\n",
    "\n",
    "#                 loss = loss_fn(y_pred.flatten(0, 1), y_train[batch_idx].repeat_interleave(self.k))\n",
    "#                 loss.backward()\n",
    "#                 if self.clip_grad_norm:\n",
    "#                     torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "#                 optimizer.step()\n",
    "\n",
    "#                 train_losses.append(loss.item())\n",
    "\n",
    "\n",
    "#              # EVALUATE.\n",
    "#             self.model.eval()\n",
    "#             val_losses = []\n",
    "#             with torch.no_grad():\n",
    "#                 for batch_idx in torch.arange(0, len(y_val), self.batch_size, device=self.device):\n",
    "#                     y_pred = self.model(\n",
    "#                         X_cont_val[batch_idx:batch_idx+self.batch_size],\n",
    "#                         X_cat_val[batch_idx:batch_idx+self.batch_size],\n",
    "#                     ).squeeze(-1).float()\n",
    "\n",
    "#                     loss = loss_fn(y_pred.flatten(0, 1), y_val[batch_idx:batch_idx+self.batch_size].repeat_interleave(self.k))\n",
    "#                     val_losses.append(loss.item())\n",
    "\n",
    "\n",
    "#             # PRINT INFO.\n",
    "#             mean_train_loss = np.mean(train_losses)\n",
    "#             mean_val_loss = np.mean(val_losses)\n",
    "#             if self.verbose:\n",
    "#                 print(f'Epoch {epoch} | Train Loss: {mean_train_loss} | Val Loss: {mean_val_loss}')\n",
    "\n",
    "\n",
    "#             # COMPARE TO BEST.\n",
    "#             if mean_val_loss < best['eval_loss']:\n",
    "#                 best['epoch'] = epoch\n",
    "#                 best['eval_loss'] = mean_val_loss\n",
    "#                 best['model_state_dict'] = self.model.state_dict()\n",
    "#                 remaining_patience = self.patience\n",
    "                \n",
    "#                 if self.verbose:\n",
    "#                     print('🌸 New best epoch! 🌸')\n",
    "#             else:\n",
    "#                 remaining_patience -= 1\n",
    "\n",
    "#             # EARLY STOPPING.\n",
    "#             if remaining_patience == 0:\n",
    "#                 break\n",
    "\n",
    "#             # RESTORE BEST MODEL.\n",
    "#             self.model.load_state_dict(best['model_state_dict'])\n",
    "\n",
    "\n",
    "#     def predict(\n",
    "#         self,\n",
    "#         X: pd.DataFrame,\n",
    "#         batch_size: Optional[int] = 8096\n",
    "#     ) -> np.ndarray:\n",
    "#         # PREPROCESS DATA.\n",
    "#         X_cat, X_cont, _, _ = self._preprocess_data(X, y=None, training=False)\n",
    "\n",
    "#         # PREDICT.\n",
    "#         self.model.eval()\n",
    "#         y_pred = []\n",
    "#         with torch.no_grad():\n",
    "#             for batch_idx in torch.arange(0, len(X), batch_size, device=self.device):\n",
    "#                 y_pred.append(\n",
    "#                     self.model(\n",
    "#                         X_cont[batch_idx:batch_idx+batch_size],\n",
    "#                         X_cat[batch_idx:batch_idx+batch_size],\n",
    "#                     ).squeeze(-1).float().cpu().numpy()\n",
    "#                 )\n",
    "\n",
    "#         y_pred = np.concatenate(y_pred)\n",
    "\n",
    "\n",
    "#         # DENORMALIZE TARGETS.\n",
    "#         y_pred = y_pred * self._target_std + self._target_mean\n",
    "\n",
    "\n",
    "#         # COMPUTE ENSEMBLE MEAN.\n",
    "#         y_pred = np.mean(y_pred, axis=1)\n",
    "\n",
    "#         return y_pred\n",
    "\n",
    "\n",
    "#     def _preprocess_data(self, X: pd.DataFrame, y: pd.Series, training: bool):\n",
    "#         # PICK NON-CONSTANT COLUMNS.\n",
    "#         if training:\n",
    "#             self._non_constant_columns = X.columns[X.nunique() > 1]\n",
    "\n",
    "#         X = X[self._non_constant_columns]\n",
    "\n",
    "#         # SEPARATE CATEGORICAL & CONTINUOUS FEATURES.\n",
    "#         categorical_features = [col for col in X.columns if X[col].dtype.name == 'object']\n",
    "#         X_cat = X[categorical_features].to_numpy()\n",
    "#         X_cont = X.drop(columns=categorical_features).to_numpy()\n",
    "\n",
    "#         # ENCODE CATEGORICAL FEATURES.\n",
    "#         cat_cardinalities = [X[col].nunique() for col in categorical_features]\n",
    "\n",
    "#         if training:\n",
    "#             self._categorical_encoders = [\n",
    "#                 OrdinalEncoder()\n",
    "#                 for _ in range(X_cat.shape[1])\n",
    "#             ]\n",
    "#         X_cat = np.concatenate([\n",
    "#             encoder.fit_transform(X_cat[:, i:i+1])\n",
    "#             for i, encoder in enumerate(self._categorical_encoders)\n",
    "#         ], axis=1)\n",
    "\n",
    "#         # NORMALIZE TARGETS.\n",
    "#         if training:\n",
    "#             self._target_mean = y.mean()\n",
    "#             self._target_std = y.std()\n",
    "\n",
    "#             y = (y - self._target_mean) / self._target_std\n",
    "\n",
    "\n",
    "#         # SCALE CONTINUOUS FEATURES.\n",
    "#         if training:\n",
    "#             noise = (\n",
    "#                 np.random.default_rng(0)\n",
    "#                 .normal(0.0, 1e-5, X_cont.shape)\n",
    "#                 .astype(X_cont.dtype)\n",
    "#             )\n",
    "#             self._cont_feature_preprocessor = QuantileTransformer(\n",
    "#                 n_quantiles=max(min(len(X) // 30, 1000), 10),\n",
    "#                 output_distribution='normal',\n",
    "#                 subsample=10**9,\n",
    "#             ).fit(X_cont + noise)\n",
    "\n",
    "#         X_cont = self._cont_feature_preprocessor.transform(X_cont)\n",
    "\n",
    "\n",
    "#         # CONVERT TO TENSORS.\n",
    "#         X_cat = torch.tensor(X_cat, dtype=torch.long, device=self.device)\n",
    "#         X_cont = torch.tensor(X_cont, dtype=torch.float32, device=self.device)\n",
    "\n",
    "#         if y is not None:\n",
    "#             y = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "\n",
    "#         return X_cat, X_cont, cat_cardinalities, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9a1b73c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:24:31.515929Z",
     "iopub.status.busy": "2025-02-18T13:24:31.515581Z",
     "iopub.status.idle": "2025-02-18T13:24:31.519711Z",
     "shell.execute_reply": "2025-02-18T13:24:31.518587Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.608095,
     "end_time": "2025-02-18T13:24:31.521352",
     "exception": false,
     "start_time": "2025-02-18T13:24:27.913257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_tabm_features(data):\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n",
    "#     FEATURES = [c for c in data.columns if not c in RMV]\n",
    "    \n",
    "#     RMV              = ['ID']\n",
    "#     X_test           = data.drop(RMV, axis=1)\n",
    "#     y_pred           = data[['ID']]\n",
    "    \n",
    "#     #print(\"X_test shape:\", X_test.shape, '\\n')\n",
    "    \n",
    "#     cat_cols         = X_test.select_dtypes(include=['object']).columns.tolist()\n",
    "#     num_cols         = X_test.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    \n",
    "#     # Preprocessing categorical\n",
    "#     imputer          = SimpleImputer(strategy='constant', fill_value='NAN')\n",
    "#     X_test[cat_cols] = imputer.fit_transform(X_test[cat_cols])\n",
    "\n",
    "#     # Preprocessing numerical\n",
    "#     imputer          = SimpleImputer(strategy=\"median\")\n",
    "#     X_test[num_cols] = imputer.fit_transform(X_test[num_cols])\n",
    "\n",
    "#     return X_test,FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6d28bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:24:38.902097Z",
     "iopub.status.busy": "2025-02-18T13:24:38.901697Z",
     "iopub.status.idle": "2025-02-18T13:24:38.906141Z",
     "shell.execute_reply": "2025-02-18T13:24:38.905166Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.666746,
     "end_time": "2025-02-18T13:24:38.908226",
     "exception": false,
     "start_time": "2025-02-18T13:24:35.241480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def prepare_features(model_path, train, test):\n",
    "\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\"]\n",
    "#     FEATURES = [c for c in train.columns if not c in RMV]\n",
    "#     #print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n",
    "    \n",
    "\n",
    "#     CATS = []\n",
    "#     for c in FEATURES:\n",
    "#         if train[c].dtype==\"object\":\n",
    "#             CATS.append(c)\n",
    "#             train[c] = train[c].fillna(\"NAN\")\n",
    "#             test[c]  = test[c].fillna(\"NAN\")\n",
    "#         elif \"DeepTabels\" in model_path or \"tn\" in model_path or \"svr\" in model_path:\n",
    "#             train[c] = train[c].fillna(-1)\n",
    "#             test[c]  = test[c].fillna(-1)\n",
    "            \n",
    "        \n",
    "#     #print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n",
    "    \n",
    "#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#     #print(\"Combined data shape:\", combined.shape )\n",
    "    \n",
    "#     # LABEL ENCODE CATEGORICAL FEATURES\n",
    "#     #print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n",
    "#     for c in FEATURES:\n",
    "    \n",
    "#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "#         if c in CATS:\n",
    "#             #print(f\"{c}, \",end=\"\")\n",
    "#             combined[c],_ = combined[c].factorize()\n",
    "#             combined[c]  -= combined[c].min()\n",
    "#             combined[c]   = combined[c].astype(\"int32\")\n",
    "#             combined[c]   = combined[c].astype(\"category\")\n",
    "            \n",
    "#         # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "#         else:\n",
    "#             if combined[c].dtype ==\"float64\":\n",
    "#                 combined[c]      = combined[c].astype(\"float32\")\n",
    "#             if combined[c].dtype ==\"int64\":\n",
    "#                 combined[c]      = combined[c].astype(\"int32\")\n",
    "        \n",
    "#     train = combined.iloc[:len(train)].copy()\n",
    "#     test  = combined.iloc[len(train):].reset_index(drop=True).copy()\n",
    "                \n",
    "#     return train, test, FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f6937ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:24:46.127632Z",
     "iopub.status.busy": "2025-02-18T13:24:46.127259Z",
     "iopub.status.idle": "2025-02-18T13:24:46.132122Z",
     "shell.execute_reply": "2025-02-18T13:24:46.130889Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.572044,
     "end_time": "2025-02-18T13:24:46.134038",
     "exception": false,
     "start_time": "2025-02-18T13:24:42.561994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_nn_features(train, test):\n",
    "    \n",
    "#     CAT_SIZE = []\n",
    "#     CAT_EMB  = []\n",
    "#     NUMS     = []\n",
    "#     CATS     = []\n",
    "\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n",
    "#     FEATURES = [c for c in train.columns if not c in RMV]\n",
    "    \n",
    "#     for c in FEATURES:\n",
    "#         if train[c].dtype==\"object\":\n",
    "#             train[c] = train[c].fillna(\"NAN\")\n",
    "#             test[c]  = test[c].fillna(\"NAN\")\n",
    "#             CATS.append(c)\n",
    "#         elif not \"age\" in c:\n",
    "#             train[c] = train[c].astype(\"str\")\n",
    "#             test[c]  = test[c].astype(\"str\")\n",
    "#             CATS.append(c)\n",
    "\n",
    "\n",
    "#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#     for c in FEATURES:\n",
    "#         if c in CATS:\n",
    "#             # LABEL ENCODE\n",
    "#             combined[c],_ = combined[c].factorize()\n",
    "#             combined[c] -= combined[c].min()\n",
    "#             combined[c] = combined[c].astype(\"int32\")\n",
    "#             #combined[c] = combined[c].astype(\"category\")\n",
    "\n",
    "#             n = combined[c].nunique()\n",
    "#             mn = combined[c].min()\n",
    "#             mx = combined[c].max()\n",
    "#             #print(f'{c} has ({n}) unique values')\n",
    "    \n",
    "#             CAT_SIZE.append(mx+1) \n",
    "#             CAT_EMB.append( int(np.ceil( np.sqrt(mx+1))) ) \n",
    "#         else:\n",
    "#             if combined[c].dtype==\"float64\":\n",
    "#                 combined[c] = combined[c].astype(\"float32\")\n",
    "#             if combined[c].dtype==\"int64\":\n",
    "#                 combined[c] = combined[c].astype(\"int32\")\n",
    "                \n",
    "#             m = combined[c].mean()\n",
    "#             s = combined[c].std()\n",
    "#             combined[c] = (combined[c]-m)/s\n",
    "#             combined[c] = combined[c].fillna(0)\n",
    "            \n",
    "#             NUMS.append(c)\n",
    "\n",
    "#     train = combined.iloc[:len(train)].copy()\n",
    "#     test = combined.iloc[len(train):].reset_index(drop=True).copy()\n",
    "\n",
    "#     return test[CATS], test[NUMS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3102729b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:24:53.395736Z",
     "iopub.status.busy": "2025-02-18T13:24:53.395334Z",
     "iopub.status.idle": "2025-02-18T13:24:53.400639Z",
     "shell.execute_reply": "2025-02-18T13:24:53.399245Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.61978,
     "end_time": "2025-02-18T13:24:53.402589",
     "exception": false,
     "start_time": "2025-02-18T13:24:49.782809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_tf_features(train, test):\n",
    "#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"y_na\",\"fold\"]\n",
    "#     FEATURES = [c for c in train.columns if not c in RMV]\n",
    "\n",
    "\n",
    "#     test                             = test.replace('Not done', 'missing')\n",
    "#     test                             = test.replace('Not tested', 'missing')\n",
    "    \n",
    "#     test['na_count']                 = test.isna().sum(axis=1)\n",
    "#     test['age_karnofsky']            = test['age_at_hct'] * test['karnofsky_score']\n",
    "#     test['age_comorbidity']          = test['age_at_hct'] * test['comorbidity_score']\n",
    "#     test['donor_recipient_age_diff'] = abs(test['donor_age'] - test['age_at_hct'])\n",
    "#     test['hla_match_ratio']          = (test['hla_high_res_8'] + test['hla_low_res_8']) / 16\n",
    "#     test['age_squared']              = test['age_at_hct'] ** 2\n",
    "#     test['karnofsky_squared']        = test['karnofsky_score'] ** 2\n",
    "#     test['16?']                      = np.where(test['age_at_hct']<=16,1,0)\n",
    "    \n",
    "#     FEATURES.extend([\"na_count\", \"age_karnofsky\", \"age_comorbidity\", \"donor_recipient_age_diff\", \"hla_match_ratio\", \"age_squared\", \"karnofsky_squared\", \"16?\"])\n",
    "\n",
    "#     CATS = []\n",
    "#     for c in FEATURES:\n",
    "#         if test[c].dtype==\"object\":\n",
    "#             CATS.append(c)\n",
    "#             test[c] = test[c].fillna(\"missing\")\n",
    "\n",
    "#     for c in FEATURES:\n",
    "#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "#         if c in CATS:\n",
    "#             #print(f\"{c}, \",end=\"\")\n",
    "#             test[c],_ = test[c].factorize()\n",
    "#             test[c]  -= test[c].min()\n",
    "#             test[c]   = test[c].astype(\"int32\")\n",
    "#             test[c]   = test[c].astype(\"category\")\n",
    "#         else:\n",
    "#             if test[c].dtype == \"float64\":\n",
    "#                 test[c]      = test[c].astype(\"float32\")\n",
    "#             if test[c].dtype ==\"int64\":\n",
    "#                 test[c]      = test[c].astype(\"int32\")\n",
    "    \n",
    "#     return test, FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6b6437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:00.639214Z",
     "iopub.status.busy": "2025-02-18T13:25:00.638808Z",
     "iopub.status.idle": "2025-02-18T13:25:00.644070Z",
     "shell.execute_reply": "2025-02-18T13:25:00.642770Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.630566,
     "end_time": "2025-02-18T13:25:00.645864",
     "exception": false,
     "start_time": "2025-02-18T13:24:57.015298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# imputer               = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# FOLDS = 10\n",
    "\n",
    "# def inference(model_path, train, test_df):\n",
    "    \n",
    "#     path = model_path.split('/')[-1]\n",
    "#     file = path.replace('-','_')\n",
    "\n",
    "#     if \"dt\" not in model_path:\n",
    "#         with open(f\"/kaggle/input/{path}/{file}.pkl\", 'rb') as f:\n",
    "#             models = pickle.load(f)\n",
    "            \n",
    "#     print(\"All models are loaded successfully....!\")\n",
    "\n",
    "#     test_predictions = np.zeros(len(test_df))\n",
    "\n",
    "#     for fold in tqdm(range(FOLDS)):\n",
    "#         if \"dt\" in model_path:\n",
    "#             # model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "#             # train, test, FEATURES   = prepare_features(model_path, train, test_df)\n",
    "#             # model                   = tf.keras.models.load_model(model_path+f\"/model_fold_{fold}.keras\", custom_objects=dt.__dict__, compile=)\n",
    "#             # fold_preds              = model.predict(test.copy())\n",
    "#             # fold_preds              = fold_preds.flatten()\n",
    "#             pass\n",
    "#         else:\n",
    "#             model  = models[fold]\n",
    "            \n",
    "            \n",
    "#         if \"svr\" in model_path:\n",
    "#             if fold==0:\n",
    "#                 train, test, FEATURES = prepare_features(model_path, train.copy(), test_df.copy())\n",
    "\n",
    "#             # Handle missing values\n",
    "#             train_imputed         = imputer.fit_transform(train[FEATURES].copy())\n",
    "#             test_imputed          = imputer.transform(test[FEATURES])\n",
    "\n",
    "#             # Convert back to DataFrame to maintain feature names\n",
    "#             train_imputed         = pd.DataFrame(train_imputed, columns=FEATURES, index=train.index)\n",
    "#             test_imputed          = pd.DataFrame(test_imputed, columns=FEATURES, index=test.index)\n",
    "            \n",
    "#             # Scale features\n",
    "#             scaler.fit(train_imputed)\n",
    "#             test_scaled           = scaler.transform(test_imputed)\n",
    "            \n",
    "#             fold_preds            = model.predict(test_scaled)\n",
    "\n",
    "#         elif \"tn\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n",
    "                \n",
    "#             fold_preds              = model.predict(test[FEATURES].values).flatten()\n",
    "            \n",
    "#         elif \"nn\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 X_cat, X_num      = get_nn_features(train, test_df.copy())\n",
    "#             fold_preds        = model.predict([X_cat.values, X_num.values])\n",
    "#             fold_preds        = fold_preds.flatten()\n",
    "\n",
    "#         elif \"tf\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 test, FEATURES = get_tf_features(train.copy(),test_df.copy())\n",
    "#                 fold_preds     = model.predict(test[FEATURES].copy())\n",
    "\n",
    "#         elif \"tabm\" in model_path:\n",
    "#             if fold == 0:\n",
    "#                 test, FEATURES = get_tabm_features(test_df.copy())\n",
    "#             fold_preds              = model.predict(test[FEATURES].copy())\n",
    "            \n",
    "#         else: \n",
    "#             if fold == 0:\n",
    "#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n",
    "#             fold_preds              = model.predict(test[FEATURES].copy())\n",
    "            \n",
    "#         test_predictions += fold_preds\n",
    "    \n",
    "#     # Get the average predictionr\n",
    "#     test_predictions /= FOLDS\n",
    "        \n",
    "#     return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09dcfe5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:07.964102Z",
     "iopub.status.busy": "2025-02-18T13:25:07.963686Z",
     "iopub.status.idle": "2025-02-18T13:25:07.967476Z",
     "shell.execute_reply": "2025-02-18T13:25:07.966472Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.694949,
     "end_time": "2025-02-18T13:25:07.969099",
     "exception": false,
     "start_time": "2025-02-18T13:25:04.274150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
    "# test_df  = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a0c8d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:15.414848Z",
     "iopub.status.busy": "2025-02-18T13:25:15.414490Z",
     "iopub.status.idle": "2025-02-18T13:25:15.418269Z",
     "shell.execute_reply": "2025-02-18T13:25:15.417284Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.624259,
     "end_time": "2025-02-18T13:25:15.419729",
     "exception": false,
     "start_time": "2025-02-18T13:25:11.795470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first_best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1a97415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:22.648892Z",
     "iopub.status.busy": "2025-02-18T13:25:22.648552Z",
     "iopub.status.idle": "2025-02-18T13:25:22.652254Z",
     "shell.execute_reply": "2025-02-18T13:25:22.651299Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.621147,
     "end_time": "2025-02-18T13:25:22.653884",
     "exception": false,
     "start_time": "2025-02-18T13:25:19.032737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial_test_preds = inference(first_best_index, train_df, test_df)\n",
    "# initial_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cb87d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:29.875272Z",
     "iopub.status.busy": "2025-02-18T13:25:29.874849Z",
     "iopub.status.idle": "2025-02-18T13:25:29.878726Z",
     "shell.execute_reply": "2025-02-18T13:25:29.877798Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.601363,
     "end_time": "2025-02-18T13:25:29.880483",
     "exception": false,
     "start_time": "2025-02-18T13:25:26.279120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ecf28eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:37.154826Z",
     "iopub.status.busy": "2025-02-18T13:25:37.154492Z",
     "iopub.status.idle": "2025-02-18T13:25:37.158405Z",
     "shell.execute_reply": "2025-02-18T13:25:37.157289Z"
    },
    "papermill": {
     "duration": 3.61811,
     "end_time": "2025-02-18T13:25:37.160112",
     "exception": false,
     "start_time": "2025-02-18T13:25:33.542002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_preds = []\n",
    "# for model, weight in model_weights.items():\n",
    "#     print(f\"Using model : {model}\")\n",
    "#     test_df            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "    \n",
    "#     test_preds         = inference(model, train_df.copy(), test_df)\n",
    "#     test_preds         = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n",
    "#     initial_test_preds = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f69e6317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:44.465758Z",
     "iopub.status.busy": "2025-02-18T13:25:44.465379Z",
     "iopub.status.idle": "2025-02-18T13:25:44.469433Z",
     "shell.execute_reply": "2025-02-18T13:25:44.468380Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.576968,
     "end_time": "2025-02-18T13:25:44.471559",
     "exception": false,
     "start_time": "2025-02-18T13:25:40.894591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df               = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
    "# test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "# test_preds             = np.zeros(len(test_df))\n",
    "\n",
    "\n",
    "# preds_dict = {}\n",
    "# for model, weight in model_weights.items():\n",
    "#     print(f\"exp name : {model}\\n\")\n",
    "#     test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "#     test_preds             = inference(model, train_df.copy(), test_df.copy())\n",
    "#     test_preds             = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n",
    "#     initial_test_preds     = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d809b7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:51.663055Z",
     "iopub.status.busy": "2025-02-18T13:25:51.662674Z",
     "iopub.status.idle": "2025-02-18T13:25:51.666658Z",
     "shell.execute_reply": "2025-02-18T13:25:51.665587Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.626791,
     "end_time": "2025-02-18T13:25:51.668394",
     "exception": false,
     "start_time": "2025-02-18T13:25:48.041603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f80a4d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:58.851818Z",
     "iopub.status.busy": "2025-02-18T13:25:58.851412Z",
     "iopub.status.idle": "2025-02-18T13:25:58.855562Z",
     "shell.execute_reply": "2025-02-18T13:25:58.854344Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.590436,
     "end_time": "2025-02-18T13:25:58.857545",
     "exception": false,
     "start_time": "2025-02-18T13:25:55.267109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# potential_ensemble                = pd.DataFrame()\n",
    "# potential_ensemble[\"predictions\"] = test_preds\n",
    "# potential_ensemble[\"ID\"]          = test_df[\"ID\"]\n",
    "# new_score                         = score(test_df[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy(), potential_ensemble.copy(), \"ID\")\n",
    "# new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e125e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:26:06.317196Z",
     "iopub.status.busy": "2025-02-18T13:26:06.316798Z",
     "iopub.status.idle": "2025-02-18T13:26:06.320542Z",
     "shell.execute_reply": "2025-02-18T13:26:06.319606Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.645735,
     "end_time": "2025-02-18T13:26:06.322242",
     "exception": false,
     "start_time": "2025-02-18T13:26:02.676507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795638e",
   "metadata": {
    "papermill": {
     "duration": 3.710368,
     "end_time": "2025-02-18T13:26:13.660278",
     "exception": false,
     "start_time": "2025-02-18T13:26:09.949910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 7: Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c004f658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:26:20.894093Z",
     "iopub.status.busy": "2025-02-18T13:26:20.893660Z",
     "iopub.status.idle": "2025-02-18T13:26:20.897730Z",
     "shell.execute_reply": "2025-02-18T13:26:20.896371Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.634435,
     "end_time": "2025-02-18T13:26:20.899561",
     "exception": false,
     "start_time": "2025-02-18T13:26:17.265126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n",
    "# sub.prediction = test_preds\n",
    "# sub.to_csv(\"submission.csv\",index=False)\n",
    "# print(\"Sub shape:\",sub.shape)\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca000d4",
   "metadata": {
    "papermill": {
     "duration": 3.584056,
     "end_time": "2025-02-18T13:26:28.172544",
     "exception": false,
     "start_time": "2025-02-18T13:26:24.588488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 10682912,
     "datasetId": 6415434,
     "sourceId": 10370860,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7545479,
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10376781,
     "datasetId": 6226248,
     "sourceId": 10097128,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10726036,
     "datasetId": 6450507,
     "sourceId": 10409094,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211322530,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 216172723,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217481514,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217813503,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 217931837,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218131499,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218144682,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218801338,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 218802756,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219153168,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219154661,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219195490,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219311236,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219519933,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219788453,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 219953795,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 220208646,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 220212754,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 220243528,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 220393279,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221224474,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221474387,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221524326,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221636013,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221640769,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221830134,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222021427,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222265918,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222267362,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222268629,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222637056,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222638468,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222639128,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222646580,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222647954,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 222688114,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 223111714,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 223114497,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23940.409992,
   "end_time": "2025-02-18T13:26:34.470210",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-18T06:47:34.060218",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
