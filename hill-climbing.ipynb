{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceType":"competition","sourceId":70942,"databundleVersionId":10381525},{"sourceType":"datasetVersion","sourceId":10370860,"datasetId":6415434,"databundleVersionId":10682912},{"sourceType":"datasetVersion","sourceId":7453542,"datasetId":921302,"databundleVersionId":7545479},{"sourceType":"datasetVersion","sourceId":10097128,"datasetId":6226248,"databundleVersionId":10376781},{"sourceType":"datasetVersion","sourceId":10409094,"datasetId":6450507,"databundleVersionId":10726036},{"sourceType":"kernelVersion","sourceId":211322530},{"sourceType":"kernelVersion","sourceId":216172723},{"sourceType":"kernelVersion","sourceId":217481514},{"sourceType":"kernelVersion","sourceId":217813503},{"sourceType":"kernelVersion","sourceId":217931837},{"sourceType":"kernelVersion","sourceId":218131499},{"sourceType":"kernelVersion","sourceId":218144682},{"sourceType":"kernelVersion","sourceId":218801338},{"sourceType":"kernelVersion","sourceId":218802756},{"sourceType":"kernelVersion","sourceId":219153168},{"sourceType":"kernelVersion","sourceId":219154661},{"sourceType":"kernelVersion","sourceId":219195490},{"sourceType":"kernelVersion","sourceId":219311236},{"sourceType":"kernelVersion","sourceId":219519933},{"sourceType":"kernelVersion","sourceId":219788453},{"sourceType":"kernelVersion","sourceId":219953795},{"sourceType":"kernelVersion","sourceId":220208646},{"sourceType":"kernelVersion","sourceId":220212754},{"sourceType":"kernelVersion","sourceId":220243528},{"sourceType":"kernelVersion","sourceId":220393279},{"sourceType":"kernelVersion","sourceId":221224474},{"sourceType":"kernelVersion","sourceId":221474387},{"sourceType":"kernelVersion","sourceId":221524326},{"sourceType":"kernelVersion","sourceId":221636013},{"sourceType":"kernelVersion","sourceId":221640769},{"sourceType":"kernelVersion","sourceId":221830134},{"sourceType":"kernelVersion","sourceId":222021427},{"sourceType":"kernelVersion","sourceId":222265918},{"sourceType":"kernelVersion","sourceId":222267362},{"sourceType":"kernelVersion","sourceId":222268629},{"sourceType":"kernelVersion","sourceId":222637056},{"sourceType":"kernelVersion","sourceId":222638468},{"sourceType":"kernelVersion","sourceId":222639128},{"sourceType":"kernelVersion","sourceId":222646580},{"sourceType":"kernelVersion","sourceId":222647954},{"sourceType":"kernelVersion","sourceId":222688114},{"sourceType":"kernelVersion","sourceId":222831405},{"sourceType":"kernelVersion","sourceId":223111714},{"sourceType":"kernelVersion","sourceId":223730449},{"sourceType":"kernelVersion","sourceId":223733528},{"sourceType":"kernelVersion","sourceId":223734261},{"sourceType":"kernelVersion","sourceId":223847496},{"sourceType":"kernelVersion","sourceId":224446847},{"sourceType":"kernelVersion","sourceId":224920880},{"sourceType":"kernelVersion","sourceId":225297866},{"sourceType":"kernelVersion","sourceId":225326328},{"sourceType":"kernelVersion","sourceId":225343712},{"sourceType":"kernelVersion","sourceId":225424423},{"sourceType":"kernelVersion","sourceId":225426770},{"sourceType":"kernelVersion","sourceId":225454357},{"sourceType":"kernelVersion","sourceId":225456146},{"sourceType":"kernelVersion","sourceId":225456748},{"sourceType":"kernelVersion","sourceId":225464407},{"sourceType":"kernelVersion","sourceId":225634491},{"sourceType":"kernelVersion","sourceId":225640399},{"sourceType":"kernelVersion","sourceId":225719412},{"sourceType":"kernelVersion","sourceId":225733236}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installations","metadata":{"_uuid":"9daabf89-8847-4537-a0b7-2a722b5c452d","_cell_guid":"46a264b2-b97f-487b-9a3d-2597a0ecdc21","collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:15:51.123667Z","iopub.execute_input":"2025-03-04T18:15:51.123888Z","iopub.status.idle":"2025-03-04T18:16:11.613179Z","shell.execute_reply.started":"2025-03-04T18:15:51.123863Z","shell.execute_reply":"2025-03-04T18:16:11.611863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --no-index -U --find-links=/kaggle/input/tabm-tabular-dl-library tabm==0.0.1.dev0\n!pip -q install /kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:16:11.614178Z","iopub.execute_input":"2025-03-04T18:16:11.614431Z","iopub.status.idle":"2025-03-04T18:16:18.778595Z","shell.execute_reply.started":"2025-03-04T18:16:11.614384Z","shell.execute_reply":"2025-03-04T18:16:18.777311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip -q install /kaggle/input/tabpfn-v2/tabpfn-2.0.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:16:18.779590Z","iopub.execute_input":"2025-03-04T18:16:18.779882Z","iopub.status.idle":"2025-03-04T18:16:22.434027Z","shell.execute_reply.started":"2025-03-04T18:16:18.779853Z","shell.execute_reply":"2025-03-04T18:16:22.433032Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 1 : Installations","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.stats import rankdata \n\nimport sys\nsys.path.append('/kaggle/input/tabm-tabular-dl-library')\n\nimport os\nimport tabm\nimport math\nimport torch\nimport random\nimport warnings\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport rtdl_num_embeddings\nimport matplotlib.pyplot as plt\nfrom typing import Optional, Tuple\nfrom sklearn.model_selection import KFold\nfrom scipy.stats import rankdata \n#from colorama import Fore, Style\nfrom typing import Optional, Tuple\nfrom numpy.typing import ArrayLike\nfrom sklearn.base import BaseEstimator\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import KFold\nfrom tabm_reference import Model, make_parameter_groups\nfrom sklearn.preprocessing import OrdinalEncoder, QuantileTransformer\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Embedding\nfrom tensorflow.keras.layers import Concatenate, BatchNormalization\nimport tensorflow.keras.backend as K\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom tabpfn import TabPFNRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:16:28.777069Z","iopub.execute_input":"2025-03-04T18:16:28.777396Z","iopub.status.idle":"2025-03-04T18:17:11.584233Z","shell.execute_reply.started":"2025-03-04T18:16:28.777363Z","shell.execute_reply":"2025-03-04T18:17:11.582406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Experiments Paths  to add in ensemble","metadata":{}},{"cell_type":"code","source":"experiments = [\n\"/kaggle/input/xgboost-exp-01\",\n\"/kaggle/input/catboost-exp-01\", \n\"/kaggle/input/lgbm-exp-01\",\n\"/kaggle/input/xgboost-exp-02\",\n\"/kaggle/input/catboost-exp-02\",\n\"/kaggle/input/lgbm-exp-03\",\n\"/kaggle/input/catboost-exp-03\",\n\"/kaggle/input/tabm-exp-01\",\n\"/kaggle/input/nn-exp-01\",\n\"/kaggle/input/tn-exp-01\",\n\"/kaggle/input/tf-exp-01\",\n\"/kaggle/input/svr-exp-01\",\n\"/kaggle/input/abd-exp-01\",\n\"/kaggle/input/catboost-exp-04\",\n\"/kaggle/input/lgbm-exp-04\",\n\"/kaggle/input/tabm-exp-02\",\n\"/kaggle/input/ds-exp-01\",\n\"/kaggle/input/nn-exp-02\",\n\"/kaggle/input/nn-exp-04\",\n\"/kaggle/input/catboost-exp-05\",\n\"/kaggle/input/xgboost-exp-05\",\n\"/kaggle/input/lgbm-exp-05\",\n\"/kaggle/input/tn-exp-02\",\n\"/kaggle/input/vr-exp-01\",\n\"/kaggle/input/tt-exp-01\",\n\"/kaggle/input/en-exp-01\",\n\"/kaggle/input/en-exp-02\",\n\"/kaggle/input/nn-exp-05\",\n\"/kaggle/input/rf-exp-05\",\n\"/kaggle/input/mcts-exp-02\",\n\"/kaggle/input/catboost-exp-06\",\n\"/kaggle/input/xgboost-exp-06\",\n\"/kaggle/input/lgbm-exp-06\",\n\"/kaggle/input/nn-exp-06\",\n\"/kaggle/input/xgboost-exp-07\",\n\"/kaggle/input/ri-exp-01\",\n\"/kaggle/input/xgboost-exp-08\",\n\"/kaggle/input/catboost-exp-08\",\n\"/kaggle/input/lgbm-exp-08\",\n\"/kaggle/input/xgboost-exp-09\",\n\"/kaggle/input/prlnn-exp-01\",\n\"/kaggle/input/ri-exp-06\",\n\"/kaggle/input/xgboost-exp-10\",\n\"/kaggle/input/lasso-exp-01\",\n\"/kaggle/input/lir-exp-01\",\n\"/kaggle/input/svr-exp-06\",\n\"/kaggle/input/et-exp-01\",\n\"/kaggle/input/lasso-exp-02\",\n\"/kaggle/input/pr-exp-06\",\n\"/kaggle/input/tr-exp-06\",\n\"/kaggle/input/lasso-exp-06\",\n\"/kaggle/input/ransac-exp-01\",\n\"/kaggle/input/cnn-exp-01\",\n\"/kaggle/input/ts-exp-01\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:20.304230Z","iopub.execute_input":"2025-03-04T18:17:20.305125Z","iopub.status.idle":"2025-03-04T18:17:20.311811Z","shell.execute_reply.started":"2025-03-04T18:17:20.305070Z","shell.execute_reply":"2025-03-04T18:17:20.310155Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3 : Competition metric","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport pandas.api.types\nimport numpy as np\nfrom lifelines.utils import concordance_index\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n    \n    event_label = 'efs'\n    interval_label = 'efs_time'\n    prediction_label = 'predictions'\n    for col in submission.columns:\n        if not pandas.api.types.is_numeric_dtype(submission[col]):\n            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n    # Merging solution and submission dfs on ID\n    merged_df = pd.concat([solution, submission], axis=1)\n    merged_df.reset_index(inplace=True)\n    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n    metric_list = []\n\n    for race in merged_df_race_dict.keys():\n        # Retrieving values from y_test based on index\n        indices = sorted(merged_df_race_dict[race])\n        merged_df_race = merged_df.iloc[indices]\n        # Calculate the concordance index\n        c_index_race = concordance_index(\n                        merged_df_race[interval_label],\n                        -merged_df_race[prediction_label],\n                        merged_df_race[event_label])\n        metric_list.append(c_index_race)\n    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:24.989435Z","iopub.execute_input":"2025-03-04T18:17:24.989853Z","iopub.status.idle":"2025-03-04T18:17:25.067703Z","shell.execute_reply.started":"2025-03-04T18:17:24.989819Z","shell.execute_reply":"2025-03-04T18:17:25.066446Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Find best model ","metadata":{}},{"cell_type":"code","source":"parquet_experiments = [\n    \"/kaggle/input/abd-exp-01\",\n    \"/kaggle/input/lgbm-exp-04\", \n    \"/kaggle/input/catboost-exp-01\", \n    \"/kaggle/input/lgbm-exp-01\", \n    \"/kaggle/input/lgbm-exp-03\", \n    \"/kaggle/input/ds-exp-01\",\n    \"/kaggle/input/nn-exp-02\",\n    \"/kaggle/input/nn-exp-04\",\n    \"/kaggle/input/tabm-exp-03\",\n    \"/kaggle/input/catboost-exp-05\",\n    \"/kaggle/input/xgboost-exp-05\",\n    \"/kaggle/input/lgbm-exp-05\",\n    \"/kaggle/input/tn-exp-02\",\n    \"/kaggle/input/vr-exp-01\",\n    \"/kaggle/input/tt-exp-01\",\n    \"/kaggle/input/en-exp-01\",\n    \"/kaggle/input/svr-exp-01\",\n    \"/kaggle/input/en-exp-02\",\n    \"/kaggle/input/nn-exp-05\",\n    \"/kaggle/input/rf-exp-05\",\n    \"/kaggle/input/mcts-exp-02\",\n    \"/kaggle/input/catboost-exp-06\",\n    \"/kaggle/input/xgboost-exp-06\",\n    \"/kaggle/input/lgbm-exp-06\",\n    \"/kaggle/input/nn-exp-06\",\n    \"/kaggle/input/xgboost-exp-07\",\n    \"/kaggle/input/ri-exp-01\",\n    \"/kaggle/input/xgboost-exp-08\",\n    \"/kaggle/input/catboost-exp-08\",\n    \"/kaggle/input/lgbm-exp-08\",\n    \"/kaggle/input/xgboost-exp-09\",\n    \"/kaggle/input/prlnn-exp-01\",\n    \"/kaggle/input/ri-exp-06\",\n    \"/kaggle/input/xgboost-exp-10\",\n    \"/kaggle/input/lasso-exp-01\",\n    \"/kaggle/input/lir-exp-01\",\n    \"/kaggle/input/svr-exp-06\",\n    \"/kaggle/input/et-exp-01\",\n    \"/kaggle/input/lasso-exp-02\",\n    \"/kaggle/input/pr-exp-06\",\n    \"/kaggle/input/tr-exp-06\",\n    \"/kaggle/input/lasso-exp-06\",\n    \"/kaggle/input/ransac-exp-01\",\n    \"/kaggle/input/cnn-exp-01\",\n    \"/kaggle/input/ts-exp-01\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:30.517324Z","iopub.execute_input":"2025-03-04T18:17:30.517790Z","iopub.status.idle":"2025-03-04T18:17:30.523661Z","shell.execute_reply.started":"2025-03-04T18:17:30.517752Z","shell.execute_reply":"2025-03-04T18:17:30.522329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metric_cindex(oof, exp_name, fast=False):    \n    if fast:\n        y_true = oof[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n        y_pred = oof[[\"ID\",\"predictions\"]].copy()\n        return optimized_score(y_true.copy(), y_pred.copy(), \"ID\"), oof\n    else:\n        y_true = oof[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n        y_pred = oof[[\"ID\",\"predictions\"]].copy()\n        return score(y_true.copy(), y_pred.copy(), \"ID\"), oof","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:36.064944Z","iopub.execute_input":"2025-03-04T18:17:36.065364Z","iopub.status.idle":"2025-03-04T18:17:36.070954Z","shell.execute_reply.started":"2025-03-04T18:17:36.065331Z","shell.execute_reply":"2025-03-04T18:17:36.069668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install openpyxl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:37.460239Z","iopub.execute_input":"2025-03-04T18:17:37.460627Z","iopub.status.idle":"2025-03-04T18:17:41.478672Z","shell.execute_reply.started":"2025-03-04T18:17:37.460583Z","shell.execute_reply":"2025-03-04T18:17:41.477288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nfrom typing import List, Dict, Tuple\nimport logging\nimport gc\nfrom scipy.stats import rankdata\nfrom lifelines.utils import concordance_index\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\n\ndef fast_concordance_index(event_times, predicted_scores, event_observed):\n    \"\"\"Faster implementation of concordance index using NumPy operations\"\"\"\n    # Convert to numpy arrays for faster operations\n    event_times = np.asarray(event_times)\n    predicted_scores = np.asarray(predicted_scores)\n    event_observed = np.asarray(event_observed)\n    \n    # Only consider pairs where at least one has an event\n    mask = event_observed == 1\n    \n    if not np.any(mask):\n        return 0.0\n    \n    # Get indices of samples with events\n    event_indices = np.where(mask)[0]\n    \n    # Initialize counters\n    concordant = 0\n    discordant = 0\n    tied_risk = 0\n    pairs = 0\n\n    # For each sample with an event\n    for i in event_indices:\n        # Find all samples with longer survival time\n        longer_survival = event_times > event_times[i]\n        \n        # For samples with same survival time, only consider if they didn't have an event\n        same_survival = (event_times == event_times[i]) & (event_observed == 0)\n        \n        # Combine masks\n        comparable = longer_survival | same_survival\n        \n        if not np.any(comparable):\n            continue\n        \n        # Get predictions for comparable samples\n        comp_scores = predicted_scores[comparable]\n        current_score = predicted_scores[i]\n        \n        # Count concordant, discordant, and tied pairs\n        concordant += np.sum(comp_scores < current_score)\n        discordant += np.sum(comp_scores > current_score)\n        tied_risk += np.sum(comp_scores == current_score)\n        \n        # Update total pairs count\n        pairs += np.sum(comparable)\n    \n    if pairs == 0:\n        return 0.0\n    \n    return (concordant + 0.5 * tied_risk) / pairs\n\n\ndef optimized_score(solution_data, submission_data, row_id_column_name=None):\n    \"\"\"Optimized scoring function using NumPy operations\"\"\"\n    if row_id_column_name:\n        # Extract necessary columns and convert to NumPy arrays\n        event = solution_data['efs'].values\n        time = solution_data['efs_time'].values\n        race_groups = solution_data['race_group'].values\n        predictions = submission_data['predictions'].values\n    else:\n        # Assume data is already in the right format\n        event = solution_data[:, 0]  # efs\n        time = solution_data[:, 1]   # efs_time\n        race_groups = solution_data[:, 2]  # race_group\n        predictions = submission_data  # predictions\n    \n    # Get unique race groups\n    unique_races = np.unique(race_groups)\n    c_indices = []\n    \n    # Calculate c-index for each race group\n    for race in unique_races:\n        mask = race_groups == race\n        \n        # Use lifelines concordance_index for correctness\n        c_index_race = concordance_index(\n            time[mask],\n            -predictions[mask],\n            event[mask]\n        )\n        c_indices.append(c_index_race)\n    \n    c_indices = np.array(c_indices)\n    return float(np.mean(c_indices) - np.sqrt(np.var(c_indices)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:45.724939Z","iopub.execute_input":"2025-03-04T18:17:45.725492Z","iopub.status.idle":"2025-03-04T18:17:45.739218Z","shell.execute_reply.started":"2025-03-04T18:17:45.725424Z","shell.execute_reply":"2025-03-04T18:17:45.737826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multiprocessing.cpu_count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:49.626524Z","iopub.execute_input":"2025-03-04T18:17:49.626929Z","iopub.status.idle":"2025-03-04T18:17:49.635454Z","shell.execute_reply.started":"2025-03-04T18:17:49.626898Z","shell.execute_reply":"2025-03-04T18:17:49.634024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport pandas as pd\n\n# Initialize empty list to store individual prediction dataframes\ndfs_to_merge = []\n\n# Load first experiment to get the base structure\nbase_exp = experiments[0]\nif base_exp in parquet_experiments:\n    base_df = pd.read_parquet(base_exp + '/' + (base_exp.split('/')[-1]).replace('-','_') + '_oof.parquet')\nelse:\n    base_df = pd.read_excel(base_exp + '/' + (base_exp.split('/')[-1]).replace('-','_') + '_oof.xlsx')\n\n# Create base dataframe with ID and target variables\npreds_df = base_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n\n# Load and merge predictions from each experiment\nfor exp_name in tqdm(experiments):\n    # Read the prediction file\n    if exp_name in parquet_experiments:\n        if \"mcts-exp-02\" in exp_name:\n            curr_df = pd.read_parquet(exp_name + '/mcts_exp_01' + '_oof.parquet')\n        elif \"ts-exp-01\" in exp_name:\n            prev_df = pd.read_parquet(\"/kaggle/input/cnn-exp-01/cnn_exp_01_oof.parquet\")\n            curr_df = pd.read_parquet(\"/kaggle/input/ts-exp-01/ts_exp_01_oof.parquet\")\n            curr_df[\"ID\"] = prev_df[\"ID\"]\n        else:\n            curr_df = pd.read_parquet(exp_name + '/' + (exp_name.split('/')[-1]).replace('-','_') + '_oof.parquet')\n    else:\n        curr_df = pd.read_excel(exp_name + '/' + (exp_name.split('/')[-1]).replace('-','_') + '_oof.xlsx')\n    \n    # Create a temporary dataframe with ID and predictions\n    temp_df = curr_df[[\"ID\", \"predictions\"]].copy()\n    temp_df = temp_df.rename(columns={\"predictions\": exp_name})\n    \n    # Merge with the main dataframe\n    preds_df = preds_df.merge(temp_df, on=\"ID\", how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:17:55.988647Z","iopub.execute_input":"2025-03-04T18:17:55.989020Z","iopub.status.idle":"2025-03-04T18:21:58.831797Z","shell.execute_reply.started":"2025-03-04T18:17:55.988992Z","shell.execute_reply":"2025-03-04T18:21:58.830603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds_df.shape, preds_df.columns ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:07.023540Z","iopub.execute_input":"2025-03-04T18:22:07.023989Z","iopub.status.idle":"2025-03-04T18:22:07.030545Z","shell.execute_reply.started":"2025-03-04T18:22:07.023949Z","shell.execute_reply":"2025-03-04T18:22:07.029235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(experiments)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:09.524968Z","iopub.execute_input":"2025-03-04T18:22:09.525346Z","iopub.status.idle":"2025-03-04T18:22:09.530733Z","shell.execute_reply.started":"2025-03-04T18:22:09.525318Z","shell.execute_reply":"2025-03-04T18:22:09.529570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_score    = 0\nbest_index    = -1\nbest_ensemble = 0\n\nfor k,name in enumerate(experiments):\n    oof_pre = preds_df[[\"ID\",\"efs\",\"efs_time\",\"race_group\",name]]\n    oof_pre = oof_pre.rename(columns={name: \"predictions\"})\n    s, oof = compute_metric_cindex(oof_pre, name, fast=True)\n    if s > best_score:\n        best_score    = s\n        best_index    = name\n        best_ensemble = oof\n        \n    print(f'C-index {s} {name}') \nprint()\nprint(f'Best single model is {best_index} with C-Index = {best_score}')\nexperiments.remove(best_index)\nfirst_best_index = best_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:09.786273Z","iopub.execute_input":"2025-03-04T18:22:09.786636Z","iopub.status.idle":"2025-03-04T18:22:27.417214Z","shell.execute_reply.started":"2025-03-04T18:22:09.786593Z","shell.execute_reply":"2025-03-04T18:22:27.416118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"experiments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:32.335941Z","iopub.execute_input":"2025-03-04T18:22:32.336332Z","iopub.status.idle":"2025-03-04T18:22:32.342467Z","shell.execute_reply.started":"2025-03-04T18:22:32.336299Z","shell.execute_reply":"2025-03-04T18:22:32.341353Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Iterations for hill climbing","metadata":{}},{"cell_type":"code","source":"USE_NEGATIVE_WGT = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:34.806308Z","iopub.execute_input":"2025-03-04T18:22:34.806699Z","iopub.status.idle":"2025-03-04T18:22:34.810666Z","shell.execute_reply.started":"2025-03-04T18:22:34.806669Z","shell.execute_reply":"2025-03-04T18:22:34.809496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"indices        = [best_index]\nold_best_score = best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:35.032269Z","iopub.execute_input":"2025-03-04T18:22:35.032709Z","iopub.status.idle":"2025-03-04T18:22:35.036669Z","shell.execute_reply.started":"2025-03-04T18:22:35.032675Z","shell.execute_reply":"2025-03-04T18:22:35.035704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PREPARE/MOVE VARIABLES TO GPU FOR SPEED UP\nbest_ensemble = best_ensemble\nstart         = -0.50\nif not USE_NEGATIVE_WGT: start = 0.01\nww            = np.arange(start,0.51,0.01) # GPU\nnn            = len(ww)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:35.262344Z","iopub.execute_input":"2025-03-04T18:22:35.262786Z","iopub.status.idle":"2025-03-04T18:22:35.267731Z","shell.execute_reply.started":"2025-03-04T18:22:35.262752Z","shell.execute_reply":"2025-03-04T18:22:35.266396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# BEGIN HILL CLIMBING\nmodels  = [best_index]\nweights = []\nmetrics = [best_score]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:37.484825Z","iopub.execute_input":"2025-03-04T18:22:37.485246Z","iopub.status.idle":"2025-03-04T18:22:37.489312Z","shell.execute_reply.started":"2025-03-04T18:22:37.485217Z","shell.execute_reply":"2025-03-04T18:22:37.488326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models, metrics, ww","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:38.131180Z","iopub.execute_input":"2025-03-04T18:22:38.131554Z","iopub.status.idle":"2025-03-04T18:22:38.138920Z","shell.execute_reply.started":"2025-03-04T18:22:38.131522Z","shell.execute_reply":"2025-03-04T18:22:38.137404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_weight(args):\n    \"\"\"Function to evaluate a single weight for a model - designed for parallel execution\"\"\"\n    weight, best_preds, model_oof, solution_data = args\n    \n    # Create potential ensemble using NumPy operations\n    best_ranks = rankdata(best_preds)\n    model_ranks = rankdata(model_oof)\n    potential_ensemble = (1 - weight) * best_ranks + weight * model_ranks\n    \n    # Calculate score\n    new_score = optimized_score(solution_data, potential_ensemble)\n    \n    return weight, new_score\n\ndef optimize_ensemble(experiments, initial_ensemble, weights_range, score_function, max_iterations=100):\n    # Convert initial ensemble to NumPy arrays for faster processing\n    ids = initial_ensemble[\"ID\"].values\n    initial_preds = initial_ensemble[\"predictions\"].values\n    \n    # Prepare solution data as NumPy array\n    solution_data = np.column_stack((\n        preds_df[\"efs\"].values,\n        preds_df[\"efs_time\"].values,\n        preds_df[\"race_group\"].values\n    ))\n    \n    # Initialize variables\n    iteration = 0\n    best_score = score_function(\n        solution_data,\n        initial_preds,\n        None\n    )\n    \n    model_weights = {}\n    remaining_experiments = experiments.copy()\n    best_preds = initial_preds.copy()\n    \n    # Get number of CPU cores for parallel processing\n    num_cores = max(1, multiprocessing.cpu_count() - 1)\n    \n    while remaining_experiments and iteration < max_iterations:\n        print(f\"{iteration}th iteration\")\n        iteration += 1\n        best_iteration = {\n            'index': -1,\n            'weight': 0,\n            'score': best_score\n        }\n        \n        # Try each remaining model\n        for model_path in remaining_experiments:\n            try:\n                # Load model OOF predictions\n                model_name = model_path.split(\"/\")[-1].replace('-', '_')\n                model_oof = preds_df[model_path].values\n                \n                # Prepare arguments for parallel processing\n                args_list = [(weight, best_preds, model_oof, solution_data) \n                             for weight in weights_range]\n                \n                # Process weights in parallel\n                with ProcessPoolExecutor(max_workers=num_cores) as executor:\n                    futures = [executor.submit(evaluate_weight, args) for args in args_list]\n                    \n                    # Process results as they complete\n                    for future in tqdm(as_completed(futures), total=len(futures), \n                                      desc=f\"Testing weights for {model_name}\"):\n                        weight, new_score = future.result()\n                        \n                        # Update best if improved\n                        if new_score > best_iteration['score']:\n                            best_iteration.update({\n                                'index': model_path,\n                                'weight': weight,\n                                'score': new_score\n                            })\n                \n                # Clean up\n                del model_oof\n                gc.collect()\n                \n            except Exception as e:\n                print(f\"Error processing {model_path}: {str(e)}\")\n                continue\n        \n        # Check if we found an improvement\n        if best_iteration['index'] == -1:\n            print(\"No improvement found, stopping\")\n            print(best_iteration)\n            break\n            \n        # Update ensemble with best model found\n        best_score = best_iteration['score']\n        model_weights[best_iteration['index']] = best_iteration['weight']\n        remaining_experiments.remove(best_iteration['index'])\n        \n        print(\n            f\"Iteration {iteration}: Added {best_iteration['index']} \"\n            f\"with weight {best_iteration['weight']:.4f}, \"\n            f\"Score: {best_iteration['score']:.4f}\"\n        )\n        \n        # Update best ensemble for next iteration\n        model_oof = preds_df[best_iteration['index']].values\n        best_ranks = rankdata(best_preds)\n        model_ranks = rankdata(model_oof)\n        best_preds = (1 - best_iteration['weight']) * best_ranks + best_iteration['weight'] * model_ranks\n        \n    # Create final ensemble DataFrame for compatibility\n    final_ensemble = pd.DataFrame({\n        \"ID\": ids,\n        \"predictions\": best_preds\n    })\n    \n    return model_weights, best_score, final_ensemble\n\n# Run the optimized ensemble function\nmodel_weights, best_score, final_ensemble = optimize_ensemble(experiments, best_ensemble, ww, optimized_score)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T18:22:40.722575Z","iopub.execute_input":"2025-03-04T18:22:40.722972Z","execution_failed":"2025-03-04T18:37:29.484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%time\n\n# from tqdm import tqdm\n# import pandas as pd\n# import numpy as np\n# from typing import List, Dict, Tuple\n# import logging\n# import gc\n\n# def optimize_ensemble(experiments, initial_ensemble, weights_range, score_function, max_iterations = 100):\n    \n#     # Initialize variables\n#     iteration  = 0\n#     best_score = score_function(\n#         initial_ensemble[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n#         initial_ensemble[[\"ID\", \"predictions\"]].copy(),\n#         \"ID\"\n#     )\n    \n#     model_weights         = {}\n#     remaining_experiments = experiments.copy()\n#     best_ensemble         = initial_ensemble.copy()\n    \n#     while remaining_experiments and iteration < max_iterations:\n#         print(f\"{iteration}th iteration\")\n#         iteration += 1\n#         best_iteration = {\n#             'index' : -1,\n#             'weight': 0,\n#             'score' : best_score\n#         }\n        \n#         # Try each remaining model\n#         for model_path in remaining_experiments:\n#             try:\n#                 #print(f\"Iteration {iteration}: Trying model {model_path}\")\n                \n#                 # Load model OOF predictions\n#                 model_name = model_path.split(\"/\")[-1].replace('-', '_')\n#                 model_oof  = preds_df[model_path]\n                \n#                 # Try different weights\n#                 for weight in tqdm(weights_range, desc=f\"Testing weights for {model_name}\"):\n#                     # Create potential ensemble\n#                     potential_ensemble = pd.DataFrame({\n#                         \"ID\": best_ensemble[\"ID\"],\n#                         \"predictions\": (1 - weight) * rankdata(best_ensemble[\"predictions\"]) + \n#                                      weight * rankdata(model_oof)\n#                     })\n                    \n#                     # Evaluate new ensemble\n#                     new_score = score_function(\n#                         preds_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy(),\n#                         potential_ensemble.copy(),\n#                         \"ID\"\n#                     )\n                    \n#                     # Update best if improved\n#                     if new_score > best_iteration['score']:\n#                         best_iteration.update({\n#                             'index' : model_path,\n#                             'weight': weight,\n#                             'score' : new_score\n#                         })\n                \n#                 # Clean up\n#                 del model_oof\n#                 gc.collect()\n                \n#             except Exception as e:\n#                 print(f\"Error processing {model_path}: {str(e)}\")\n#                 continue\n        \n#         # Check if we found an improvement\n#         if best_iteration['index'] == -1:\n#             print(\"No improvement found, stopping\")\n#             print(best_iteration)\n#             break\n            \n#         # Update ensemble with best model found\n#         best_score                             = best_iteration['score']\n#         model_weights[best_iteration['index']] = best_iteration['weight']\n#         remaining_experiments.remove(best_iteration['index'])\n        \n#         print(\n#             f\"Iteration {iteration}: Added {best_iteration['index']} \"\n#             f\"with weight {best_iteration['weight']:.4f}, \"\n#             f\"Score: {best_iteration['score']:.4f}\"\n#         )\n        \n#         # Update best ensemble for next iteration\n#         model_oof = preds_df[best_iteration['index']]\n#         best_ensemble[\"predictions\"] = (\n#             (1 - best_iteration['weight']) * rankdata(best_ensemble[\"predictions\"]) + \n#             best_iteration['weight'] * rankdata(model_oof)\n#         )\n        \n#     return model_weights, best_score\n\n\n# model_weights, best_score = optimize_ensemble(experiments, best_ensemble, ww, score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T03:43:36.692068Z","iopub.execute_input":"2025-03-04T03:43:36.692313Z","iopub.status.idle":"2025-03-04T03:43:36.700214Z","shell.execute_reply.started":"2025-03-04T03:43:36.692291Z","shell.execute_reply":"2025-03-04T03:43:36.698862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_weights, best_score, final_ensemble","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T03:43:36.701045Z","iopub.execute_input":"2025-03-04T03:43:36.701265Z","iopub.status.idle":"2025-03-04T03:43:36.722962Z","shell.execute_reply.started":"2025-03-04T03:43:36.701244Z","shell.execute_reply":"2025-03-04T03:43:36.722011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# first_best_index, experiments","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Inference on test","metadata":{}},{"cell_type":"code","source":"# class CFG:\n#     folds = 10\n\n# # https://www.kaggle.com/datasets/jsday96/mcts-tabm-models/data?select=TabMRegressor.py\n# class TabMRegressor:\n#     def __init__(\n#         self,\n#         arch_type: str        = 'tabm-mini',\n#         backbone: dict        = {'type': 'MLP', 'n_blocks': 3, 'd_block': 512, 'dropout': 0.1},\n#         d_embedding: int      = 64,  # Only used for 'tabm-mini'\n#         bin_count: int        = 48,  # Only used for 'tabm-mini'\n#         k: int                = 32,\n#         learning_rate: float  = 1e-4,\n#         weight_decay: float   = 1e-3,\n#         clip_grad_norm: bool  = True,\n#         max_epochs: int       = 100,\n#         patience: int         = 15,\n#         batch_size: int       = 32,\n#         compile_model: bool   = False,\n#         device: Optional[str] = 'cuda:0',\n#         random_state: int     = 0,\n#         verbose: bool         = True\n#     ):\n#         self.arch_type = arch_type\n#         self.backbone = backbone\n#         self.d_embedding = d_embedding\n#         self.bin_count = bin_count\n#         self.k = k\n#         self.learning_rate = learning_rate\n#         self.weight_decay = weight_decay\n#         self.clip_grad_norm = clip_grad_norm\n#         self.max_epochs = max_epochs\n#         self.patience = patience\n#         self.batch_size = batch_size\n#         self.compile_model = compile_model\n#         self.device = torch.device(device if device else ('cuda' if torch.cuda.is_available() else 'cpu'))\n#         self.random_state = random_state\n#         self.verbose = verbose\n\n#     def fit(\n#         self,\n#         X: pd.DataFrame,\n#         y: np.array,\n#         eval_set: Tuple[pd.DataFrame, np.array]\n#     ):\n#         # PREPROCESS DATA.\n#         X_cat_train, X_cont_train, cat_cardinalities, y_train = self._preprocess_data(X, y, training=True)\n#         X_cat_val, X_cont_val, _, y_val = self._preprocess_data(eval_set[0], eval_set[1], training=False)\n\n#         # CREATE MODEL & TRAINING ALGO.\n#         bins = rtdl_num_embeddings.compute_bins(X_cont_train, n_bins=self.bin_count) if self.arch_type == 'tabm-mini' else None\n#         self.model = Model(\n#             n_num_features=X_cont_train.shape[1],\n#             cat_cardinalities=cat_cardinalities,\n#             n_classes=None,\n#             backbone=self.backbone,\n#             bins=bins,\n#             num_embeddings=(\n#                 None\n#                 if bins is None\n#                 else {\n#                     'type': 'PiecewiseLinearEmbeddings',\n#                     'd_embedding': self.d_embedding,\n#                     'activation': True,\n#                     'version': 'B',\n#                 }\n#             ),\n#             arch_type=self.arch_type,\n#             k=self.k,\n#         ).to(self.device)\n#         optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.learning_rate, weight_decay=self.weight_decay)\n#         if self.compile_model:\n#             self.model = torch.compile(self.model)\n\n#         loss_fn = torch.nn.MSELoss().to(self.device)\n#         # TRAIN & TEST MODEL.\n#         best = {\n#             'epoch': -1,\n#             'eval_loss': math.inf,\n#             'model_state_dict': None,\n#         }\n#         remaining_patience = self.patience\n#         epoch_size = math.ceil(len(X) / self.batch_size)\n\n\n#         for epoch in range(self.max_epochs):\n#             # TRAIN.\n#             optimizer.zero_grad()\n#             train_losses = []\n#             progress_bar = torch.randperm(len(y_train), device=self.device).split(self.batch_size)\n#             progress_bar = tqdm(progress_bar, desc=f'Epoch {epoch}', total=epoch_size) if self.verbose else progress_bar\n#             for batch_idx in progress_bar:\n#                 self.model.train()\n\n#                 with torch.amp.autocast(device_type='cuda', dtype = torch.bfloat16):\n#                     y_pred = self.model(\n#                         X_cont_train[batch_idx],\n#                         X_cat_train[batch_idx],\n#                     ).squeeze(-1).float()\n\n#                 loss = loss_fn(y_pred.flatten(0, 1), y_train[batch_idx].repeat_interleave(self.k))\n#                 loss.backward()\n#                 if self.clip_grad_norm:\n#                     torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n#                 optimizer.step()\n\n#                 train_losses.append(loss.item())\n\n\n#              # EVALUATE.\n#             self.model.eval()\n#             val_losses = []\n#             with torch.no_grad():\n#                 for batch_idx in torch.arange(0, len(y_val), self.batch_size, device=self.device):\n#                     y_pred = self.model(\n#                         X_cont_val[batch_idx:batch_idx+self.batch_size],\n#                         X_cat_val[batch_idx:batch_idx+self.batch_size],\n#                     ).squeeze(-1).float()\n\n#                     loss = loss_fn(y_pred.flatten(0, 1), y_val[batch_idx:batch_idx+self.batch_size].repeat_interleave(self.k))\n#                     val_losses.append(loss.item())\n\n\n#             # PRINT INFO.\n#             mean_train_loss = np.mean(train_losses)\n#             mean_val_loss = np.mean(val_losses)\n#             if self.verbose:\n#                 print(f'Epoch {epoch} | Train Loss: {mean_train_loss} | Val Loss: {mean_val_loss}')\n\n\n#             # COMPARE TO BEST.\n#             if mean_val_loss < best['eval_loss']:\n#                 best['epoch'] = epoch\n#                 best['eval_loss'] = mean_val_loss\n#                 best['model_state_dict'] = self.model.state_dict()\n#                 remaining_patience = self.patience\n                \n#                 if self.verbose:\n#                     print('🌸 New best epoch! 🌸')\n#             else:\n#                 remaining_patience -= 1\n\n#             # EARLY STOPPING.\n#             if remaining_patience == 0:\n#                 break\n\n#             # RESTORE BEST MODEL.\n#             self.model.load_state_dict(best['model_state_dict'])\n\n\n#     def predict(\n#         self,\n#         X: pd.DataFrame,\n#         batch_size: Optional[int] = 8096\n#     ) -> np.ndarray:\n#         # PREPROCESS DATA.\n#         X_cat, X_cont, _, _ = self._preprocess_data(X, y=None, training=False)\n\n#         # PREDICT.\n#         self.model.eval()\n#         y_pred = []\n#         with torch.no_grad():\n#             for batch_idx in torch.arange(0, len(X), batch_size, device=self.device):\n#                 y_pred.append(\n#                     self.model(\n#                         X_cont[batch_idx:batch_idx+batch_size],\n#                         X_cat[batch_idx:batch_idx+batch_size],\n#                     ).squeeze(-1).float().cpu().numpy()\n#                 )\n\n#         y_pred = np.concatenate(y_pred)\n\n\n#         # DENORMALIZE TARGETS.\n#         y_pred = y_pred * self._target_std + self._target_mean\n\n\n#         # COMPUTE ENSEMBLE MEAN.\n#         y_pred = np.mean(y_pred, axis=1)\n\n#         return y_pred\n\n\n#     def _preprocess_data(self, X: pd.DataFrame, y: pd.Series, training: bool):\n#         # PICK NON-CONSTANT COLUMNS.\n#         if training:\n#             self._non_constant_columns = X.columns[X.nunique() > 1]\n\n#         X = X[self._non_constant_columns]\n\n#         # SEPARATE CATEGORICAL & CONTINUOUS FEATURES.\n#         categorical_features = [col for col in X.columns if X[col].dtype.name == 'object']\n#         X_cat = X[categorical_features].to_numpy()\n#         X_cont = X.drop(columns=categorical_features).to_numpy()\n\n#         # ENCODE CATEGORICAL FEATURES.\n#         cat_cardinalities = [X[col].nunique() for col in categorical_features]\n\n#         if training:\n#             self._categorical_encoders = [\n#                 OrdinalEncoder()\n#                 for _ in range(X_cat.shape[1])\n#             ]\n#         X_cat = np.concatenate([\n#             encoder.fit_transform(X_cat[:, i:i+1])\n#             for i, encoder in enumerate(self._categorical_encoders)\n#         ], axis=1)\n\n#         # NORMALIZE TARGETS.\n#         if training:\n#             self._target_mean = y.mean()\n#             self._target_std = y.std()\n\n#             y = (y - self._target_mean) / self._target_std\n\n\n#         # SCALE CONTINUOUS FEATURES.\n#         if training:\n#             noise = (\n#                 np.random.default_rng(0)\n#                 .normal(0.0, 1e-5, X_cont.shape)\n#                 .astype(X_cont.dtype)\n#             )\n#             self._cont_feature_preprocessor = QuantileTransformer(\n#                 n_quantiles=max(min(len(X) // 30, 1000), 10),\n#                 output_distribution='normal',\n#                 subsample=10**9,\n#             ).fit(X_cont + noise)\n\n#         X_cont = self._cont_feature_preprocessor.transform(X_cont)\n\n\n#         # CONVERT TO TENSORS.\n#         X_cat = torch.tensor(X_cat, dtype=torch.long, device=self.device)\n#         X_cont = torch.tensor(X_cont, dtype=torch.float32, device=self.device)\n\n#         if y is not None:\n#             y = torch.tensor(y, dtype=torch.float32, device=self.device)\n\n#         return X_cat, X_cont, cat_cardinalities, y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:38.013044Z","iopub.execute_input":"2025-01-22T15:52:38.013333Z","iopub.status.idle":"2025-01-22T15:52:38.021341Z","shell.execute_reply.started":"2025-01-22T15:52:38.013310Z","shell.execute_reply":"2025-01-22T15:52:38.020210Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_tabm_features(data):\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n#     FEATURES = [c for c in data.columns if not c in RMV]\n    \n#     RMV              = ['ID']\n#     X_test           = data.drop(RMV, axis=1)\n#     y_pred           = data[['ID']]\n    \n#     #print(\"X_test shape:\", X_test.shape, '\\n')\n    \n#     cat_cols         = X_test.select_dtypes(include=['object']).columns.tolist()\n#     num_cols         = X_test.select_dtypes(exclude=['object']).columns.tolist()\n    \n#     # Preprocessing categorical\n#     imputer          = SimpleImputer(strategy='constant', fill_value='NAN')\n#     X_test[cat_cols] = imputer.fit_transform(X_test[cat_cols])\n\n#     # Preprocessing numerical\n#     imputer          = SimpleImputer(strategy=\"median\")\n#     X_test[num_cols] = imputer.fit_transform(X_test[num_cols])\n\n#     return X_test,FEATURES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:27.416912Z","iopub.execute_input":"2025-01-22T15:52:27.417188Z","iopub.status.idle":"2025-01-22T15:52:27.420357Z","shell.execute_reply.started":"2025-01-22T15:52:27.417167Z","shell.execute_reply":"2025-01-22T15:52:27.419366Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def prepare_features(model_path, train, test):\n\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\"]\n#     FEATURES = [c for c in train.columns if not c in RMV]\n#     #print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n    \n\n#     CATS = []\n#     for c in FEATURES:\n#         if train[c].dtype==\"object\":\n#             CATS.append(c)\n#             train[c] = train[c].fillna(\"NAN\")\n#             test[c]  = test[c].fillna(\"NAN\")\n#         elif \"DeepTabels\" in model_path or \"tn\" in model_path or \"svr\" in model_path:\n#             train[c] = train[c].fillna(-1)\n#             test[c]  = test[c].fillna(-1)\n            \n        \n#     #print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n    \n#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n#     #print(\"Combined data shape:\", combined.shape )\n    \n#     # LABEL ENCODE CATEGORICAL FEATURES\n#     #print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n#     for c in FEATURES:\n    \n#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n#         if c in CATS:\n#             #print(f\"{c}, \",end=\"\")\n#             combined[c],_ = combined[c].factorize()\n#             combined[c]  -= combined[c].min()\n#             combined[c]   = combined[c].astype(\"int32\")\n#             combined[c]   = combined[c].astype(\"category\")\n            \n#         # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n#         else:\n#             if combined[c].dtype ==\"float64\":\n#                 combined[c]      = combined[c].astype(\"float32\")\n#             if combined[c].dtype ==\"int64\":\n#                 combined[c]      = combined[c].astype(\"int32\")\n        \n#     train = combined.iloc[:len(train)].copy()\n#     test  = combined.iloc[len(train):].reset_index(drop=True).copy()\n                \n#     return train, test, FEATURES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:22.261913Z","iopub.execute_input":"2025-01-22T15:52:22.262226Z","iopub.status.idle":"2025-01-22T15:52:22.265689Z","shell.execute_reply.started":"2025-01-22T15:52:22.262197Z","shell.execute_reply":"2025-01-22T15:52:22.264976Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_nn_features(train, test):\n    \n#     CAT_SIZE = []\n#     CAT_EMB  = []\n#     NUMS     = []\n#     CATS     = []\n\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"fold\"]\n#     FEATURES = [c for c in train.columns if not c in RMV]\n    \n#     for c in FEATURES:\n#         if train[c].dtype==\"object\":\n#             train[c] = train[c].fillna(\"NAN\")\n#             test[c]  = test[c].fillna(\"NAN\")\n#             CATS.append(c)\n#         elif not \"age\" in c:\n#             train[c] = train[c].astype(\"str\")\n#             test[c]  = test[c].astype(\"str\")\n#             CATS.append(c)\n\n\n#     combined = pd.concat([train,test],axis=0,ignore_index=True)\n#     for c in FEATURES:\n#         if c in CATS:\n#             # LABEL ENCODE\n#             combined[c],_ = combined[c].factorize()\n#             combined[c] -= combined[c].min()\n#             combined[c] = combined[c].astype(\"int32\")\n#             #combined[c] = combined[c].astype(\"category\")\n\n#             n = combined[c].nunique()\n#             mn = combined[c].min()\n#             mx = combined[c].max()\n#             #print(f'{c} has ({n}) unique values')\n    \n#             CAT_SIZE.append(mx+1) \n#             CAT_EMB.append( int(np.ceil( np.sqrt(mx+1))) ) \n#         else:\n#             if combined[c].dtype==\"float64\":\n#                 combined[c] = combined[c].astype(\"float32\")\n#             if combined[c].dtype==\"int64\":\n#                 combined[c] = combined[c].astype(\"int32\")\n                \n#             m = combined[c].mean()\n#             s = combined[c].std()\n#             combined[c] = (combined[c]-m)/s\n#             combined[c] = combined[c].fillna(0)\n            \n#             NUMS.append(c)\n\n#     train = combined.iloc[:len(train)].copy()\n#     test = combined.iloc[len(train):].reset_index(drop=True).copy()\n\n#     return test[CATS], test[NUMS]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:18.343995Z","iopub.execute_input":"2025-01-22T15:52:18.344275Z","iopub.status.idle":"2025-01-22T15:52:18.347993Z","shell.execute_reply.started":"2025-01-22T15:52:18.344254Z","shell.execute_reply":"2025-01-22T15:52:18.347104Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_tf_features(train, test):\n#     RMV = [\"ID\",\"efs\",\"efs_time\",\"y\",\"y_na\",\"fold\"]\n#     FEATURES = [c for c in train.columns if not c in RMV]\n\n\n#     test                             = test.replace('Not done', 'missing')\n#     test                             = test.replace('Not tested', 'missing')\n    \n#     test['na_count']                 = test.isna().sum(axis=1)\n#     test['age_karnofsky']            = test['age_at_hct'] * test['karnofsky_score']\n#     test['age_comorbidity']          = test['age_at_hct'] * test['comorbidity_score']\n#     test['donor_recipient_age_diff'] = abs(test['donor_age'] - test['age_at_hct'])\n#     test['hla_match_ratio']          = (test['hla_high_res_8'] + test['hla_low_res_8']) / 16\n#     test['age_squared']              = test['age_at_hct'] ** 2\n#     test['karnofsky_squared']        = test['karnofsky_score'] ** 2\n#     test['16?']                      = np.where(test['age_at_hct']<=16,1,0)\n    \n#     FEATURES.extend([\"na_count\", \"age_karnofsky\", \"age_comorbidity\", \"donor_recipient_age_diff\", \"hla_match_ratio\", \"age_squared\", \"karnofsky_squared\", \"16?\"])\n\n#     CATS = []\n#     for c in FEATURES:\n#         if test[c].dtype==\"object\":\n#             CATS.append(c)\n#             test[c] = test[c].fillna(\"missing\")\n\n#     for c in FEATURES:\n#         # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n#         if c in CATS:\n#             #print(f\"{c}, \",end=\"\")\n#             test[c],_ = test[c].factorize()\n#             test[c]  -= test[c].min()\n#             test[c]   = test[c].astype(\"int32\")\n#             test[c]   = test[c].astype(\"category\")\n#         else:\n#             if test[c].dtype == \"float64\":\n#                 test[c]      = test[c].astype(\"float32\")\n#             if test[c].dtype ==\"int64\":\n#                 test[c]      = test[c].astype(\"int32\")\n    \n#     return test, FEATURES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:14.653655Z","iopub.execute_input":"2025-01-22T15:52:14.653930Z","iopub.status.idle":"2025-01-22T15:52:14.657340Z","shell.execute_reply.started":"2025-01-22T15:52:14.653909Z","shell.execute_reply":"2025-01-22T15:52:14.656475Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pickle\n# from tqdm import tqdm\n# from sklearn.svm import SVR\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.impute import KNNImputer\n\n# imputer               = KNNImputer(n_neighbors=5, weights='uniform')\n\n# scaler = StandardScaler()\n\n# FOLDS = 10\n\n# def inference(model_path, train, test_df):\n    \n#     path = model_path.split('/')[-1]\n#     file = path.replace('-','_')\n\n#     if \"dt\" not in model_path:\n#         with open(f\"/kaggle/input/{path}/{file}.pkl\", 'rb') as f:\n#             models = pickle.load(f)\n            \n#     print(\"All models are loaded successfully....!\")\n\n#     test_predictions = np.zeros(len(test_df))\n\n#     for fold in tqdm(range(FOLDS)):\n#         if \"dt\" in model_path:\n#             # model = keras.models.load_model(model_path, custom_objects=custom_objects)\n#             # train, test, FEATURES   = prepare_features(model_path, train, test_df)\n#             # model                   = tf.keras.models.load_model(model_path+f\"/model_fold_{fold}.keras\", custom_objects=dt.__dict__, compile=)\n#             # fold_preds              = model.predict(test.copy())\n#             # fold_preds              = fold_preds.flatten()\n#             pass\n#         else:\n#             model  = models[fold]\n            \n            \n#         if \"svr\" in model_path:\n#             if fold==0:\n#                 train, test, FEATURES = prepare_features(model_path, train.copy(), test_df.copy())\n\n#             # Handle missing values\n#             train_imputed         = imputer.fit_transform(train[FEATURES].copy())\n#             test_imputed          = imputer.transform(test[FEATURES])\n\n#             # Convert back to DataFrame to maintain feature names\n#             train_imputed         = pd.DataFrame(train_imputed, columns=FEATURES, index=train.index)\n#             test_imputed          = pd.DataFrame(test_imputed, columns=FEATURES, index=test.index)\n            \n#             # Scale features\n#             scaler.fit(train_imputed)\n#             test_scaled           = scaler.transform(test_imputed)\n            \n#             fold_preds            = model.predict(test_scaled)\n\n#         elif \"tn\" in model_path:\n#             if fold == 0:\n#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n                \n#             fold_preds              = model.predict(test[FEATURES].values).flatten()\n            \n#         elif \"nn\" in model_path:\n#             if fold == 0:\n#                 X_cat, X_num      = get_nn_features(train, test_df.copy())\n#             fold_preds        = model.predict([X_cat.values, X_num.values])\n#             fold_preds        = fold_preds.flatten()\n\n#         elif \"tf\" in model_path:\n#             if fold == 0:\n#                 test, FEATURES = get_tf_features(train.copy(),test_df.copy())\n#                 fold_preds     = model.predict(test[FEATURES].copy())\n\n#         elif \"tabm\" in model_path:\n#             if fold == 0:\n#                 test, FEATURES = get_tabm_features(test_df.copy())\n#             fold_preds              = model.predict(test[FEATURES].copy())\n            \n#         else: \n#             if fold == 0:\n#                 train, test, FEATURES   = prepare_features(model_path, train, test_df)\n#             fold_preds              = model.predict(test[FEATURES].copy())\n            \n#         test_predictions += fold_preds\n    \n#     # Get the average predictionr\n#     test_predictions /= FOLDS\n        \n#     return test_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:11.189637Z","iopub.execute_input":"2025-01-22T15:52:11.189923Z","iopub.status.idle":"2025-01-22T15:52:11.193648Z","shell.execute_reply.started":"2025-01-22T15:52:11.189903Z","shell.execute_reply":"2025-01-22T15:52:11.192819Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n# test_df  = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-22T15:51:51.162801Z","iopub.execute_input":"2025-01-22T15:51:51.163120Z","iopub.status.idle":"2025-01-22T15:51:51.166096Z","shell.execute_reply.started":"2025-01-22T15:51:51.163097Z","shell.execute_reply":"2025-01-22T15:51:51.165367Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# first_best_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:54.701659Z","iopub.execute_input":"2025-01-22T15:51:54.701943Z","iopub.status.idle":"2025-01-22T15:51:54.704832Z","shell.execute_reply.started":"2025-01-22T15:51:54.701923Z","shell.execute_reply":"2025-01-22T15:51:54.704065Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# initial_test_preds = inference(first_best_index, train_df, test_df)\n# initial_test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:57.348357Z","iopub.execute_input":"2025-01-22T15:51:57.348690Z","iopub.status.idle":"2025-01-22T15:51:57.351830Z","shell.execute_reply.started":"2025-01-22T15:51:57.348663Z","shell.execute_reply":"2025-01-22T15:51:57.351159Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:52:01.335658Z","iopub.execute_input":"2025-01-22T15:52:01.335938Z","iopub.status.idle":"2025-01-22T15:52:01.338972Z","shell.execute_reply.started":"2025-01-22T15:52:01.335916Z","shell.execute_reply":"2025-01-22T15:52:01.338017Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_preds = []\n# for model, weight in model_weights.items():\n#     print(f\"Using model : {model}\")\n#     test_df            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n    \n#     test_preds         = inference(model, train_df.copy(), test_df)\n#     test_preds         = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n#     initial_test_preds = test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:25:28.022763Z","iopub.execute_input":"2025-01-22T15:25:28.023081Z","iopub.status.idle":"2025-01-22T15:25:28.027486Z","shell.execute_reply.started":"2025-01-22T15:25:28.023052Z","shell.execute_reply":"2025-01-22T15:25:28.026444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df               = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n# test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n# test_preds             = np.zeros(len(test_df))\n\n\n# preds_dict = {}\n# for model, weight in model_weights.items():\n#     print(f\"exp name : {model}\\n\")\n#     test_df                = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n#     test_preds             = inference(model, train_df.copy(), test_df.copy())\n#     test_preds             = (1-weight) * rankdata(initial_test_preds) + weight * rankdata(test_preds)\n#     initial_test_preds     = test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:34.790171Z","iopub.execute_input":"2025-01-22T15:51:34.790539Z","iopub.status.idle":"2025-01-22T15:51:34.795219Z","shell.execute_reply.started":"2025-01-22T15:51:34.790484Z","shell.execute_reply":"2025-01-22T15:51:34.793900Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:38.332302Z","iopub.execute_input":"2025-01-22T15:51:38.332656Z","iopub.status.idle":"2025-01-22T15:51:38.335669Z","shell.execute_reply.started":"2025-01-22T15:51:38.332625Z","shell.execute_reply":"2025-01-22T15:51:38.334872Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# potential_ensemble                = pd.DataFrame()\n# potential_ensemble[\"predictions\"] = test_preds\n# potential_ensemble[\"ID\"]          = test_df[\"ID\"]\n# new_score                         = score(test_df[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy(), potential_ensemble.copy(), \"ID\")\n# new_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:42:13.951997Z","iopub.execute_input":"2025-01-22T15:42:13.952261Z","iopub.status.idle":"2025-01-22T15:42:13.955904Z","shell.execute_reply.started":"2025-01-22T15:42:13.952239Z","shell.execute_reply":"2025-01-22T15:42:13.955011Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:41.520933Z","iopub.execute_input":"2025-01-22T15:51:41.521214Z","iopub.status.idle":"2025-01-22T15:51:41.524083Z","shell.execute_reply.started":"2025-01-22T15:51:41.521193Z","shell.execute_reply":"2025-01-22T15:51:41.523309Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7: Create submission file","metadata":{}},{"cell_type":"code","source":"# sub            = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n# sub.prediction = test_preds\n# sub.to_csv(\"submission.csv\",index=False)\n# print(\"Sub shape:\",sub.shape)\n# sub.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:51:44.807144Z","iopub.execute_input":"2025-01-22T15:51:44.807435Z","iopub.status.idle":"2025-01-22T15:51:44.810222Z","shell.execute_reply.started":"2025-01-22T15:51:44.807409Z","shell.execute_reply":"2025-01-22T15:51:44.809395Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}